# Requirements Archive: v1.0 GPU Optimization Foundation

**Archived:** 2026-02-02
**Status:** ✅ SHIPPED (Phases 1-4.1 complete)

This is the archived requirements specification for v1.0.
For current requirements, see `.planning/REQUIREMENTS.md` (created for next milestone).

---

## v1 Requirements (Completed in Phases 1-4.1)

### GPU Parallelization

- [x] **ESM-01**: ESM-2 parallelizes across multiple GPUs using PyTorch DDP — v1.0
- [x] **ESM-02**: ESM-2 automatically queues and processes multiple batches per GPU without manual intervention — v1.0
- [x] **DNABERT-01**: DNABERT-S uses optimized batching (better than current one-file-per-GPU) — v1.0
- [x] **DNABERT-02**: DNABERT-S automatically queues and processes multiple batches per GPU — v1.0
- [x] **GPU-01**: Mixed precision (BF16) enabled for both ESM-2 and DNABERT-S (2x speedup) — v1.0
- [x] **GPU-02**: Batch sizes optimized via profiling for target GPUs (2-4x increase from current) — v1.0

### Attention & Memory Optimization

- [x] **ATT-01**: FlashAttention-2 integrated for ESM-2 embeddings (2-4x attention speedup) — v1.0
- [x] **ATT-02**: FlashAttention-2 integrated for DNABERT-S embeddings — v1.0
- [x] **MEM-01**: DataLoader prefetching with optimized worker count (num_workers=4-8) — v1.0
- [x] **MEM-02**: CUDA streams for async I/O overlap (hide 20-40% latency) — v1.0
- [x] **MEM-03**: Memory fragmentation prevention via sequence sorting — v1.0
- [x] **MEM-04**: Memory fragmentation prevention via expandable segments (PYTORCH_CUDA_ALLOC_CONF) — v1.0
- [x] **MEM-05**: Periodic CUDA cache clearing between file batches — v1.0

### Infrastructure & Checkpointing

- [x] **INFRA-01**: Batch queue manager coordinates work distribution across GPUs — v1.0
- [x] **INFRA-02**: GPU worker pool with spawn context (CUDA-safe multiprocessing) — v1.0
- [x] **INFRA-03**: Checkpoint integration with .done markers (distinguish complete vs in-progress) — v1.0
- [x] **INFRA-04**: Atomic file writes via temp-then-rename pattern (prevent corruption) — v1.0
- [x] **INFRA-05**: Checkpoint validation checks file size >0 and optionally validates keys — v1.0

### Monitoring & Load Balancing

- [x] **LOAD-01**: Load-balanced file assignment using greedy bin packing by sequence count — v1.0
- [x] **LOAD-02**: Checkpoint versioning with migration functions for backward compatibility — v1.0

### Performance & Scalability

- [x] **SCALE-02**: Works with variable GPU counts (1, 4, 8, or any number of GPUs) — v1.0

### Compatibility

- [x] **COMPAT-01**: CLI interface unchanged (users run same `virnucpro predict` command) — v1.0
- [x] **COMPAT-02**: Can resume checkpoints from pre-optimization runs (backward compatible) — v1.0
- [x] **COMPAT-03**: Single-GPU fallback mode works when only one GPU available — v1.0

### Testing

- [x] **TEST-01**: ESM-2 worker unit tests verify model loading, batching, and output format — v1.0
- [x] **TEST-02**: ESM-2 multi-GPU integration test compares output against single-GPU baseline — v1.0
- [x] **TEST-03**: DNABERT-S worker unit tests verify optimized batching matches vanilla output — v1.0
- [x] **TEST-04**: Checkpoint unit tests verify atomic writes, corruption handling, and resume capability — v1.0
- [x] **TEST-05**: Memory/attention unit tests verify FlashAttention integration and fragmentation prevention — v1.0

## Requirements Deferred to v1.1/v2.0

### Monitoring & Load Balancing (Incomplete)

- [ ] **MON-01**: GPU utilization monitoring via nvitop logs compute % and memory usage — Deferred (benchmarking incomplete)
- [ ] **MON-02**: Throughput logging tracks sequences/sec per GPU — Deferred (benchmarking incomplete)
- [ ] **MON-03**: Monitoring detects stalled workers or imbalanced load — Deferred (benchmarking incomplete)
- [ ] **LOAD-03**: Heterogeneous GPU support (handle mixed GPU types/memory sizes) — Deferred to v2.0

### Performance & Scalability (Needs Validation)

- [ ] **PERF-01**: Pipeline completes one sample (thousands of sequences) in under 10 hours — Deferred (needs end-to-end benchmarking)
- [ ] **PERF-02**: GPU utilization metrics show >80% GPU usage during embedding steps — Deferred (needs validation)
- [ ] **SCALE-01**: Adding GPUs provides linear speedup (2x GPUs = ~2x faster, measured) — Deferred (needs scaling tests)

### Testing (Incomplete)

- [ ] **TEST-06**: End-to-end integration test compares full pipeline output (optimized vs vanilla) — Deferred (Phase 6 incomplete)

---

## Milestone Summary

**Shipped:** 29 of 37 v1 requirements (78%)
**Deferred:** 8 requirements (validation/benchmarking needed)

**Key Achievements:**
- All core GPU parallelization requirements delivered
- FlashAttention-2 and memory optimizations integrated
- Checkpoint robustness with atomic writes
- Backward compatibility maintained

**Gaps:**
- Performance validation incomplete (Phase 6: 4/5 plans)
- No automated regression tracking
- End-to-end benchmarking not performed

---

_Archived: 2026-02-02 as part of v1.0 milestone completion_
