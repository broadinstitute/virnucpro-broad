---
phase: 01.1-parallel-translation
plan: 03
type: execute
wave: 3
depends_on: [01.1-02]
files_modified: [tests/test_parallel_translate.py, tests/test_integration_parallel_translate.py]
autonomous: true

must_haves:
  truths:
    - "Translation output identical between parallel and sequential"
    - "Performance improves with multiple workers"
    - "Edge cases handled correctly"
  artifacts:
    - path: "tests/test_parallel_translate.py"
      provides: "Unit tests for parallel translation"
      min_lines: 150
      contains: "test_worker_function"
    - path: "tests/test_integration_parallel_translate.py"
      provides: "Integration tests comparing outputs"
      min_lines: 100
      contains: "test_output_matches_sequential"
  key_links:
    - from: "test_parallel_translate.py"
      to: "parallel_translate.py"
      via: "import and test"
      pattern: "from virnucpro.pipeline.parallel_translate import"
---

<objective>
Add comprehensive tests for parallel translation functionality.

Purpose: Ensure parallel translation produces identical results to sequential processing and handles edge cases correctly.
Output: Test suite validating correctness, performance improvement, and error handling.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01.1-parallel-translation/01.1-01-SUMMARY.md
@.planning/phases/01.1-parallel-translation/01.1-02-SUMMARY.md

# Existing test patterns
@tests/test_parallel.py
@tests/test_work_queue.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create unit tests for parallel translation</name>
  <files>tests/test_parallel_translate.py</files>
  <action>
    Create comprehensive unit tests for parallel translation module:

    1. Create test fixture with sample sequences:
       ```python
       @pytest.fixture
       def sample_sequences():
           return [
               ("seq1", "ATGGCATGA"),  # Valid ORF
               ("seq2", "ATGAAATAA"),  # Contains stop codon
               ("seq3", "ATGATGATG"),  # All valid
               ("seq4", "NNN"),        # Invalid/ambiguous
           ]
       ```

    2. Test translate_sequence_worker:
       - test_worker_function_valid_sequence(): Valid sequence returns results
       - test_worker_function_invalid_sequence(): Invalid returns None
       - test_worker_function_picklable(): Worker can be pickled

    3. Test parallel_translate_sequences:
       - test_parallel_translate_basic(): Basic functionality with temp files
       - test_parallel_translate_single_worker(): Works with num_workers=1
       - test_parallel_translate_multiple_workers(): Works with num_workers=4
       - test_parallel_translate_empty_input(): Handles empty FASTA gracefully
       - test_parallel_translate_large_input(): Create 10000 sequences, verify processing

    4. Test batch processing:
       - test_create_sequence_batches(): Batches created correctly
       - test_translate_batch_worker(): Batch worker processes multiple sequences
       - test_batch_size_edge_cases(): Last batch handled correctly

    5. Test error handling:
       - test_corrupted_fasta_handling(): Malformed FASTA doesn't crash
       - test_worker_failure_recovery(): One worker failing doesn't stop all

    Use pytest fixtures for temp files and sample data.
    Follow patterns from existing test_parallel.py.
    Mock multiprocessing.cpu_count() to test different scenarios.
  </action>
  <verify>pytest tests/test_parallel_translate.py -v</verify>
  <done>Unit tests created covering worker functions, parallel processing, and error handling</done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests comparing outputs</name>
  <files>tests/test_integration_parallel_translate.py</files>
  <action>
    Create integration tests that verify parallel output matches sequential:

    1. Create test data generator:
       ```python
       def create_test_fasta(num_sequences=1000, seq_length=500):
           """Generate test FASTA with known sequences"""
           sequences = []
           for i in range(num_sequences):
               # Generate deterministic sequences for reproducibility
               seq = ''.join(random.Random(i).choices('ATCG', k=seq_length))
               sequences.append((f"seq_{i}", seq))
           return sequences
       ```

    2. Test output equivalence:
       - test_output_matches_sequential():
         * Run sequential translation using existing identify_seq
         * Run parallel translation with workers=4
         * Compare output files line by line
         * Assert identical content

    3. Test performance improvement:
       - test_performance_scales_with_workers():
         * Create 10000 sequences
         * Time with 1 worker
         * Time with 4 workers
         * Assert 4-worker is faster (at least 2x)
         * Log actual speedup ratio

    4. Test with real-world data patterns:
       - test_mixed_sequence_lengths(): Sequences from 100bp to 10000bp
       - test_all_reading_frames(): Verify all 6 frames processed
       - test_stop_codon_filtering(): Sequences with stops filtered correctly

    5. Test CLI integration:
       - test_cli_threads_parameter():
         * Run via subprocess: "python -m virnucpro predict test.fa --threads 4"
         * Verify completes successfully
         * Check log contains "parallel translation with 4 workers"

    Use pytest-benchmark for performance tests if available.
    Create temp directories for output files.
    Use subprocess for CLI testing to test exact user interface.
  </action>
  <verify>pytest tests/test_integration_parallel_translate.py -v</verify>
  <done>Integration tests created verifying output equivalence and performance gains</done>
</task>

<task type="auto">
  <name>Task 3: Add edge case and stress tests</name>
  <files>tests/test_parallel_translate.py</files>
  <action>
    Add additional edge case and stress tests to test_parallel_translate.py:

    1. Memory efficiency tests:
       - test_memory_efficient_processing():
         * Create mock of 1 million sequences (don't actually process)
         * Verify Pool.imap() is used (not map())
         * Check that results are yielded, not accumulated

    2. Spawn context tests:
       - test_spawn_context_used():
         * Mock multiprocessing.get_context
         * Verify called with 'spawn'
         * Ensures CUDA safety pattern followed

    3. Chunksize optimization tests:
       - test_chunksize_calculation():
         * Test get_optimal_settings() with various inputs
         * Verify chunksize is reasonable (not 1, not too large)

    4. Progress reporting tests:
       - test_progress_reporting():
         * Mock tqdm or ProgressReporter
         * Verify update() called correct number of times
         * Check progress bar description

    5. Resource cleanup tests:
       - test_pool_cleanup_on_exception():
         * Force exception during processing
         * Verify Pool is properly closed
         * Check no zombie processes

    These tests ensure robustness and production readiness.
    Use unittest.mock for mocking where appropriate.
    Follow existing patterns for resource management tests.
  </action>
  <verify>grep -c "def test_" tests/test_parallel_translate.py</verify>
  <done>Edge case and stress tests added for memory efficiency, context management, and resource cleanup</done>
</task>

</tasks>

<verification>
- Unit tests exist at tests/test_parallel_translate.py
- Integration tests exist at tests/test_integration_parallel_translate.py
- Tests verify output equivalence between parallel and sequential
- Performance tests confirm speedup with multiple workers
- Edge cases and error conditions covered
- CLI integration tested via subprocess
</verification>

<success_criteria>
- All tests pass: pytest tests/test_parallel_translate.py tests/test_integration_parallel_translate.py
- Parallel output identical to sequential (byte-for-byte)
- Performance tests show at least 2x speedup with 4 workers
- Memory-efficient processing verified (no loading 22M results in memory)
- Error handling tests pass (graceful degradation)
</success_criteria>

<output>
After completion, create `.planning/phases/01.1-parallel-translation/01.1-03-SUMMARY.md`
</output>