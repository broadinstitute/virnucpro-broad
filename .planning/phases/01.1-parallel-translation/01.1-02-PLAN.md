---
phase: 01.1-parallel-translation
plan: 02
type: execute
wave: 2
depends_on: [01.1-01]
files_modified: [virnucpro/pipeline/prediction.py, virnucpro/cli/predict.py]
autonomous: true

must_haves:
  truths:
    - "User can control translation workers with --threads parameter"
    - "Pipeline uses parallel translation when multiple cores available"
    - "Single-threaded fallback works for compatibility"
  artifacts:
    - path: "virnucpro/cli/predict.py"
      provides: "--threads CLI parameter"
      contains: "--threads"
    - path: "virnucpro/pipeline/prediction.py"
      provides: "Integration of parallel translation"
      contains: "parallel_translate"
  key_links:
    - from: "prediction.py"
      to: "parallel_translate.py"
      via: "conditional import and call"
      pattern: "from virnucpro.pipeline.parallel_translate import"
    - from: "CLI --threads"
      to: "parallel_translate_sequences"
      via: "parameter passing"
      pattern: "num_workers.*threads"
---

<objective>
Integrate parallel translation into the pipeline with CLI support.

Purpose: Enable users to control translation parallelism via --threads parameter and automatically use parallel processing when beneficial.
Output: Pipeline integration that conditionally uses parallel translation based on available cores and user preferences.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01.1-parallel-translation/01.1-01-SUMMARY.md

# Files to modify
@virnucpro/pipeline/prediction.py
@virnucpro/cli/predict.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add --threads CLI parameter</name>
  <files>virnucpro/cli/predict.py</files>
  <action>
    Add --threads parameter to the predict command:

    1. Add new option after existing parameters (around line 65, after --esm-batch-size):
       ```python
       @click.option('--threads', '-t',
                     type=int,
                     default=None,
                     help='Number of CPU threads for six-frame translation (default: all cores)')
       ```

    2. Add threads to the predict function signature (after esm_batch_size parameter)

    3. Pass threads to run_prediction_pipeline in the kwargs dict (around line 180-190 where other parameters are passed):
       - Add 'translation_threads': threads to the kwargs

    Follow existing parameter patterns in the file.
    Default to None to allow auto-detection of CPU count in the pipeline.
    Use clear help text that explains the parameter's purpose.
  </action>
  <verify>grep -n "\-\-threads" virnucpro/cli/predict.py</verify>
  <done>CLI --threads parameter added for controlling translation parallelism</done>
</task>

<task type="auto">
  <name>Task 2: Integrate parallel translation in pipeline</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Modify Stage 2 (Translation) to use parallel processing:

    1. Add translation_threads parameter to run_prediction_pipeline function signature (after esm_batch_size)

    2. Replace the existing translation stage (lines 118-156) with conditional parallel/sequential logic:
       ```python
       # Stage 2: Translation (Six-Frame Translation)
       if start_stage <= PipelineStage.TRANSLATION or not checkpoint_manager.can_skip_stage(state, PipelineStage.TRANSLATION):
           logger.info("=== Stage 2: Six-Frame Translation ===")
           checkpoint_manager.mark_stage_started(state, PipelineStage.TRANSLATION)

           # Determine whether to use parallel translation
           import os
           cpu_count = os.cpu_count() or 1
           use_parallel = False
           num_workers = translation_threads if translation_threads else cpu_count

           # Use parallel if explicitly requested or if multiple cores available
           if num_workers > 1:
               use_parallel = True
               logger.info(f"Using parallel translation with {num_workers} workers")
           else:
               logger.info("Using sequential translation (single core)")

           if use_parallel:
               from virnucpro.pipeline.parallel_translate import parallel_translate_with_progress
               try:
                   parallel_translate_with_progress(
                       chunked_file,
                       nucleotide_file,
                       protein_file,
                       num_workers=num_workers,
                       show_progress=not no_progress
                   )
               except Exception as e:
                   logger.error(f"Parallel translation failed: {e}")
                   logger.info("Falling back to sequential translation")
                   use_parallel = False

           if not use_parallel:
               # Keep existing sequential code as fallback
               from virnucpro.utils.sequence import identify_seq
               from Bio import SeqIO
               # ... (existing sequential translation code)
       ```

    3. Keep the existing sequential translation code as a fallback for:
       - Single-core systems
       - When parallel translation fails
       - When --threads=1 is explicitly set

    4. Ensure checkpoint marking remains the same for both paths

    Maintain backward compatibility by keeping sequential as fallback.
    Log clearly which mode is being used.
  </action>
  <verify>grep -n "parallel_translate" virnucpro/pipeline/prediction.py</verify>
  <done>Pipeline integrated with parallel translation, maintaining sequential fallback</done>
</task>

<task type="auto">
  <name>Task 3: Add logging and error handling</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Enhance the translation stage with proper logging and metrics:

    1. Add timing measurement:
       - Import time module at top
       - Record start_time before translation
       - Log elapsed time after completion

    2. Add sequence counting for both paths:
       - Count input sequences from chunked_file
       - Count output sequences (valid ORFs found)
       - Calculate and log translation rate (sequences/second)

    3. Improve error handling:
       - Catch specific exceptions (ImportError, multiprocessing errors)
       - Log detailed error messages
       - Ensure graceful fallback to sequential

    4. Add memory usage logging (optional):
       - Use psutil if available to log memory before/after
       - Helps users understand resource usage

    Example logging format:
    "Translation complete: processed 22,341,567 sequences in 87.3s (256,042 seq/s)"
    "Found 134,049,402 valid ORFs across 6 frames"

    This helps users understand performance gains from parallelization.
  </action>
  <verify>grep -n "Translation complete" virnucpro/pipeline/prediction.py</verify>
  <done>Enhanced logging and metrics added to translation stage</done>
</task>

</tasks>

<verification>
- CLI has --threads parameter in predict command
- Pipeline conditionally uses parallel translation based on cores and user preference
- Sequential translation retained as fallback
- Proper logging shows which mode is used and performance metrics
- Error handling ensures graceful degradation
</verification>

<success_criteria>
- User can run: virnucpro predict input.fa --threads 8
- Pipeline automatically uses parallel translation on multi-core systems
- Single-threaded systems still work with sequential translation
- Clear logging indicates translation mode and performance
- Errors in parallel mode fall back to sequential gracefully
</success_criteria>

<output>
After completion, create `.planning/phases/01.1-parallel-translation/01.1-02-SUMMARY.md`
</output>