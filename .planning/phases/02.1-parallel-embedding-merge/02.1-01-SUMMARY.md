---
phase: 02.1
plan: 01
type: summary

# Dependency tracking
requires:
  - phases: [02]
    reason: "Builds on DNABERT-S multi-GPU extraction producing multiple feature files"
provides:
  - capability: "Parallel CPU-based embedding merge"
  - functions: ["merge_file_pair_worker", "parallel_merge_features", "parallel_merge_with_progress"]
  - module: "virnucpro.pipeline.parallel_merge"
affects:
  - phase: 02.1-02
    impact: "Enables pipeline integration for parallel merge orchestration"

# Tech changes
tech-stack:
  added:
    - lib: "multiprocessing (stdlib)"
      purpose: "CPU parallelization for embedding concatenation"
      version: "stdlib (3.9+)"
  patterns:
    - name: "spawn-context-workers"
      description: "Top-level worker functions with spawn context for picklability"
      location: "virnucpro/pipeline/parallel_merge.py"
    - name: "checkpoint-skip"
      description: "Skip merge if output file exists (resume capability)"
      location: "virnucpro/pipeline/features.py:214-216"
    - name: "atomic-write"
      description: "Save to temp file then rename for corruption prevention"
      location: "virnucpro/pipeline/features.py:264-272"

# File tracking
key-files:
  created:
    - path: "virnucpro/pipeline/parallel_merge.py"
      purpose: "Parallel merge worker functions and orchestration"
      lines: 273
      exports: ["merge_file_pair_worker", "merge_batch_worker", "parallel_merge_features", "parallel_merge_with_progress", "get_optimal_settings"]
    - path: "tests/test_parallel_merge.py"
      purpose: "Unit tests for parallel merge functionality"
      lines: 424
      coverage: "Worker functions, orchestration, progress reporting, checkpoint behavior"
  modified:
    - path: "virnucpro/pipeline/features.py"
      changes: "Added checkpoint support and atomic write to merge_features()"
      lines_added: 16
      impact: "Resume capability and robustness for merge operations"

# Architecture decisions
decisions:
  - id: "spawn-context-merge"
    decision: "Use spawn context for merge workers matching Phase 1.1 pattern"
    rationale: "Consistency with existing parallel_translate.py and GPU workers, Python 3.14 compatibility"
    alternatives: "fork context (faster but unsafe with CUDA environment)"
    impact: "Consistent multiprocessing pattern across codebase"

  - id: "chunksize-dynamic"
    decision: "Calculate chunksize dynamically: max(1, num_files // (workers * 4))"
    rationale: "Balance between serialization overhead and parallelism for varying workloads"
    alternatives: "Fixed chunksize=1 (simpler but suboptimal for large workloads)"
    impact: "Better performance for 50+ file pairs without manual tuning"

  - id: "checkpoint-and-atomic"
    decision: "Add checkpoint skip and atomic write to merge_features()"
    rationale: "Enables resume capability and prevents partial file corruption"
    alternatives: "No checkpoint (reprocess all files), no atomic write (risk corruption)"
    impact: "Robustness for long-running merge operations and interruption handling"

  - id: "batch-size-one"
    decision: "Default batch_size=1 for merge (one file pair per worker call)"
    rationale: "Each file pair is substantial work (load 2 files, merge tensors, save), batching adds complexity"
    alternatives: "Batch multiple file pairs like Phase 1.1 translation (reduces serialization)"
    impact: "Simpler implementation, batch_worker available for 100+ file workloads if needed"

# Performance & Quality
metrics:
  duration: "3.7 minutes"
  completed: "2026-01-23"
  commits: 3
  tests:
    added: 15
    coverage: "Worker functions, orchestration, progress, checkpoint, spawn context"

subsystem: "embedding-processing"
tags: ["multiprocessing", "cpu-parallelization", "embedding-merge", "checkpointing"]
---

# Phase 02.1 Plan 01: Parallel Merge Worker Functions Summary

**One-liner:** CPU multiprocessing for DNABERT-S/ESM-2 feature concatenation with spawn context workers, checkpoint resume, and atomic writes

## What Was Built

Created parallel merge infrastructure following Phase 1.1 patterns to eliminate sequential bottleneck in embedding concatenation.

### Core Components

**1. Worker Functions (parallel_merge.py)**
- `merge_file_pair_worker(file_pair)` - Process single (nuc, pro, output) tuple
- `merge_batch_worker(file_pair_batch)` - Process batch of file pairs (100+ files)
- Import `merge_features()` inside workers to avoid pickling heavy objects
- Top-level functions for spawn context picklability

**2. Orchestration Functions**
- `parallel_merge_features()` - Basic parallel merge with spawn context and Pool.imap()
- `parallel_merge_with_progress()` - User-facing version with ProgressReporter integration
- `get_optimal_settings()` - Calculate workers, batch_size, chunksize for workload

**3. Checkpoint Support (features.py)**
- Skip merge if output file exists: `if output_file.exists() and output_file.stat().st_size > 0`
- Atomic write pattern: save to .tmp file, rename to final
- Cleanup temp file on failure

**4. Comprehensive Tests (test_parallel_merge.py)**
- Worker function validation (valid pairs, missing files, checkpoint skip)
- Batch worker partial failure handling
- Optimal settings calculation
- Spawn context usage verification
- Progress reporting integration
- Sequential vs parallel equivalence
- Resume capability validation

## Technical Implementation

### Spawn Context Pattern
```python
ctx = multiprocessing.get_context('spawn')
with ctx.Pool(num_workers) as pool:
    results = pool.imap(merge_file_pair_worker, file_pairs, chunksize=chunksize)
```

**Why spawn:**
- Consistency with Phase 1.1 (parallel_translate.py) and GPU workers
- Safe with CUDA-initialized environment
- Python 3.14 default (future-proof)

### Dynamic Chunksize
```python
chunksize = max(1, num_file_pairs // (num_workers * 4))
```

**Benefits:**
- Small workloads (10 files): chunksize=1, low overhead
- Large workloads (100 files, 8 workers): chunksize=3, reduced serialization
- Automatic tuning without user intervention

### Checkpoint + Atomic Write
```python
# Checkpoint skip
if output_file.exists() and output_file.stat().st_size > 0:
    logger.info(f"Skipping merge - output exists: {output_file}")
    return output_file

# Atomic write
temp_file = output_file.with_suffix('.tmp')
torch.save(merged_dict, temp_file)
temp_file.rename(output_file)
```

**Robustness:**
- Resume capability: skip already-merged files
- Corruption prevention: never leave partial .pt files
- Cleanup: remove temp file on failure

## Files Changed

### Created
- `virnucpro/pipeline/parallel_merge.py` (273 lines)
  - 2 worker functions (single + batch)
  - 2 orchestration functions (basic + progress)
  - Optimal settings helper

- `tests/test_parallel_merge.py` (424 lines)
  - 15 test methods across 5 test classes
  - Integration scenarios (equivalence, resume)

### Modified
- `virnucpro/pipeline/features.py` (+16 lines)
  - Checkpoint skip at merge start
  - Atomic write for save operation

## Deviations from Plan

None - plan executed exactly as written.

## Decisions Made

### 1. Spawn Context for Merge Workers
**Decision:** Use `multiprocessing.get_context('spawn')` instead of default (fork on Linux)

**Rationale:**
- Matches Phase 1.1 (parallel_translate.py) and GPU workers pattern
- Safe with CUDA environment (no state inheritance)
- Python 3.14 default (future-proof)

**Impact:** Consistent multiprocessing across codebase, slightly slower worker startup than fork but negligible for merge workload

### 2. Dynamic Chunksize Calculation
**Decision:** Calculate chunksize based on workload: `max(1, num_files // (workers * 4))`

**Rationale:**
- Small workloads: chunksize=1 fine (low overhead with 10 files)
- Large workloads: higher chunksize reduces serialization (100 files → chunksize=3)
- Automatic optimization without user tuning

**Impact:** Better performance across workload sizes without manual configuration

### 3. Checkpoint and Atomic Write
**Decision:** Add checkpoint skip and temp-file pattern to merge_features()

**Rationale:**
- Checkpoint: enables resume if merge interrupted (matches extraction pattern)
- Atomic write: prevents partial .pt files from corrupting downstream steps
- Minimal overhead: single exists() check and rename() operation

**Impact:** Robustness for long-running merge operations, safe interruption handling

### 4. Batch Size = 1 Default
**Decision:** Default batch_size=1 (one file pair per worker call), provide batch_worker for 100+ files

**Rationale:**
- Each file pair is substantial work (2 torch.load(), dict creation, concat, save)
- Batching adds complexity for typical workloads (10-50 files)
- merge_batch_worker available if profiling shows benefit for 100+ files

**Impact:** Simpler implementation for typical case, optimization available if needed

## What We Learned

### Pattern Reuse from Phase 1.1
Phase 1.1 (parallel_translate.py) provided directly applicable patterns:
- Top-level worker functions for spawn picklability
- Import heavy deps inside workers (not at module level)
- Pool.imap() with dynamic chunksize
- ProgressReporter integration with create_file_bar()

**Impact:** Consistent patterns across CPU parallelization tasks, minimal new code

### Checkpoint Pattern from Extraction
Extraction stages (prediction.py:336-340) use simple pattern:
```python
if not output_file.exists():
    files_to_process.append(input_file)
```

Applied to merge with atomic write extension for robustness.

**Impact:** Consistent checkpoint behavior across pipeline stages

### Merge Simpler than Translation
Merge is embarrassingly parallel with no complexity:
- No ORF detection logic (just load + concat + save)
- No sequence filtering or validation
- Each file pair fully independent

**Impact:** Simpler implementation than Phase 1.1, same patterns apply

## Next Phase Readiness

### For 02.1-02 (Pipeline Integration)
**Ready:**
- ✓ parallel_merge_features() and parallel_merge_with_progress() ready to use
- ✓ Checkpoint support enables resume capability
- ✓ Progress reporting matches existing stages (ProgressReporter.create_file_bar())
- ✓ Error handling returns list of successful merges (partial failure tolerance)

**Integration points:**
- prediction.py Stage 7: Replace sequential loop with parallel_merge_with_progress()
- CLI: Add --merge-workers parameter (default: cpu_count())
- File pairing: Use existing zip(nucleotide_files, protein_files) pattern

### Blockers
None identified.

### Risks
None identified. Patterns proven in Phase 1.1 and extraction stages.

## Commit History

| Commit | Message | Files | Impact |
|--------|---------|-------|--------|
| 31a4bb3 | feat(02.1-01): create parallel merge worker functions | parallel_merge.py | Core worker and orchestration functions |
| b0844eb | feat(02.1-01): add checkpoint support to merge_features | features.py | Resume capability and atomic writes |
| 76a8bb4 | test(02.1-01): add unit tests for parallel merge | test_parallel_merge.py | Comprehensive test coverage |

## Verification

All verification criteria met:
- ✓ Module imports correctly: `from virnucpro.pipeline import parallel_merge`
- ✓ Worker functions accessible: `merge_file_pair_worker, parallel_merge_features, parallel_merge_with_progress`
- ✓ Checkpoint support verified: `grep "exists()" features.py | grep output_file`
- ✓ Tests created with 15 test methods covering all scenarios
- ✓ Spawn context usage verified in tests
- ✓ Progress reporting integration verified

## Success Criteria Met

- ✓ parallel_merge.py module created with worker functions and orchestration
- ✓ features.py updated with checkpoint support
- ✓ Unit tests validate correctness and parallelization
- ✓ Worker functions use spawn context matching Phase 1.1 pattern
- ✓ Progress reporting integrated for user visibility

## Performance Impact

**Expected speedup:**
- Single-threaded merge: N file pairs × ~200ms/pair = 2 seconds for 10 files
- Parallel merge (8 cores): N/8 × ~200ms = 0.3 seconds for 10 files
- **6-7x speedup** for typical workloads (limited by I/O and CPU cores)

**Actual impact:** Will be measured in 02.1-02 integration testing

## Documentation

**Code documentation:**
- Comprehensive docstrings for all functions
- Examples in docstrings showing usage patterns
- Comments explaining spawn context and chunksize rationale

**Tests as documentation:**
- Test method names describe scenarios clearly
- Integration tests show sequential vs parallel equivalence
- Resume capability test demonstrates checkpoint behavior

**For users:**
- parallel_merge_with_progress() provides progress bar matching existing stages
- No configuration required (auto-detects CPU count)
- Checkpoint resume automatic (transparent to users)
