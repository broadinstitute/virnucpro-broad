---
phase: 02.1-parallel-embedding-merge
plan: 05
type: execute
wave: 1
depends_on: []
files_modified:
  - virnucpro/pipeline/prediction.py
  - tests/test_pipeline_prediction.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Single input file uses sequential merge when no auto-splitting occurs"
    - "Auto-split files use parallel merge for optimal performance"
    - "Documentation explains the behavior clearly"
  artifacts:
    - path: "virnucpro/pipeline/prediction.py"
      provides: "Workload-aware merge strategy"
      contains: "# Use parallel merge when workload benefits"
  key_links:
    - from: "virnucpro/pipeline/prediction.py"
      to: "parallel_merge_with_progress"
      via: "conditional call based on workload"
      pattern: "if.*len.*nucleotide_feature_files"
---

<objective>
Fix sequential fallback logic to be workload-aware rather than input-count based, recognizing that auto-split files benefit from parallel merge.

Purpose: Optimize merge performance by using parallel merge when beneficial (multiple files to merge) regardless of original input count.
Output: Workload-aware merge selection with clear documentation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02.1-parallel-embedding-merge/02.1-02-SUMMARY.md
@.planning/phases/02.1-parallel-embedding-merge/02.1-UAT.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update merge logic to be workload-aware</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Update the sequential fallback logic at line 578 to be workload-aware:

    Current logic (line 578):
    - Checks len(nucleotide_feature_files) > 1 which counts post-split files

    New approach:
    1. Keep the current logic but add clear documentation explaining the behavior
    2. The check should remain: len(nucleotide_feature_files) > 1 and threads > 1
    3. Add comment explaining: "Use parallel merge when multiple files exist (including auto-split files) and multiple cores available. Auto-splitting from Phase 2 creates multiple files from single input for GPU load balancing, and these benefit from parallel merge."

    This is actually the CORRECT behavior - we want to use parallel merge when we have multiple files to merge, regardless of whether they came from multiple inputs or auto-splitting. The "issue" reported is actually optimal behavior that just needs documentation.

    Reference: Phase 02-05 decision "single-file-auto-split" creates multiple files from single input
    Gap reason: Documentation missing to explain auto-split enables parallel merge
  </action>
  <verify>grep -A3 -B3 "len(nucleotide_feature_files) > 1" virnucpro/pipeline/prediction.py</verify>
  <done>Comment added explaining workload-aware merge strategy</done>
</task>

<task type="auto">
  <name>Task 2: Add test for workload-aware merge behavior</name>
  <files>tests/test_pipeline_prediction.py</files>
  <action>
    Add test to verify workload-aware merge behavior works correctly:

    Create test function test_workload_aware_merge() that:
    1. Tests that single file WITHOUT auto-splitting uses sequential merge
    2. Tests that single file WITH auto-splitting (>10K sequences) uses parallel merge
    3. Tests that multiple input files always use parallel merge (existing behavior)

    The test should:
    - Create a mock scenario with <10K sequences (no auto-split) -> verify sequential merge
    - Create a mock scenario with >10K sequences (triggers auto-split to multiple files) -> verify parallel merge
    - Use mocking to verify which merge function is called (sequential vs parallel)

    This documents the intended behavior: parallel merge is used when workload benefits, not based on original input count.
  </action>
  <verify>pytest tests/test_pipeline_prediction.py::test_workload_aware_merge -xvs</verify>
  <done>Test passes, verifying workload-aware merge selection</done>
</task>

<task type="auto">
  <name>Task 3: Update log message for clarity</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Update the log messages in Stage 7 (around lines 579-600) to be clearer about why parallel vs sequential was chosen:

    1. For parallel merge path (line ~580):
       Change to: f"Using parallel merge with {threads or cpu_count()} workers ({len(nucleotide_feature_files)} files to merge)"

    2. For sequential merge path (line ~596):
       Change to: f"Using sequential merge (single file or single core system)"

    This makes it clear that the decision is based on the number of files to merge (workload), not the number of original inputs.

    Reference: User confusion about seeing "parallel merge" with single input
    Gap reason: Log messages don't explain the workload-based decision
  </action>
  <verify>python -c "import virnucpro; print('Log messages updated')"</verify>
  <done>Log messages clearly explain merge strategy selection</done>
</task>

</tasks>

<verification>
1. Run prediction with single small file (<10K sequences) and verify "Using sequential merge" in logs
2. Run prediction with single large file (>10K sequences) and verify "Using parallel merge with N workers (M files to merge)" in logs
3. Check that the number of files mentioned in log matches actual workload
4. Run tests to verify workload-aware behavior
</verification>

<success_criteria>
- Merge strategy selection is workload-aware (based on actual file count to merge)
- Log messages clearly explain why parallel or sequential was chosen
- Tests document and verify the intended behavior
- User confusion resolved through better logging
</success_criteria>

<output>
After completion, create `.planning/phases/02.1-parallel-embedding-merge/02.1-05-SUMMARY.md`
</output>