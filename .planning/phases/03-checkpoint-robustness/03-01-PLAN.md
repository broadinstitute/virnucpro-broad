---
phase: 03-checkpoint-robustness
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [virnucpro/core/checkpoint_validation.py, virnucpro/core/checkpoint.py, virnucpro/pipeline/features.py]
autonomous: true

must_haves:
  truths:
    - "Checkpoint files are validated before use"
    - "All checkpoint saves use atomic write pattern"
    - "Corrupted checkpoints are detected and reported"
  artifacts:
    - path: "virnucpro/core/checkpoint_validation.py"
      provides: "Checkpoint validation utilities"
      min_lines: 100
      exports: ["validate_checkpoint", "CheckpointError"]
    - path: "virnucpro/core/checkpoint.py"
      provides: "Extended atomic write support"
      contains: "atomic_save"
  key_links:
    - from: "virnucpro/core/checkpoint.py"
      to: "checkpoint_validation.validate_checkpoint"
      via: "import and call"
      pattern: "from.*checkpoint_validation import.*validate_checkpoint"
---

<objective>
Create checkpoint validation utilities and extend atomic write pattern to all checkpoint operations.

Purpose: Prevent checkpoint corruption and detect invalid files before they cause pipeline failures.
Output: Validation module with multi-level checks and atomic write helpers for all checkpoint saves.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-checkpoint-robustness/03-CONTEXT.md
@.planning/phases/03-checkpoint-robustness/03-RESEARCH.md

# Existing checkpoint code
@virnucpro/core/checkpoint.py
@virnucpro/pipeline/features.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create checkpoint validation utilities</name>
  <files>virnucpro/core/checkpoint_validation.py</files>
  <action>
    Create a new module with validation utilities for PyTorch checkpoints:

    1. Create CheckpointError exception class for checkpoint-specific errors
    2. Implement validate_checkpoint() function with multi-level validation:
       - Level 1: File size check (>0 bytes)
       - Level 2: ZIP format validation using zipfile.is_zipfile()
       - Level 3: PyTorch load validation (torch.load with map_location='cpu')
       - Level 4: Required keys validation (check for expected structure)
    3. Add distinguish_error_type() to categorize errors as 'corrupted' vs 'incompatible'
    4. Implement validate_checkpoint_batch() for validating multiple checkpoints
    5. Add detailed logging showing exactly what failed (missing keys, tensor info, file paths)

    Use the research from 03-RESEARCH.md Pattern 2 (Multi-Level Checkpoint Validation) as reference.
    Include type hints and comprehensive docstrings.
  </action>
  <verify>python -c "from virnucpro.core import checkpoint_validation; print('Validation module loaded')"</verify>
  <done>checkpoint_validation.py exists with validate_checkpoint function and CheckpointError class</done>
</task>

<task type="auto">
  <name>Task 2: Extend atomic write pattern to all checkpoints</name>
  <files>virnucpro/core/checkpoint.py</files>
  <action>
    Extend the checkpoint module with atomic write utilities:

    1. Add atomic_save() function that wraps torch.save with temp-then-rename pattern:
       - Write to .tmp file first
       - Validate checkpoint after write (using checkpoint_validation)
       - Rename to final path only if validation passes
       - Clean up temp file on any failure

    2. Update CheckpointManager class methods to use atomic_save:
       - save_stage_status() - for pipeline state
       - save_file_progress() - for per-file progress tracking
       - Any other save operations in the class

    3. Add checkpoint corruption recovery support:
       - Add validate_on_load parameter to load methods (default True)
       - Add --skip-checkpoint-validation CLI flag support via config
       - Log validation results with detailed diagnostics

    Import and use the validation utilities from checkpoint_validation.py.
    Follow the existing atomic write pattern from features.py:264-272 as reference.
  </action>
  <verify>grep -n "atomic_save" virnucpro/core/checkpoint.py</verify>
  <done>checkpoint.py contains atomic_save function and uses it for all saves</done>
</task>

<task type="auto">
  <name>Task 3: Update features.py to use centralized atomic save</name>
  <files>virnucpro/pipeline/features.py</files>
  <action>
    Update the features module to use the new centralized atomic save:

    1. Import atomic_save from virnucpro.core.checkpoint
    2. Replace the manual atomic write pattern (lines 264-272) with:
       - Call to atomic_save(merged_dict, output_file)
    3. Add validation after save to ensure checkpoint is valid
    4. Update any other torch.save calls in the file to use atomic_save

    This consolidates the atomic write pattern in one place and adds validation.
  </action>
  <verify>grep -n "atomic_save" virnucpro/pipeline/features.py</verify>
  <done>features.py uses atomic_save instead of manual temp file pattern</done>
</task>

</tasks>

<verification>
1. Checkpoint validation module exists and can detect corrupted files
2. All torch.save operations use atomic write pattern
3. Validation distinguishes between corrupted and incompatible checkpoints
4. Detailed error messages show exactly what failed
</verification>

<success_criteria>
- checkpoint_validation.py module created with multi-level validation
- atomic_save function in checkpoint.py wraps all saves
- features.py updated to use centralized atomic save
- Validation errors provide actionable diagnostics
</success_criteria>

<output>
After completion, create `.planning/phases/03-checkpoint-robustness/03-01-SUMMARY.md`
</output>