---
phase: 05-async-dataloader-foundation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - virnucpro/utils/gpu_monitor.py
autonomous: true

must_haves:
  truths:
    - "GPU monitor tracks DataLoader wait time between batches"
    - "Monitor warns when GPU idle >10% (I/O bottleneck detection)"
    - "Worker queue depth metric available for prefetch monitoring"
    - "Throughput metric (sequences/sec) tracked during inference"
  artifacts:
    - path: "virnucpro/utils/gpu_monitor.py"
      provides: "Extended GPU monitor with DataLoader metrics"
      exports: ["NvitopMonitor", "GPUMonitor", "DataLoaderMetrics"]
      contains: "record_dataloader_wait"
  key_links:
    - from: "virnucpro/utils/gpu_monitor.py"
      to: "nvitop.Device"
      via: "GPU utilization sampling"
      pattern: "gpu_utilization"
---

<objective>
Extend GPU monitoring to track DataLoader-specific metrics for async pipeline performance analysis.

Purpose: Add DataLoader wait time tracking, bottleneck detection, and throughput metrics to the existing NvitopMonitor. These metrics are essential for validating that the async DataLoader achieves <5% GPU idle time (per roadmap success criteria).

Output:
- Extended `virnucpro/utils/gpu_monitor.py` with DataLoader metrics tracking
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-async-dataloader-foundation/05-CONTEXT.md
@.planning/phases/05-async-dataloader-foundation/05-RESEARCH.md

# Existing code to extend
@virnucpro/utils/gpu_monitor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add DataLoaderMetrics dataclass</name>
  <files>virnucpro/utils/gpu_monitor.py</files>
  <action>
Add a new `DataLoaderMetrics` dataclass after the existing `GPUMetrics` dataclass:

```python
@dataclass
class DataLoaderMetrics:
    """DataLoader performance metrics snapshot."""
    timestamp: float
    wait_time_ms: float        # Time spent waiting for next batch
    queue_depth: int           # Number of prefetched batches ready (if available)
    batch_idx: int             # Current batch index
    sequences_in_batch: int    # Sequences in this batch
    tokens_in_batch: int       # Tokens in this batch (for packed batches)
```

This dataclass captures per-batch DataLoader performance for bottleneck analysis.
  </action>
  <verify>
```bash
python -c "
from virnucpro.utils.gpu_monitor import DataLoaderMetrics
import time

m = DataLoaderMetrics(
    timestamp=time.time(),
    wait_time_ms=5.2,
    queue_depth=4,
    batch_idx=0,
    sequences_in_batch=32,
    tokens_in_batch=1024
)
print(f'DataLoaderMetrics created: wait={m.wait_time_ms}ms, queue={m.queue_depth}')
"
```
  </verify>
  <done>DataLoaderMetrics dataclass defined with wait_time_ms, queue_depth, batch_idx, sequences_in_batch, tokens_in_batch fields</done>
</task>

<task type="auto">
  <name>Task 2: Extend NvitopMonitor with DataLoader tracking</name>
  <files>virnucpro/utils/gpu_monitor.py</files>
  <action>
Add DataLoader metrics tracking to the existing `NvitopMonitor` class:

1. **Add instance variables in `__init__`:**
   ```python
   self._dataloader_metrics: List[DataLoaderMetrics] = []
   self._idle_threshold: float = 0.10  # Warn if GPU idle >10%
   self._batch_log_interval: int = 10  # Log every N batches
   self._total_sequences: int = 0
   self._inference_start_time: Optional[float] = None
   ```

2. **Add `record_dataloader_wait` method:**
   ```python
   def record_dataloader_wait(
       self,
       wait_time_ms: float,
       batch_idx: int,
       sequences_in_batch: int,
       tokens_in_batch: int = 0,
       queue_depth: int = 0
   ) -> None:
       """Record DataLoader fetch timing for bottleneck detection."""
       metrics = DataLoaderMetrics(
           timestamp=time.time(),
           wait_time_ms=wait_time_ms,
           queue_depth=queue_depth,
           batch_idx=batch_idx,
           sequences_in_batch=sequences_in_batch,
           tokens_in_batch=tokens_in_batch
       )
       with self._lock:
           self._dataloader_metrics.append(metrics)
           self._total_sequences += sequences_in_batch

       # Log every N batches per CONTEXT.md decision
       if batch_idx % self._batch_log_interval == 0:
           logger.info(
               f"Batch {batch_idx}: wait={wait_time_ms:.1f}ms, "
               f"seqs={sequences_in_batch}, tokens={tokens_in_batch}"
           )
   ```

3. **Add `check_bottleneck` method:**
   ```python
   def check_bottleneck(self, recent_samples: int = 10) -> Tuple[bool, float]:
       """
       Check if GPU is idle too often indicating I/O bottleneck.

       Returns:
           Tuple of (is_bottleneck, avg_utilization)
       """
       with self._lock:
           if len(self._metrics) < recent_samples:
               return False, 0.0

           recent = self._metrics[-recent_samples:]
           avg_util = sum(m.gpu_util for m in recent) / len(recent)

           is_bottleneck = avg_util < (1 - self._idle_threshold) * 100

           if is_bottleneck:
               logger.warning(
                   f"I/O bottleneck detected: GPU utilization {avg_util:.1f}% "
                   f"(threshold: {(1 - self._idle_threshold) * 100:.0f}%)"
               )

           return is_bottleneck, avg_util
   ```

4. **Add `get_dataloader_statistics` method:**
   ```python
   def get_dataloader_statistics(self) -> Dict[str, Any]:
       """Get aggregated DataLoader performance statistics."""
       with self._lock:
           metrics = self._dataloader_metrics.copy()

       if not metrics:
           return {}

       wait_times = [m.wait_time_ms for m in metrics]
       queue_depths = [m.queue_depth for m in metrics if m.queue_depth > 0]

       return {
           'avg_wait_time_ms': sum(wait_times) / len(wait_times),
           'max_wait_time_ms': max(wait_times),
           'min_wait_time_ms': min(wait_times),
           'p95_wait_time_ms': sorted(wait_times)[int(len(wait_times) * 0.95)] if wait_times else 0,
           'avg_queue_depth': sum(queue_depths) / len(queue_depths) if queue_depths else 0,
           'total_batches': len(metrics),
           'total_sequences': self._total_sequences,
       }
   ```

5. **Add `start_inference_timer` and `get_throughput` methods:**
   ```python
   def start_inference_timer(self) -> None:
       """Start timer for throughput calculation."""
       self._inference_start_time = time.time()

   def get_throughput(self) -> Dict[str, float]:
       """Get throughput metrics (sequences/sec)."""
       if self._inference_start_time is None:
           return {'sequences_per_sec': 0.0, 'elapsed_seconds': 0.0}

       elapsed = time.time() - self._inference_start_time
       seqs_per_sec = self._total_sequences / elapsed if elapsed > 0 else 0.0

       return {
           'sequences_per_sec': seqs_per_sec,
           'elapsed_seconds': elapsed,
           'total_sequences': self._total_sequences,
       }
   ```

6. **Update `get_statistics` to include DataLoader metrics:**
   - Add DataLoader stats to the returned dict under `'dataloader'` key
  </action>
  <verify>
```bash
python -c "
import time
from virnucpro.utils.gpu_monitor import NvitopMonitor

# Create monitor (may not have GPU, that's fine)
monitor = NvitopMonitor(device_ids=[0], log_interval=1.0)

# Test DataLoader metrics recording
monitor.start_inference_timer()
for i in range(5):
    monitor.record_dataloader_wait(
        wait_time_ms=2.5 + i * 0.5,
        batch_idx=i,
        sequences_in_batch=32,
        tokens_in_batch=1024,
        queue_depth=4
    )

# Get statistics
dl_stats = monitor.get_dataloader_statistics()
assert 'avg_wait_time_ms' in dl_stats, 'Missing avg_wait_time_ms'
assert 'total_batches' in dl_stats, 'Missing total_batches'
assert dl_stats['total_batches'] == 5, f'Expected 5 batches, got {dl_stats[\"total_batches\"]}'

# Get throughput
throughput = monitor.get_throughput()
assert 'sequences_per_sec' in throughput, 'Missing sequences_per_sec'
assert throughput['total_sequences'] == 160, f'Expected 160 seqs, got {throughput[\"total_sequences\"]}'

print(f'GPU monitor DataLoader tracking test passed')
print(f'  Avg wait: {dl_stats[\"avg_wait_time_ms\"]:.1f}ms')
print(f'  Throughput: {throughput[\"sequences_per_sec\"]:.0f} seqs/sec')
"
```
  </verify>
  <done>NvitopMonitor tracks DataLoader wait times, queue depths, bottleneck detection, and throughput metrics</done>
</task>

</tasks>

<verification>
All tasks complete when:
1. `DataLoaderMetrics` dataclass exists with wait_time_ms, queue_depth fields
2. `NvitopMonitor.record_dataloader_wait()` accepts wait time and batch metadata
3. `NvitopMonitor.check_bottleneck()` warns when GPU idle >10%
4. `NvitopMonitor.get_dataloader_statistics()` returns aggregated metrics
5. `NvitopMonitor.get_throughput()` returns sequences/sec
</verification>

<success_criteria>
- DataLoaderMetrics dataclass captures per-batch timing
- record_dataloader_wait() stores metrics and logs every 10 batches
- check_bottleneck() detects when GPU utilization drops below 90%
- get_dataloader_statistics() returns avg/max/p95 wait times
- get_throughput() returns sequences/sec based on timer
</success_criteria>

<output>
After completion, create `.planning/phases/05-async-dataloader-foundation/05-02-SUMMARY.md`
</output>
