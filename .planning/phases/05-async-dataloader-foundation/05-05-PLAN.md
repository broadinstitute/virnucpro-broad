---
phase: 05-async-dataloader-foundation
plan: 05
type: execute
wave: 4
depends_on:
  - "05-01"
  - "05-02"
  - "05-03"
  - "05-04"
files_modified:
  - tests/test_async_dataloader.py
autonomous: false

must_haves:
  truths:
    - "Workers have no CUDA access (validation passes in worker processes)"
    - "Prefetched batches arrive before GPU finishes previous batch"
    - "Output embeddings are valid (correct shape, reasonable values)"
    - "GPU utilization tracked during inference"
    - "End-to-end pipeline produces embeddings from FASTA input"
  artifacts:
    - path: "tests/test_async_dataloader.py"
      provides: "Integration tests for async DataLoader pipeline"
      min_lines: 100
  key_links:
    - from: "tests/test_async_dataloader.py"
      to: "virnucpro/data/sequence_dataset.py"
      via: "SequenceDataset instantiation"
      pattern: "SequenceDataset"
    - from: "tests/test_async_dataloader.py"
      to: "virnucpro/pipeline/async_inference.py"
      via: "AsyncInferenceRunner usage"
      pattern: "AsyncInferenceRunner"
---

<objective>
Create integration tests validating the async DataLoader pipeline end-to-end.

Purpose: Verify that CUDA safety, prefetching, and inference correctness work together. These tests validate the Phase 5 success criteria: workers don't touch CUDA, GPU receives prefetched batches, and output embeddings match expected format.

Output:
- `tests/test_async_dataloader.py`: Integration tests for async pipeline
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-async-dataloader-foundation/05-CONTEXT.md

# Prior plan outputs
@.planning/phases/05-async-dataloader-foundation/05-01-SUMMARY.md
@.planning/phases/05-async-dataloader-foundation/05-02-SUMMARY.md
@.planning/phases/05-async-dataloader-foundation/05-03-SUMMARY.md
@.planning/phases/05-async-dataloader-foundation/05-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create integration test file</name>
  <files>tests/test_async_dataloader.py</files>
  <action>
Create `tests/test_async_dataloader.py` with integration tests:

```python
"""Integration tests for async DataLoader pipeline.

These tests validate Phase 5 requirements:
- SAFE-01: Workers don't initialize CUDA
- ARCH-02: Async DataLoader with prefetching
- ARCH-03: Batch prefetching works
- ARCH-04: Pin memory for fast GPU transfer
- ARCH-05: Stream-based I/O overlap

Tests require GPU to run. Skip gracefully if no GPU available.
"""

import pytest
import torch
import tempfile
import os
from pathlib import Path
from typing import List

# Skip all tests if no CUDA available
pytestmark = pytest.mark.skipif(
    not torch.cuda.is_available(),
    reason="CUDA not available"
)


@pytest.fixture
def test_fasta_files() -> List[Path]:
    """Create temporary FASTA files for testing."""
    files = []

    # Create 2 test files with different sequences
    for i in range(2):
        with tempfile.NamedTemporaryFile(
            mode='w', suffix='.fasta', delete=False
        ) as f:
            # Write 10 sequences per file
            for j in range(10):
                seq_id = f"seq_{i}_{j}"
                # Generate random-ish protein sequence
                seq = "MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLSGAEKAVQVKVKALPDAQFEVVHSLAKWKRQQIA"[:50 + j*5]
                f.write(f">{seq_id}\n{seq}\n")
            files.append(Path(f.name))

    yield files

    # Cleanup
    for f in files:
        if f.exists():
            os.unlink(f)


@pytest.fixture
def esm_model_and_converter():
    """Load ESM-2 model and batch converter for testing."""
    import esm

    # Use smaller model for faster tests
    model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()
    batch_converter = alphabet.get_batch_converter()

    device = torch.device('cuda:0')
    model = model.to(device)
    model.eval()

    return model, batch_converter, device


class TestSequenceDataset:
    """Tests for SequenceDataset CUDA safety."""

    def test_dataset_yields_sequences(self, test_fasta_files):
        """Dataset yields sequence dicts from FASTA files."""
        from virnucpro.data import SequenceDataset

        dataset = SequenceDataset(test_fasta_files)
        items = list(dataset)

        # Should have 20 sequences total (10 per file)
        assert len(items) == 20, f"Expected 20 items, got {len(items)}"

        # Check structure
        item = items[0]
        assert 'id' in item, "Missing 'id' key"
        assert 'sequence' in item, "Missing 'sequence' key"
        assert 'file' in item, "Missing 'file' key"

    def test_dataset_respects_max_length(self, test_fasta_files):
        """Dataset truncates sequences to max_length."""
        from virnucpro.data import SequenceDataset

        dataset = SequenceDataset(test_fasta_files, max_length=30)
        items = list(dataset)

        for item in items:
            assert len(item['sequence']) <= 30, \
                f"Sequence too long: {len(item['sequence'])}"


class TestVarlenCollator:
    """Tests for VarlenCollator tokenization."""

    def test_collator_produces_packed_format(self, esm_model_and_converter):
        """Collator produces input_ids and cu_seqlens."""
        from virnucpro.data import VarlenCollator

        _, batch_converter, _ = esm_model_and_converter
        collator = VarlenCollator(batch_converter, max_tokens=500)

        batch = [
            {'id': 'seq1', 'sequence': 'MKTAYIAK', 'file': 'test.fasta'},
            {'id': 'seq2', 'sequence': 'VLSPADKTNV', 'file': 'test.fasta'},
        ]

        result = collator(batch)

        assert 'input_ids' in result
        assert 'cu_seqlens' in result
        assert 'max_seqlen' in result
        assert 'sequence_ids' in result
        assert 'num_sequences' in result

        # Verify types
        assert result['input_ids'].dtype == torch.long
        assert result['cu_seqlens'].dtype == torch.int32

        # cu_seqlens should have num_sequences + 1 elements
        assert len(result['cu_seqlens']) == result['num_sequences'] + 1


class TestAsyncDataLoader:
    """Tests for async DataLoader with CUDA safety."""

    def test_dataloader_prefetches_batches(self, test_fasta_files, esm_model_and_converter):
        """DataLoader prefetches batches while GPU computes."""
        from virnucpro.data import SequenceDataset, VarlenCollator, create_async_dataloader

        _, batch_converter, _ = esm_model_and_converter

        dataset = SequenceDataset(test_fasta_files)
        collator = VarlenCollator(batch_converter, max_tokens=500)

        loader = create_async_dataloader(
            dataset,
            collator,
            batch_size=5,
            num_workers=2,
            prefetch_factor=2,
        )

        # Iterate through batches
        batches = list(loader)

        # Should have multiple batches (20 sequences / 5 per batch = ~4)
        assert len(batches) >= 2, f"Expected at least 2 batches, got {len(batches)}"

        # Each batch should have expected structure
        for batch in batches:
            assert 'input_ids' in batch
            assert 'cu_seqlens' in batch

    def test_dataloader_uses_spawn_context(self, test_fasta_files, esm_model_and_converter):
        """DataLoader uses spawn context for CUDA safety."""
        from virnucpro.data import SequenceDataset, VarlenCollator, create_async_dataloader

        _, batch_converter, _ = esm_model_and_converter

        dataset = SequenceDataset(test_fasta_files)
        collator = VarlenCollator(batch_converter)

        loader = create_async_dataloader(
            dataset,
            collator,
            num_workers=2,
        )

        # Access internal multiprocessing context
        # Note: This tests implementation detail but is important for CUDA safety
        assert loader.multiprocessing_context == 'spawn', \
            "DataLoader should use spawn context"


class TestAsyncInference:
    """Tests for AsyncInferenceRunner end-to-end."""

    def test_inference_produces_embeddings(self, test_fasta_files, esm_model_and_converter):
        """Full pipeline produces valid embeddings."""
        from virnucpro.data import SequenceDataset, VarlenCollator, create_async_dataloader
        from virnucpro.pipeline import AsyncInferenceRunner

        model, batch_converter, device = esm_model_and_converter

        dataset = SequenceDataset(test_fasta_files)
        collator = VarlenCollator(batch_converter, max_tokens=500)
        loader = create_async_dataloader(
            dataset,
            collator,
            batch_size=5,
            num_workers=2,
        )

        runner = AsyncInferenceRunner(
            model=model,
            device=device,
            enable_streams=True,
        )

        results = list(runner.run(loader))

        # Should have results
        assert len(results) > 0, "No results produced"

        # Check result structure
        for result in results:
            assert len(result.sequence_ids) > 0, "No sequence IDs"
            assert result.embeddings.shape[0] == len(result.sequence_ids), \
                "Embedding count mismatch"
            # ESM-2 650M has 1280 dim embeddings
            assert result.embeddings.shape[1] == 1280, \
                f"Wrong embedding dim: {result.embeddings.shape[1]}"

    def test_inference_statistics_available(self, test_fasta_files, esm_model_and_converter):
        """Runner provides statistics after inference."""
        from virnucpro.data import SequenceDataset, VarlenCollator, create_async_dataloader
        from virnucpro.pipeline import AsyncInferenceRunner

        model, batch_converter, device = esm_model_and_converter

        dataset = SequenceDataset(test_fasta_files)
        collator = VarlenCollator(batch_converter, max_tokens=500)
        loader = create_async_dataloader(
            dataset,
            collator,
            batch_size=10,
            num_workers=2,
        )

        runner = AsyncInferenceRunner(model=model, device=device)
        list(runner.run(loader))  # Consume iterator

        stats = runner.get_statistics()

        assert 'total_batches' in stats
        assert 'total_sequences' in stats
        assert 'throughput' in stats
        assert stats['total_sequences'] == 20, \
            f"Expected 20 sequences, got {stats['total_sequences']}"


class TestCUDASafety:
    """Tests specifically for CUDA isolation in workers."""

    def test_worker_init_hides_cuda(self):
        """worker_init_fn sets CUDA_VISIBLE_DEVICES=''."""
        from virnucpro.data.dataloader_utils import cuda_safe_worker_init
        import os

        # Save current env
        old_cuda_visible = os.environ.get('CUDA_VISIBLE_DEVICES')
        old_tokenizers = os.environ.get('TOKENIZERS_PARALLELISM')

        try:
            # This would run in worker process
            cuda_safe_worker_init(0)

            assert os.environ.get('CUDA_VISIBLE_DEVICES') == '', \
                "CUDA_VISIBLE_DEVICES not set to empty"
            assert os.environ.get('TOKENIZERS_PARALLELISM') == 'false', \
                "TOKENIZERS_PARALLELISM not disabled"

        finally:
            # Restore env
            if old_cuda_visible is not None:
                os.environ['CUDA_VISIBLE_DEVICES'] = old_cuda_visible
            if old_tokenizers is not None:
                os.environ['TOKENIZERS_PARALLELISM'] = old_tokenizers


if __name__ == '__main__':
    pytest.main([__file__, '-v'])
```
  </action>
  <verify>
```bash
cd /Users/carze/Documents/work/Broad_EMI/projects/virnucpro_broad && python -c "
import ast
with open('tests/test_async_dataloader.py') as f:
    tree = ast.parse(f.read())

# Count test classes and methods
test_classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef) and node.name.startswith('Test')]
test_methods = []
for cls in test_classes:
    for item in cls.body:
        if isinstance(item, ast.FunctionDef) and item.name.startswith('test_'):
            test_methods.append(f'{cls.name}.{item.name}')

print(f'Found {len(test_classes)} test classes with {len(test_methods)} test methods:')
for method in test_methods:
    print(f'  - {method}')
"
```
  </verify>
  <done>Integration test file created with tests for SequenceDataset, VarlenCollator, AsyncDataLoader, AsyncInference, and CUDA safety</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete async DataLoader pipeline with:
1. SequenceDataset: CUDA-safe FASTA streaming
2. VarlenCollator: Packed format tokenization
3. create_async_dataloader: CUDA-safe DataLoader factory
4. AsyncInferenceRunner: Stream-based GPU inference
5. GPU monitoring with DataLoader metrics
6. Integration tests validating end-to-end pipeline
  </what-built>
  <how-to-verify>
Run the integration tests on a GPU machine:

```bash
cd /Users/carze/Documents/work/Broad_EMI/projects/virnucpro_broad

# Run async DataLoader tests
pytest tests/test_async_dataloader.py -v

# Expected: All tests pass (or skip if no GPU)
```

Verify key behaviors:
1. Workers don't have CUDA access (TestCUDASafety.test_worker_init_hides_cuda passes)
2. DataLoader uses spawn context (TestAsyncDataLoader.test_dataloader_uses_spawn_context passes)
3. End-to-end inference produces embeddings (TestAsyncInference.test_inference_produces_embeddings passes)
4. Statistics tracked (TestAsyncInference.test_inference_statistics_available passes)

If no GPU available, tests should skip gracefully (not fail).
  </how-to-verify>
  <resume-signal>Type "approved" if tests pass, or describe failures to address</resume-signal>
</task>

</tasks>

<verification>
All tasks complete when:
1. `tests/test_async_dataloader.py` exists with 10+ test methods
2. Tests cover: SequenceDataset, VarlenCollator, DataLoader, AsyncInference, CUDA safety
3. Tests pass on GPU machine (or skip gracefully without GPU)
4. Human verification confirms end-to-end pipeline works
</verification>

<success_criteria>
- Integration tests validate all Phase 5 requirements
- CUDA safety tested: workers have no GPU access
- Prefetching tested: DataLoader produces batches
- Inference tested: embeddings have correct shape (1280 dim for ESM-2 650M)
- Statistics tested: throughput and DataLoader metrics available
- Tests skip gracefully on CPU-only machines
</success_criteria>

<output>
After completion, create `.planning/phases/05-async-dataloader-foundation/05-05-SUMMARY.md`
</output>
