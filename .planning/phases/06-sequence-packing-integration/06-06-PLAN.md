---
phase: 06-sequence-packing-integration
plan: 06
type: execute
wave: 4
depends_on: ["06-04"]
files_modified:
  - virnucpro/utils/gpu_monitor.py
  - virnucpro/data/packing.py
autonomous: true

must_haves:
  truths:
    - "Packing efficiency metric tracks token utilization percentage"
    - "Periodic logging every N batches with summary stats"
    - "Warning logged when packing efficiency < 85% (Gap 6 - raised from 80%)"
    - "Critical error logged when packing efficiency < 80%"
  artifacts:
    - path: "virnucpro/utils/gpu_monitor.py"
      provides: "Extended packing efficiency metrics"
      contains: "packing_efficiency"
    - path: "virnucpro/data/packing.py"
      provides: "Efficiency calculation and logging utilities"
      exports: ["GreedyPacker", "validate_packed_equivalence", "compute_batch_efficiency"]
  key_links:
    - from: "virnucpro/utils/gpu_monitor.py"
      to: "packing_efficiency"
      via: "DataLoaderMetrics field"
      pattern: "packing_efficiency"
---

<objective>
Add packing efficiency metrics and monitoring

Purpose: Track packing density to ensure >90% token utilization. Log periodic summaries and warn when efficiency drops below threshold. This helps diagnose suboptimal batching configurations.

Output: Packing efficiency tracking in GPU monitor and logging utilities
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-sequence-packing-integration/06-RESEARCH.md
@.planning/phases/06-sequence-packing-integration/06-CONTEXT.md
@virnucpro/utils/gpu_monitor.py
@virnucpro/data/packing.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add compute_batch_efficiency utility</name>
  <files>virnucpro/data/packing.py</files>
  <action>
Add batch efficiency calculation function to packing.py:

```python
def compute_batch_efficiency(
    num_tokens: int,
    num_sequences: int,
    max_seqlen: int,
    max_tokens_per_batch: int,
) -> Dict[str, float]:
    """
    Compute packing efficiency metrics for a batch.

    Args:
        num_tokens: Total tokens in packed batch
        num_sequences: Number of sequences in batch
        max_seqlen: Maximum sequence length in batch
        max_tokens_per_batch: Token budget used for packing

    Returns:
        Dict with:
            - token_utilization: num_tokens / max_tokens_per_batch
            - padding_waste: 1 - (num_tokens / (num_sequences * max_seqlen))
            - avg_sequence_length: num_tokens / num_sequences
            - theoretical_efficiency: num_tokens / max_tokens_per_batch
    """
```

Also add two-tier threshold logging to GreedyPacker.pack_sequences (Gap 6):
```python
efficiency = self.compute_efficiency(batches)

# Two-tier threshold system (Gap 6)
CRITICAL_THRESHOLD = 0.80  # Something is broken
WARN_THRESHOLD = 0.85      # Buffer may be too small

if efficiency < CRITICAL_THRESHOLD:
    logger.error(
        f"CRITICAL: Packing efficiency {efficiency:.1%} < 80%. "
        "Packing may be broken or buffer_size too small."
    )
elif efficiency < WARN_THRESHOLD:
    logger.warning(
        f"Low packing efficiency: {efficiency:.1%} < 85%. "
        "Consider increasing buffer_size (current: {self.buffer_size if hasattr(self, 'buffer_size') else 'N/A'})"
    )
else:
    logger.debug(f"Packing efficiency: {efficiency:.1%}")
```
  </action>
  <verify>
python -c "from virnucpro.data.packing import compute_batch_efficiency; print('Efficiency function imported')"
  </verify>
  <done>
compute_batch_efficiency utility function exists
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend GPU monitor packing metrics</name>
  <files>virnucpro/utils/gpu_monitor.py</files>
  <action>
Extend NvitopMonitor.record_dataloader_wait to track packing efficiency:

Add new parameters to record_dataloader_wait:
```python
def record_dataloader_wait(
    self,
    wait_time_ms: float,
    batch_idx: int,
    sequences_in_batch: int,
    tokens_in_batch: int,
    avg_sequence_length: float,
    max_sequence_length: int,
    packing_efficiency: float = None,  # NEW: Optional packing efficiency
):
```

If packing_efficiency provided:
1. Track in DataLoaderMetrics
2. Compute running average
3. Log warning if below 80%

Add packing efficiency to get_dataloader_statistics() return dict:
```python
{
    ...
    'avg_packing_efficiency': self._avg_packing_efficiency,
    'min_packing_efficiency': self._min_packing_efficiency,
    'batches_below_threshold': self._low_efficiency_count,
}
```
  </action>
  <verify>
grep -n "packing_efficiency" virnucpro/utils/gpu_monitor.py | head -5 && echo "Packing efficiency tracked"
  </verify>
  <done>
GPU monitor tracks packing efficiency with rolling statistics
  </done>
</task>

<task type="auto">
  <name>Task 3: Add periodic efficiency logging</name>
  <files>virnucpro/pipeline/async_inference.py</files>
  <action>
Update AsyncInferenceRunner.run() to compute and log packing efficiency:

In the batch processing loop, compute efficiency:
```python
# Compute packing efficiency for this batch
if 'cu_seqlens' in batch and 'max_seqlen' in batch:
    from virnucpro.data.packing import compute_batch_efficiency
    efficiency_stats = compute_batch_efficiency(
        num_tokens=tokens_in_batch,
        num_sequences=num_sequences,
        max_seqlen=batch['max_seqlen'],
        max_tokens_per_batch=4096  # TODO: Get from collator config
    )
    packing_efficiency = efficiency_stats['token_utilization']
else:
    packing_efficiency = None
```

Pass to monitor.record_dataloader_wait:
```python
self.monitor.record_dataloader_wait(
    ...,
    packing_efficiency=packing_efficiency,
)
```

Add periodic logging (every 100 batches):
```python
if batch_idx % 100 == 0 and batch_idx > 0:
    dl_stats = self.monitor.get_dataloader_statistics()
    logger.info(
        f"Batch {batch_idx}: {dl_stats.get('avg_packing_efficiency', 0):.1%} avg efficiency, "
        f"{dl_stats.get('tokens_per_sec', 0):.0f} tokens/sec"
    )
```
  </action>
  <verify>
grep -n "packing_efficiency" virnucpro/pipeline/async_inference.py | head -5 && echo "Efficiency logging added"
  </verify>
  <done>
Periodic packing efficiency logging in inference loop
  </done>
</task>

</tasks>

<verification>
- [ ] compute_batch_efficiency returns efficiency metrics dict
- [ ] GPU monitor tracks packing_efficiency per batch
- [ ] Running average efficiency computed
- [ ] Warning logged when efficiency < 80%
- [ ] Periodic logging every 100 batches in inference loop
- [ ] get_dataloader_statistics includes packing metrics
</verification>

<success_criteria>
1. Packing efficiency tracked per batch
2. Rolling statistics (avg, min) available from monitor
3. Low efficiency warnings help diagnose batching issues
4. Periodic logging provides runtime visibility
</success_criteria>

<output>
After completion, create `.planning/phases/06-sequence-packing-integration/06-06-SUMMARY.md`
</output>
