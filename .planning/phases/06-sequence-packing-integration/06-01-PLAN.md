---
phase: 06-sequence-packing-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - virnucpro/data/packing.py
  - virnucpro/data/__init__.py
  - tests/unit/test_packing.py
autonomous: true

must_haves:
  truths:
    - "GreedyPacker sorts sequences by length descending (FFD algorithm) - ARCH-11"
    - "Sequences exceeding max_length are truncated with warning"
    - "Packing efficiency >90% for typical viral sequence datasets"
    - "Deterministic tie-breaking by sequence ID"
    - "calculate_token_budget computes budget from GPU memory - PACK-03"
  artifacts:
    - path: "virnucpro/data/packing.py"
      provides: "GreedyPacker class with FFD algorithm and dynamic budget calculation"
      exports: ["GreedyPacker", "calculate_token_budget"]
    - path: "virnucpro/data/__init__.py"
      provides: "Export GreedyPacker and calculate_token_budget"
      contains: "GreedyPacker"
  key_links:
    - from: "virnucpro/data/packing.py"
      to: "logging"
      via: "logger.warning for truncation"
      pattern: "logger\\.warning.*truncat"
    - from: "virnucpro/data/packing.py"
      to: "torch.cuda"
      via: "GPU memory query for token budget"
      pattern: "torch\\.cuda\\.get_device_properties"
---

<objective>
Implement First-Fit Decreasing (FFD) packing algorithm and dynamic token budget calculation

Purpose: Pack variable-length sequences into token-budget batches to maximize GPU utilization. FFD achieves ~90-95% packing efficiency by placing longest sequences first (ARCH-11), then filling gaps with shorter sequences. Dynamic token budget (PACK-03) adapts to available GPU memory.

Output: GreedyPacker class and calculate_token_budget function in virnucpro/data/packing.py
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-sequence-packing-integration/06-RESEARCH.md
@.planning/phases/06-sequence-packing-integration/06-CONTEXT.md
@virnucpro/data/collators.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GreedyPacker with FFD algorithm (ARCH-11)</name>
  <files>virnucpro/data/packing.py</files>
  <action>
Create virnucpro/data/packing.py with GreedyPacker class implementing First-Fit Decreasing:

```python
class GreedyPacker:
    """First-Fit Decreasing packer for sequence batching.

    Implements ARCH-11: Sort sequences by length descending before packing.
    This is critical for greedy bin packing efficiency (~90-95% vs ~70% unsorted).
    """

    def __init__(self, max_tokens_per_batch: int, max_sequence_length: int = 1022):
        """
        Args:
            max_tokens_per_batch: Token budget per batch (e.g., 4096)
            max_sequence_length: Max sequence length before truncation (ESM-2 limit: 1022 aa + 2 special tokens = 1024)
        """
```

Key methods:
1. `pack_sequences(sequences: List[Dict]) -> List[List[Dict]]`:
   - **CRITICAL (ARCH-11):** Sort by length descending FIRST (FFD algorithm)
   - Secondary sort by sequence ID for deterministic tie-breaking
   - Account for +2 tokens (BOS/EOS) per sequence
   - Truncate sequences >max_sequence_length with warning and `truncated=True` flag
   - Return list of batches, each a list of sequence dicts

2. `sort_by_length(sequences: List[Dict]) -> List[Dict]`:
   - **Explicit method for ARCH-11**: Sort sequences by length descending
   - Secondary sort by ID for determinism
   - Returns sorted copy (does not mutate input)

3. `compute_efficiency(batches: List[List[Dict]]) -> float`:
   - Calculate packing efficiency: total_tokens / total_capacity
   - Returns float in range [0.0, 1.0]

4. `_tokenized_length(sequence: str) -> int`:
   - Return len(sequence) + 2 for BOS/EOS tokens

Implementation notes from CONTEXT.md:
- Truncation preserves N-terminal (important for ESM-2 biological signal)
- Log truncation statistics per sequence with sequence ID
- Use logger from logging module, not print statements
  </action>
  <verify>
python -c "from virnucpro.data.packing import GreedyPacker; p = GreedyPacker(4096); print('GreedyPacker imported successfully')"
  </verify>
  <done>
GreedyPacker class exists with pack_sequences (sorts by length - ARCH-11), sort_by_length, and compute_efficiency methods
  </done>
</task>

<task type="auto">
  <name>Task 2: Add dynamic token budget calculation (PACK-03)</name>
  <files>virnucpro/data/packing.py</files>
  <action>
Add calculate_token_budget function to virnucpro/data/packing.py (from RESEARCH.md pattern):

```python
def calculate_token_budget(
    device_id: int = 0,
    model_memory_gb: float = 5.0,
    safety_margin_gb: float = 2.0,
    bytes_per_token: int = 4096,
    min_tokens: int = 1024,
    max_tokens: int = 16384,
) -> int:
    """
    Calculate token budget based on available GPU memory (PACK-03).

    Uses torch.cuda.get_device_properties to query total GPU memory,
    then estimates available memory for batching after reserving space
    for model weights and safety margin.

    Args:
        device_id: CUDA device index
        model_memory_gb: Estimated model memory usage in GB (ESM-2 3B ~5GB)
        safety_margin_gb: Reserved memory for CUDA overhead and activations
        bytes_per_token: Estimated bytes per token for intermediate activations
            ESM-2 3B: ~4KB per token with attention overhead
        min_tokens: Minimum token budget (floor)
        max_tokens: Maximum token budget (ceiling)

    Returns:
        Maximum tokens per batch, clamped to [min_tokens, max_tokens]

    Example:
        >>> budget = calculate_token_budget(device_id=0, model_memory_gb=5.0)
        >>> print(f"Token budget: {budget}")
        Token budget: 8192
    """
    import torch

    if not torch.cuda.is_available():
        logger.warning("CUDA not available, using default token budget")
        return 4096

    props = torch.cuda.get_device_properties(device_id)
    total_memory_gb = props.total_memory / (1024**3)

    # Available memory = total - model - safety margin
    available_memory_gb = total_memory_gb - model_memory_gb - safety_margin_gb
    available_memory_gb = max(0.5, available_memory_gb)  # Minimum 0.5GB

    # Calculate token budget
    max_tokens_calculated = int((available_memory_gb * 1024**3) / bytes_per_token)

    # Clamp to reasonable range
    token_budget = max(min_tokens, min(max_tokens_calculated, max_tokens))

    logger.info(
        f"Token budget: {token_budget} (GPU {device_id}: "
        f"{total_memory_gb:.1f}GB total, {available_memory_gb:.1f}GB available)"
    )

    return token_budget
```

This enables dynamic batch sizing based on actual GPU memory rather than hardcoded 4096.
  </action>
  <verify>
python -c "from virnucpro.data.packing import calculate_token_budget; print(f'calculate_token_budget imported: {calculate_token_budget}')"
  </verify>
  <done>
calculate_token_budget function exists and computes budget from GPU memory (PACK-03)
  </done>
</task>

<task type="auto">
  <name>Task 3: Update data module exports and add unit tests</name>
  <files>virnucpro/data/__init__.py, tests/unit/test_packing.py</files>
  <action>
**Part A: Update virnucpro/data/__init__.py exports:**

1. Add imports: `from virnucpro.data.packing import GreedyPacker, calculate_token_budget`
2. Add to `__all__` list if it exists
3. Keep existing exports (SequenceDataset, VarlenCollator, create_async_dataloader)

**Part B: Create tests/unit/test_packing.py with pytest tests:**

1. `test_ffd_sorting`: Verify sequences sorted by length descending (ARCH-11)
2. `test_sort_by_length`: Explicit test for sort_by_length method
3. `test_deterministic_tiebreaking`: Same-length sequences sorted by ID
4. `test_token_budget_respected`: Batches don't exceed max_tokens_per_batch
5. `test_truncation_warning`: Oversized sequences truncated with warning
6. `test_efficiency_calculation`: Efficiency computed correctly
7. `test_bos_eos_accounting`: +2 tokens per sequence accounted for
8. `test_calculate_token_budget_no_cuda`: Test fallback when CUDA unavailable

Test data:
```python
sequences = [
    {'id': 'short1', 'sequence': 'MKTAY'},         # 5 aa = 7 tokens
    {'id': 'medium1', 'sequence': 'MKTAYIAKQR'},  # 10 aa = 12 tokens
    {'id': 'long1', 'sequence': 'M' * 50},        # 50 aa = 52 tokens
]
```

Use pytest.mark.parametrize for edge cases (empty list, single sequence, exact budget).
  </action>
  <verify>
python -c "from virnucpro.data import GreedyPacker, calculate_token_budget; print('Exports work')" && \
pytest tests/unit/test_packing.py -v --tb=short 2>/dev/null || echo "Tests created (will run in integration)"
  </verify>
  <done>
GreedyPacker and calculate_token_budget importable from virnucpro.data; unit tests exist
  </done>
</task>

</tasks>

<verification>
- [ ] GreedyPacker class exists in virnucpro/data/packing.py
- [ ] pack_sequences sorts by length descending FIRST (ARCH-11)
- [ ] sort_by_length method exists for explicit length sorting
- [ ] Truncation adds 'truncated': True flag and logs warning
- [ ] compute_efficiency returns float in [0.0, 1.0]
- [ ] calculate_token_budget uses torch.cuda.get_device_properties (PACK-03)
- [ ] calculate_token_budget returns fallback 4096 when CUDA unavailable
- [ ] GreedyPacker and calculate_token_budget importable from virnucpro.data
- [ ] Unit tests cover FFD sorting, truncation, efficiency, token budget
</verification>

<success_criteria>
1. GreedyPacker packs sequences with FFD algorithm (longest first) - ARCH-11
2. calculate_token_budget computes budget from GPU memory - PACK-03
3. Truncation preserves N-terminal with warning log
4. Packing efficiency calculation works correctly
5. All exports work from virnucpro.data
</success_criteria>

<output>
After completion, create `.planning/phases/06-sequence-packing-integration/06-01-SUMMARY.md`
</output>
