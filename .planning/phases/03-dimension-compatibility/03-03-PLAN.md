---
phase: 03-dimension-compatibility
plan: 03
type: execute
wave: 3
depends_on: ["03-01", "03-02"]
files_modified:
  - scripts/test_dimension_compatibility.py
autonomous: true

must_haves:
  truths:
    - "Test script validates all 5 DIM requirements (DIM-01 through DIM-05)"
    - "merge_data() produces 2048-dim output with correct inputs"
    - "merge_data() rejects old 2560-dim protein embeddings with DimensionError"
    - "MLPClassifier accepts 2048-dim input and rejects 3328-dim input"
    - "Checkpoint with version 2.0.0 metadata can be saved and loaded"
    - "Old checkpoints (no metadata, version 1.x) are rejected with clear migration message"
    - "VALIDATE_DIMS toggle controls optional checks"
  artifacts:
    - path: "scripts/test_dimension_compatibility.py"
      provides: "Comprehensive test validating all DIM-01 through DIM-05 requirements"
      min_lines: 100
  key_links:
    - from: "scripts/test_dimension_compatibility.py"
      to: "units.py:merge_data()"
      via: "test function calls"
      pattern: "merge_data"
    - from: "scripts/test_dimension_compatibility.py"
      to: "units.py:DimensionError"
      via: "catches expected exceptions"
      pattern: "DimensionError"
    - from: "scripts/test_dimension_compatibility.py"
      to: "prediction.py:load_checkpoint_with_validation()"
      via: "test function calls"
      pattern: "load_checkpoint_with_validation"
---

<objective>
Create comprehensive integration test that validates all DIM-01 through DIM-05 requirements end-to-end, confirming the dimension compatibility migration is complete and correct.

Purpose: Without an integration test, individual changes might work in isolation but fail when combined. This test proves the entire pipeline handles the dimension change correctly and catches regressions.

Output: scripts/test_dimension_compatibility.py - standalone test script that validates all dimension compatibility requirements.
</objective>

<execution_context>
@/home/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-dimension-compatibility/03-CONTEXT.md
@.planning/phases/03-dimension-compatibility/03-01-SUMMARY.md
@.planning/phases/03-dimension-compatibility/03-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create dimension compatibility integration test script</name>
  <files>scripts/test_dimension_compatibility.py</files>
  <action>
Create scripts/test_dimension_compatibility.py following the same pattern as the existing scripts/test_extraction.py (standalone test script with numbered checks, exit code 0 on all pass, exit code 1 on any failure).

The test must validate all 5 DIM requirements WITHOUT requiring GPU, model loading, or data files. All tests use synthetic tensors.

**Test checks (numbered):**

1. **DIM-01: merge_data() produces 2048-dim output**
   - Create synthetic DNABERT-S data: {'nucleotide': ['seq1', 'seq2'], 'data': [{'mean_representation': torch.randn(768).tolist()}, {'mean_representation': torch.randn(768).tolist()}]}
   - Create synthetic protein data: {'proteins': ['seq1', 'seq2'], 'data': [torch.randn(1280), torch.randn(1280)]}
   - Save both to temp .pt files
   - Call merge_data() with data_type='viral'
   - Load result, verify data shape is (2, 2048)
   - Verify labels is [1] (viral)

2. **DIM-02a: Dimension validation catches wrong protein dims**
   - Create protein data with 2560-dim embeddings (old ESM2 3B)
   - Call merge_data() and expect DimensionError
   - Verify error message includes expected (1280) and actual (2560) dims

3. **DIM-02b: Dimension validation catches wrong DNA dims**
   - Create DNA data with 384-dim embeddings (wrong size)
   - Call merge_data() and expect DimensionError
   - Verify error includes expected (768) and actual (384)

4. **DIM-02c: VALIDATE_DIMS toggle**
   - Import VALIDATE_DIMS from units
   - Verify it defaults to True
   - Verify validate_protein_embeddings() runs when True
   - Test that validate_protein_embeddings() catches wrong-dim embeddings

5. **DIM-03: MLPClassifier uses correct input dim**
   - Import MLPClassifier from train (may need try/except due to module-level code)
   - If import fails, read train.py and verify `input_dim = MERGED_DIM` by string search
   - If import succeeds: create MLPClassifier(2048, 512, 2), verify forward pass with torch.randn(4, 2048) works
   - Verify forward pass with torch.randn(4, 3328) raises DimensionError

6. **DIM-04: Checkpoint metadata format**
   - Import save_checkpoint_with_metadata from train (try/except for module-level code)
   - If import fails, read train.py and verify function exists with correct metadata keys by string search
   - If import succeeds: create model, call save_checkpoint_with_metadata, load result, verify metadata contains: checkpoint_version='2.0.0', model_type='fastesm650', dna_dim=768, protein_dim=1280, merged_dim=2048, input_dim=2048, training_date (string), huggingface_model_id

7. **DIM-05a: Reject checkpoint with no metadata**
   - Import load_checkpoint_with_validation from prediction (try/except for module-level code)
   - If import fails, read prediction.py and verify function exists by string search
   - If import succeeds: save checkpoint without metadata key, attempt load, expect ValueError containing "ESM2 3B"

8. **DIM-05b: Reject checkpoint with version 1.x**
   - Save checkpoint with metadata={'checkpoint_version': '1.0.0', 'merged_dim': 3328}
   - Attempt load_checkpoint_with_validation, expect ValueError containing "2560-dim"

9. **DIM-05c: Accept valid v2.0.0 checkpoint**
   - Save checkpoint with full v2.0.0 metadata (including model_state_dict from a small MLPClassifier)
   - Load with load_checkpoint_with_validation, verify success
   - Verify returned checkpoint has correct metadata

10. **Constants verification**
    - Verify DNA_DIM == 768
    - Verify PROTEIN_DIM == 1280
    - Verify MERGED_DIM == 2048 (== DNA_DIM + PROTEIN_DIM)
    - Verify CHECKPOINT_VERSION == "2.0.0"
    - Verify DimensionError is a subclass of Exception

**Important implementation notes:**
- train.py and prediction.py have module-level execution code that may prevent direct import. Wrap imports in try/except. If import fails, fall back to reading the file and searching for expected patterns (use string search to verify key changes like `input_dim = MERGED_DIM`).
- Use tempfile for all test files, clean up in finally blocks.
- Follow exact pattern from scripts/test_extraction.py: numbered checks, pass/fail tracking, summary at end, exit code.
- Print "[PASS]" or "[FAIL]" for each check.
  </action>
  <verify>
Run the test script: `python scripts/test_dimension_compatibility.py` -- should print all checks as [PASS] and exit with code 0.

If run inside Docker: `docker-compose run --rm virnucpro python scripts/test_dimension_compatibility.py`

All 10 checks should pass, confirming DIM-01 through DIM-05 are fully implemented.
  </verify>
  <done>
Test script validates all 5 DIM requirements with 10 numbered checks. All checks pass. merge_data() produces 2048-dim output (DIM-01). Dimension validation catches mismatches (DIM-02). MLPClassifier uses 2048-dim input (DIM-03). Checkpoint metadata includes version 2.0.0 and dimensions (DIM-04). Old checkpoints rejected with migration message (DIM-05). Script exits with code 0.
  </done>
</task>

</tasks>

<verification>
Run `python scripts/test_dimension_compatibility.py` - all 10 checks pass with exit code 0.
</verification>

<success_criteria>
- scripts/test_dimension_compatibility.py exists and is executable
- All 10 checks pass validating DIM-01 through DIM-05
- Test works without GPU, model loading, or data files (uses synthetic data)
- Exit code 0 on all pass, exit code 1 on any failure
- Phase 3 dimension compatibility fully validated
</success_criteria>

<output>
After completion, create `.planning/phases/03-dimension-compatibility/03-03-SUMMARY.md`
</output>
