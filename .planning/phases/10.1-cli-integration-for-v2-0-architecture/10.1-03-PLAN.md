---
phase: 10.1-cli-integration
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - virnucpro/pipeline/prediction.py
  - tests/unit/test_cli_predict.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "HDF5-to-PT conversion logs elapsed time and sequence count for telemetry"
    - "v1.0 fallback path logs ESM-2 stage timing for baseline comparison"
    - "Regression test asserts HDF5-to-PT conversion completes within 5 seconds for 1000 sequences"
  artifacts:
    - path: "virnucpro/pipeline/prediction.py"
      provides: "Telemetry timing around _stream_h5_to_pt_files and v1.0 ESM-2 stage"
      contains: "conversion_elapsed"
    - path: "tests/unit/test_cli_predict.py"
      provides: "Regression test for HDF5-to-PT conversion overhead"
      contains: "test_h5_to_pt_conversion"
  key_links:
    - from: "virnucpro/pipeline/prediction.py"
      to: "_stream_h5_to_pt_files"
      via: "time.monotonic() wrapping conversion call in Stage 6 v2.0 branch"
      pattern: "conversion_elapsed"
    - from: "virnucpro/pipeline/prediction.py"
      to: "v1.0 ESM-2 stage"
      via: "time.monotonic() wrapping v1.0 protein feature extraction"
      pattern: "esm_v1_elapsed"
---

<objective>
Close 3 high-priority gaps from Phase 10.1 verification that affect Phase 10 benchmarks:

1. **Gap 1 (HDF5->PT conversion overhead):** Add telemetry timing around `_stream_h5_to_pt_files()` to measure the 30-60s conversion tax on 6M sequences. Log elapsed time and sequence count so Phase 10 can evaluate if >5% of runtime.
2. **Gap 2 (Missing v1.0 telemetry):** Add timing around the v1.0 ESM-2 fallback path so Phase 10 Plan 05 (v1.0 vs v2.0 comparison) has baseline metrics.
3. **Gap 3 (No conversion regression test):** Add a unit test that exercises `_stream_h5_to_pt_files()` with mock HDF5 data and asserts it completes within a reasonable time threshold.

Purpose: Without these telemetry additions, Phase 10 benchmarks cannot fairly compare v1.0 vs v2.0, and the conversion overhead cannot be measured or regression-tested.

Output: Updated `virnucpro/pipeline/prediction.py` with timing telemetry, updated `tests/unit/test_cli_predict.py` with conversion regression test.
</objective>

<execution_context>
@/home/unix/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/unix/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10.1-cli-integration-for-v2-0-architecture/10.1-01-SUMMARY.md
@virnucpro/pipeline/prediction.py
@tests/unit/test_cli_predict.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add telemetry timing for HDF5-to-PT conversion and v1.0 ESM-2 baseline</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
Add timing telemetry to measure conversion overhead and v1.0 baseline in `virnucpro/pipeline/prediction.py`.

### Part A: Time the HDF5-to-PT conversion (Gap 1)

In the Stage 6 v2.0 branch (around line 670-677 where `_stream_h5_to_pt_files` is called), wrap the conversion call with timing:

```python
# Convert v2.0 HDF5 output to v1.0 per-file .pt format for merge stage compatibility
# Uses streaming approach to avoid loading entire HDF5 into memory (Issue 2)
conversion_start = time.monotonic()
protein_feature_files = _stream_h5_to_pt_files(
    esm_output_path, protein_split_dir, nucleotide_feature_files
)
conversion_elapsed = time.monotonic() - conversion_start
failed_files = []  # No failures (we fail-fast above)

logger.info(f"v2.0 ESM-2 complete: {len(protein_feature_files)} feature files created")
logger.info(
    f"HDF5-to-PT conversion: {conversion_elapsed:.1f}s for "
    f"{len(protein_feature_files)} files"
)
if conversion_elapsed > 60:
    logger.warning(
        f"HDF5-to-PT conversion took {conversion_elapsed:.1f}s - "
        f"consider Phase 10.2 merge stage HDF5 refactor"
    )
```

The `time` module is already imported at the top of prediction.py (line 7). No new imports needed.

### Part B: Time the v1.0 ESM-2 fallback stage (Gap 2)

In the Stage 6 `else` branch (the v1.0 ESM-2 code, starting around line 678-679), wrap the entire v1.0 protein feature extraction with timing. Add at the start of the else block:

```python
esm_v1_start = time.monotonic()
```

And after the v1.0 protein feature extraction loop completes (after the existing `protein_feature_files` and `failed_files` are populated, at the end of the v1.0 block before Stage 6 checkpoint save):

```python
esm_v1_elapsed = time.monotonic() - esm_v1_start
logger.info(
    f"v1.0 ESM-2 complete: {len(protein_feature_files)} files in {esm_v1_elapsed:.1f}s"
)
```

This provides the baseline timing that Phase 10 Plan 05 needs for v1.0 vs v2.0 comparison.

**Important:** Do NOT modify the v1.0 logic itself. Only add timing statements around the existing code.
  </action>
  <verify>
    grep -n "conversion_elapsed\|esm_v1_elapsed\|esm_v1_start\|conversion_start" virnucpro/pipeline/prediction.py
    python -c "from virnucpro.pipeline.prediction import run_prediction; print('imports OK')"
  </verify>
  <done>
    `prediction.py` logs HDF5-to-PT conversion time with warning if >60s. v1.0 ESM-2 fallback logs elapsed time for baseline comparison. Both use `time.monotonic()` for accurate wall-clock timing. No business logic changes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add HDF5-to-PT conversion regression test</name>
  <files>tests/unit/test_cli_predict.py</files>
  <action>
Add a regression test for `_stream_h5_to_pt_files()` to `tests/unit/test_cli_predict.py`.

Add the following test at the end of the file:

```python
def test_h5_to_pt_conversion_performance(tmp_path):
    """Regression test: HDF5-to-PT conversion completes within 5s for 1000 sequences.

    Exercises _stream_h5_to_pt_files with mock HDF5 data to ensure conversion
    overhead stays within acceptable bounds. This prevents the conversion adapter
    from becoming a bottleneck that erodes v2.0 speedup gains.

    Gap 3: No conversion overhead regression test.
    """
    import time
    import numpy as np
    import torch

    # Create mock HDF5 file with 1000 sequences
    try:
        import h5py
    except ImportError:
        pytest.skip("h5py not available")

    h5_path = tmp_path / "embeddings.h5"
    num_sequences = 1000
    embedding_dim = 2560  # ESM-2 3B hidden dim

    # Create mock sequence IDs and embeddings
    seq_ids = [f"seq_{i}" for i in range(num_sequences)]
    embeddings = np.random.randn(num_sequences, embedding_dim).astype(np.float32)

    with h5py.File(h5_path, 'w') as f:
        f.create_dataset('sequence_ids', data=[s.encode() for s in seq_ids])
        f.create_dataset('embeddings', data=embeddings)

    # Create mock nucleotide .pt files (split sequences across 10 files)
    nuc_dir = tmp_path / "nuc_features"
    nuc_dir.mkdir()
    nuc_files = []
    seqs_per_file = num_sequences // 10

    for file_idx in range(10):
        start = file_idx * seqs_per_file
        end = start + seqs_per_file
        nuc_data = {seq_ids[i]: torch.randn(embedding_dim) for i in range(start, end)}
        nuc_path = nuc_dir / f"output_{file_idx}_DNABERT_S.pt"
        torch.save(nuc_data, nuc_path)
        nuc_files.append(nuc_path)

    # Import and time the conversion
    from virnucpro.pipeline.prediction import _stream_h5_to_pt_files

    output_dir = tmp_path / "esm_output"
    start_time = time.monotonic()
    pt_files = _stream_h5_to_pt_files(h5_path, output_dir, nuc_files)
    elapsed = time.monotonic() - start_time

    # Assertions
    assert len(pt_files) == 10, f"Expected 10 .pt files, got {len(pt_files)}"

    # Verify all sequences were converted
    total_seqs = 0
    for pt_file in pt_files:
        data = torch.load(pt_file, weights_only=False)
        total_seqs += len(data)
    assert total_seqs == num_sequences, f"Expected {num_sequences} sequences, got {total_seqs}"

    # Verify file naming convention (DNABERT_S -> ESM)
    for pt_file in pt_files:
        assert "_ESM.pt" in pt_file.name, f"Expected _ESM.pt suffix, got {pt_file.name}"
        assert "_DNABERT_S.pt" not in pt_file.name, f"Unexpected _DNABERT_S.pt in {pt_file.name}"

    # Performance regression: must complete within 5 seconds for 1000 sequences
    # Production workloads (6M sequences) scale linearly, so 5s for 1K implies ~30s for 6M
    assert elapsed < 5.0, (
        f"HDF5-to-PT conversion took {elapsed:.2f}s for {num_sequences} sequences "
        f"(threshold: 5.0s). Investigate performance regression."
    )
```

**Note on imports:** `numpy` and `h5py` are imported inside the test function to handle optional dependencies. `torch` is already available since it's used by the project. The test gracefully skips if `h5py` is not installed.

**Note on threshold:** 5 seconds for 1000 sequences is generous (actual should be <1s). The threshold catches regressions like accidentally loading entire HDF5 into memory or O(n^2) lookups, without being so tight that normal variance causes flaky tests.
  </action>
  <verify>
    pytest tests/unit/test_cli_predict.py::test_h5_to_pt_conversion_performance -v --tb=short 2>&1 | tail -10
  </verify>
  <done>
    Regression test creates 1000 mock sequences in HDF5 format, converts via `_stream_h5_to_pt_files()`, asserts: 10 output files created, all 1000 sequences present, correct naming convention (_ESM.pt), completes within 5 seconds. Test runs without GPU.
  </done>
</task>

</tasks>

<verification>
- `grep -n "conversion_elapsed\|esm_v1_elapsed" virnucpro/pipeline/prediction.py` shows telemetry timing in both v2.0 and v1.0 paths
- `pytest tests/unit/test_cli_predict.py -v --tb=short` all existing + new test pass
- `pytest tests/unit/test_cli_predict.py::test_h5_to_pt_conversion_performance -v` regression test passes within 5s threshold
- `python -c "from virnucpro.pipeline.prediction import run_prediction; print('OK')"` imports clean
</verification>

<success_criteria>
HDF5-to-PT conversion logs elapsed time with warning if >60s. v1.0 ESM-2 fallback logs elapsed time for baseline comparison. Regression test validates _stream_h5_to_pt_files performance (1000 sequences, 10 files, <5s, correct naming). All existing tests still pass.
</success_criteria>

<output>
After completion, create `.planning/phases/10.1-cli-integration-for-v2-0-architecture/10.1-03-SUMMARY.md`
</output>
