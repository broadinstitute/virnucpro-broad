---
phase: 01-esm-2-multi-gpu-foundation
plan: 03
type: execute
wave: 2
depends_on: ["01-01", "01-02"]
files_modified:
  - virnucpro/pipeline/prediction.py
  - virnucpro/cli/predict.py
  - tests/test_parallel_esm.py
  - tests/test_work_queue.py
autonomous: true

must_haves:
  truths:
    - "Pipeline automatically uses all available GPUs for ESM-2"
    - "Single-GPU fallback works transparently"
    - "Failed files are logged to failed_files.txt"
  artifacts:
    - path: "virnucpro/pipeline/prediction.py"
      provides: "Multi-GPU ESM-2 integration"
      contains: "parallel_esm.*process_esm"
    - path: "virnucpro/cli/predict.py"
      provides: "CLI GPU configuration"
      contains: "--gpus.*--batch-size"
    - path: "tests/test_parallel_esm.py"
      provides: "ESM-2 worker tests"
      min_lines: 50
    - path: "tests/test_work_queue.py"
      provides: "Queue manager tests"
      min_lines: 40
  key_links:
    - from: "prediction.py"
      to: "parallel_esm.py"
      via: "import and call process_esm_files"
      pattern: "from.*parallel_esm import"
    - from: "prediction.py"
      to: "work_queue.BatchQueueManager"
      via: "Queue manager for coordination"
      pattern: "BatchQueueManager.*process_files"
---

<objective>
Integrate multi-GPU ESM-2 processing into the main pipeline with CLI support and comprehensive testing.

Purpose: Wire the parallel ESM-2 infrastructure into the prediction pipeline, add CLI flags for GPU control, and ensure robust testing.
Output: Modified pipeline that automatically parallelizes ESM-2, CLI options for GPU configuration, and test coverage.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-esm-2-multi-gpu-foundation/01-01-SUMMARY.md
@.planning/phases/01-esm-2-multi-gpu-foundation/01-02-SUMMARY.md
@virnucpro/pipeline/prediction.py
@virnucpro/cli/predict.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate multi-GPU ESM-2 into pipeline</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Modify the prediction pipeline to use parallel ESM-2 processing:

    1. Add imports at top:
       ```python
       from virnucpro.pipeline.parallel_esm import assign_files_by_size, process_esm_files_worker
       from virnucpro.pipeline.work_queue import BatchQueueManager
       from virnucpro.pipeline.dashboard import MultiGPUDashboard
       from virnucpro.pipeline.gpu_monitor import GPUMonitor, check_bf16_support
       ```

    2. In the ESM-2 processing section (around where it processes protein files):
       - Detect available GPUs:
         ```python
         cuda_devices = detect_cuda_devices()  # from parallel.py
         num_gpus = len(cuda_devices) if cuda_devices else 1
         use_parallel = num_gpus > 1 and len(protein_files) > 1
         ```

       - If parallel processing:
         ```python
         if use_parallel:
             logger.info(f"Using {num_gpus} GPUs for ESM-2 extraction")

             # Assign files based on sequence count
             file_assignments = assign_files_by_size(protein_files, num_gpus)

             # Create dashboard if not in quiet mode
             if not quiet:
                 dashboard = MultiGPUDashboard(num_gpus, {i: len(files) for i, files in enumerate(file_assignments)})
                 dashboard.start()

             # Process with queue manager
             queue_manager = BatchQueueManager(num_gpus, process_esm_files_worker)
             processed, failed = queue_manager.process_files(
                 file_assignments,
                 toks_per_batch=toks_per_batch,
                 output_dir=output_dir
             )

             if dashboard:
                 dashboard.complete_all()

             # Log failures
             if failed:
                 failed_file_path = output_dir / "failed_files.txt"
                 with open(failed_file_path, 'w') as f:
                     for file_path, error in failed:
                         f.write(f"{file_path}|ESM-2|{error}\n")
                 logger.warning(f"Failed to process {len(failed)} files, see {failed_file_path}")
         ```

       - Fallback to single GPU:
         ```python
         else:
             logger.info("Using single GPU for ESM-2 extraction")
             device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
             for protein_file in protein_files:
                 output_file = output_dir / f"{protein_file.stem}_ESM.pt"
                 extract_esm_features(protein_file, output_file, device, toks_per_batch=toks_per_batch)
         ```

    3. Add exit code handling:
       - Return 0 for complete success
       - Return 2 for partial success (some files failed)
       - Return 1 for total failure

    Ensure backward compatibility - single GPU systems should work without changes.
    Follow existing checkpoint patterns in the pipeline.
  </action>
  <verify>grep -n "parallel_esm" virnucpro/pipeline/prediction.py</verify>
  <done>Pipeline integrates parallel ESM-2 processing with fallback</done>
</task>

<task type="auto">
  <name>Task 2: Add CLI options for GPU configuration</name>
  <files>virnucpro/cli/predict.py</files>
  <action>
    Add command-line options for GPU control and batch size configuration:

    1. Add new Click options to the predict command (after existing options):
       ```python
       @click.option(
           '--gpus',
           type=str,
           default=None,
           help='Comma-separated GPU IDs to use (e.g., "0,1,2"). Overrides CUDA_VISIBLE_DEVICES.'
       )
       @click.option(
           '--batch-size',
           type=int,
           default=None,
           help='Batch size for ESM-2 processing. Reduce if encountering OOM errors.'
       )
       @click.option(
           '--verbose/--quiet',
           default=True,
           help='Show/hide progress dashboard and detailed logs.'
       )
       ```

    2. In the predict function, handle GPU selection:
       ```python
       def predict(input_file, output_dir, config_file, gpus, batch_size, verbose, ...):
           # Handle GPU selection
           if gpus:
               import os
               os.environ['CUDA_VISIBLE_DEVICES'] = gpus
               logger.info(f"Using GPUs: {gpus}")

           # Pass batch_size to pipeline if provided
           pipeline_kwargs = {}
           if batch_size:
               pipeline_kwargs['toks_per_batch'] = batch_size
               logger.info(f"Using batch size: {batch_size}")

           # Pass verbose flag for dashboard control
           pipeline_kwargs['quiet'] = not verbose
       ```

    3. Pass the kwargs to the main pipeline function call

    Ensure --gpus flag overrides environment variable as documented.
    Maintain backward compatibility - all new options are optional.
  </action>
  <verify>python -m virnucpro predict --help | grep -E "(gpus|batch-size|verbose)"</verify>
  <done>CLI has new options for GPU configuration and batch size</done>
</task>

<task type="auto">
  <name>Task 3: Create tests for parallel ESM-2 and queue manager</name>
  <files>tests/test_parallel_esm.py tests/test_work_queue.py</files>
  <action>
    Create comprehensive tests for the new parallel processing components:

    **tests/test_parallel_esm.py:**
    1. Import unittest, pathlib, tempfile, torch, and modules to test

    2. TestAssignFilesBySize class:
       - test_empty_files(): Test with empty file list
       - test_single_worker(): All files go to one worker
       - test_balanced_assignment(): Files distributed evenly
       - test_size_aware_assignment(): Mock varying sequence counts

    3. TestESMWorker class:
       - setUp(): Create temp directory and mock files
       - test_worker_cuda_initialization(): Verify deferred CUDA init
       - test_worker_processes_files(): Mock processing, verify output
       - test_worker_handles_oom(): Simulate OOM, verify recovery
       - tearDown(): Clean up temp files

    4. Use unittest.mock to mock CUDA operations for CI/CD compatibility

    **tests/test_work_queue.py:**
    1. Import unittest, multiprocessing, queue, time, and work_queue module

    2. TestWorkerStatus class:
       - test_enum_values(): Verify all status values exist

    3. TestBatchQueueManager class:
       - test_initialization(): Verify spawn context setup
       - test_process_files(): Mock worker function, verify execution
       - test_failed_file_tracking(): Simulate failures, verify tracking
       - test_systemic_failure_detection(): Test 3+ failure abort

    4. Mock multiprocessing.Pool for deterministic testing

    Follow existing test patterns in the codebase.
    Ensure tests work without GPU (mock CUDA operations).
  </action>
  <verify>python -m pytest tests/test_parallel_esm.py tests/test_work_queue.py -v</verify>
  <done>Tests pass for parallel ESM-2 and queue manager components</done>
</task>

</tasks>

<verification>
- Pipeline detects and uses multiple GPUs automatically
- Single-GPU systems fall back transparently
- CLI provides --gpus and --batch-size options
- Failed files are logged to failed_files.txt
- Tests cover worker functions and queue manager
</verification>

<success_criteria>
- Multi-GPU ESM-2 integrated into main pipeline
- CLI options for GPU and batch size configuration
- Comprehensive test coverage for new components
- Backward compatibility maintained
</success_criteria>

<output>
After completion, create `.planning/phases/01-esm-2-multi-gpu-foundation/01-03-SUMMARY.md`
</output>