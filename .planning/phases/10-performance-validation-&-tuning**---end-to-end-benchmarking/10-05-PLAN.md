---
phase: 10-performance-validation-tuning
plan: 05
type: execute
wave: 3
depends_on: ["10-02", "10-03", "10-04"]
files_modified:
  - tests/benchmarks/test_v1_comparison.py
autonomous: false

must_haves:
  truths:
    - "v1.0 comparison is conditional and skips gracefully if v1.0 tag unavailable"
    - "v2.0 >= 4.5x faster than v1.0 (validates claim)"
    - "10K sequence workload ensures compute time dominates fixed overhead"
    - "Both v1.0 and v2.0 use world_size=1 for fair single-GPU comparison"
    - "v2.0 runs first with cooldown to prevent thermal contamination"
    - "Comparison includes both per-GPU throughput and total pipeline time"
    - "Results document what contributed to speedup (packing, FP16, async DataLoader)"
    - "Human checkpoint includes decision tree for failed requirements"
  artifacts:
    - path: "tests/benchmarks/test_v1_comparison.py"
      provides: "v1.0 vs v2.0 speedup comparison benchmark"
      min_lines: 200
  key_links:
    - from: "tests/benchmarks/test_v1_comparison.py"
      to: "virnucpro.pipeline.multi_gpu_inference"
      via: "run_multi_gpu_inference for v2.0 measurement"
      pattern: "run_multi_gpu_inference"
---

<objective>
Create v1.0 vs v2.0 speedup comparison benchmark to validate the 4.5x speedup claim.

Purpose: This validates the entire v2.0 effort by measuring actual speedup against the v1.0 baseline. The user specifically requested this comparison (CONTEXT.md: "v1.0 comparison important: Want to validate the 4.5x speedup claim with actual measurements"). v1.0 comparison is conditional -- if the v1.0 tag doesn't exist in the repo, tests skip gracefully with clear messages. Both versions run on a single GPU (world_size=1) for apples-to-apples throughput comparison. Uses 10K sequences so compute time dominates model loading overhead. Includes a human verification checkpoint with decision tree for failed requirements.

Output: `tests/benchmarks/test_v1_comparison.py`
</objective>

<execution_context>
@/home/unix/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/unix/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-performance-validation-&-tuning**---end-to-end-benchmarking/10-CONTEXT.md
@.planning/phases/10-performance-validation-&-tuning**---end-to-end-benchmarking/10-02-SUMMARY.md
@.planning/phases/10-performance-validation-&-tuning**---end-to-end-benchmarking/10-03-SUMMARY.md
@.planning/phases/10-performance-validation-&-tuning**---end-to-end-benchmarking/10-04-SUMMARY.md
@virnucpro/pipeline/multi_gpu_inference.py
@virnucpro/pipeline/runtime_config.py
@virnucpro/utils/telemetry.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: v1.0 vs v2.0 speedup comparison benchmark</name>
  <files>tests/benchmarks/test_v1_comparison.py</files>
  <action>
Create `tests/benchmarks/test_v1_comparison.py` with:

Module docstring: "v1.0 vs v2.0 speedup comparison. Validates the 4.5x speedup claim by measuring actual throughput difference between multi-worker-per-GPU (v1.0) and async DataLoader + packing (v2.0) architectures. v1.0 comparison is conditional -- skips gracefully if v1.0 git tag is unavailable. Both versions use world_size=1 for fair single-GPU comparison. Uses 10K sequences to ensure compute time dominates fixed overhead (model loading ~30s)."

Pytest markers: `pytestmark = [pytest.mark.slow, pytest.mark.gpu]`

1. **Helper: check_v1_available**
   - `check_v1_available(worktree_base: Path) -> Tuple[bool, Optional[Path]]`
   - Check if v1.0 git tag exists: run `git tag --list "v1.0"` via subprocess, check if output is non-empty
   - If tag exists: create git worktree at `worktree_base / "v1_worktree"` via `git worktree add <path> v1.0`
   - Return (True, worktree_path) if successful
   - Return (False, None) if tag missing or worktree checkout fails
   - Wrap in try/except to handle git errors gracefully
   - Log clear message about v1.0 availability status

2. **Helper: cleanup_v1_worktree**
   - `cleanup_v1_worktree(worktree_path: Path) -> None`
   - Run `git worktree remove <path> --force` to clean up
   - Called in test teardown to prevent worktree accumulation

3. **Helper: generate_comparison_workload**
   - `generate_comparison_workload(output_dir: Path, num_sequences: int = 10000, seed: int = 42) -> Path`
   - Generates FASTA with protein sequences (varied lengths, same distribution as other tests)
   - 10K sequences ensures compute time (~120s) dominates fixed overhead (model loading ~30s) per Amdahl's Law
   - Returns FASTA path

4. **TestV1Comparison** class (test names use numeric prefixes to force pytest execution order):

   a. **test_1_v2_throughput** (v2.0 benchmark -- runs FIRST to avoid thermal contamination):
   - Skip if not torch.cuda.is_available()
   - Generate 10K sequence workload
   - Run v2.0 pipeline via run_multi_gpu_inference:
     - model_config: model_type='esm2', model_name='esm2_t36_3B_UR50D', enable_fp16=True
     - runtime_config: RuntimeConfig(enable_checkpointing=False)
     - world_size=1 (FORCED single GPU for fair comparison, NOT min(device_count, 2))
   - Measure elapsed time
   - Calculate sequences_per_sec, projected_6M_hours
   - Save results to tmp_path / "v2_results.json":
     ```json
     {
       "version": "v2.0",
       "architecture": "async_dataloader_packing_fp16",
       "num_sequences": 10000,
       "world_size": 1,
       "elapsed_sec": X.XX,
       "sequences_per_sec": X.XX,
       "projected_6M_hours": X.XX
     }
     ```
   - After measurement: cleanup GPU state with torch.cuda.empty_cache(), gc.collect()
   - Sleep 30 seconds for thermal cooldown before v1.0 runs
   - Print results

   b. **test_2_v1_throughput** (v1.0 benchmark -- runs SECOND, after cooldown):
   - Skip if not torch.cuda.is_available()
   - Call check_v1_available(tmp_path) first
   - If v1.0 unavailable: `pytest.skip("v1.0 git tag not found -- cannot run v1.0 baseline comparison. Tag 'v1.0' must exist in the repository.")`
   - Generate same 10K sequence workload (same seed for reproducibility)
   - Run v1.0 via subprocess from the worktree directory:
     ```python
     cmd = [
         "python", "-m", "virnucpro", "predict",
         str(fasta_path),
         "--output-dir", str(output_dir),
         "--gpus", "0",          # Single GPU ONLY for fair comparison
         "--parallel",
         "--no-progress",
     ]
     ```
   - Set cwd to the worktree path so v1.0 code runs, not v2.0
   - Measure elapsed time
   - Save results to tmp_path / "v1_results.json"
   - Cleanup worktree via cleanup_v1_worktree
   - Print results

   c. **test_3_speedup_comparison** (comparison analysis -- runs LAST):
   - Attempt to load v1_results.json and v2_results.json from previous tests
   - If v1_results.json missing: `pytest.skip("v1.0 results unavailable -- v1.0 tag likely missing from repository. Cannot compute speedup comparison.")`
   - If v2_results.json missing: `pytest.skip("v2.0 results missing -- test_1_v2_throughput must run first.")`
   - Calculate speedup = v1_elapsed / v2_elapsed
   - Print comprehensive comparison:
     ```
     v1.0 vs v2.0 Speedup Comparison
     ================================
     Metric          | v1.0 (multi-worker) | v2.0 (async+pack)  | Improvement
     Architecture    | Multi-worker/GPU    | Async DataLoader    | -
     Precision       | BF16                | FP16                | -
     Packing         | None                | FFD + FlashAttn     | -
     World Size      | 1                   | 1                   | (apples-to-apples)
     Sequences       | 10,000              | 10,000              | -
     Elapsed (s)     | XXX.XX              | XXX.XX              | X.Xx faster
     Seq/sec         | XX.X                | XX.X                | X.Xx higher
     Projected 6M    | XX.X hours          | XX.X hours          | XX.X hours saved
     ================================
     Overall Speedup: X.Xx
     Target: >= 4.5x (validates 4.5x speedup claim)
     Result: PASS/FAIL

     Speedup Breakdown (estimated):
     - Async DataLoader (no GPU starvation): ~1.2-1.5x
     - Sequence Packing (FFD + FlashAttention): ~2-3x
     - FP16 Precision (larger batches + tensor cores): ~1.5-1.8x
     - Combined (some overlap): ~4.0-4.5x
     ```
   - Assert speedup >= 4.5 (matches CONTEXT.md "validate the 4.5x speedup claim")
   - Save comparison to tmp_path / "speedup_comparison.json"

Imports:
- pytest, torch, time, subprocess, json, random, logging, gc from stdlib
- Path from pathlib
- Tuple, Optional from typing
- run_multi_gpu_inference from virnucpro.pipeline.multi_gpu_inference
- RuntimeConfig from virnucpro.pipeline.runtime_config
  </action>
  <verify>
    python -c "from tests.benchmarks.test_v1_comparison import TestV1Comparison; print('v1 comparison imports OK')"
  </verify>
  <done>
    v2.0 benchmark runs first (world_size=1, single GPU) with thermal cooldown after. v1.0 benchmark runs second from git worktree (single GPU), skipping gracefully if v1.0 tag unavailable. Comparison calculates actual speedup with comprehensive breakdown table. Asserts v2.0 >= 4.5x faster than v1.0. 10K sequences ensures compute dominates overhead.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete Phase 10 performance validation suite:
1. TelemetryLogger and InferenceProgressReporter (Plan 01)
2. Production workload benchmark with PERF-01/02/05 validation (Plan 02)
3. 2-GPU scaling validation at 95% efficiency (Plan 03)
4. DataLoader and packing parameter sweep (Plan 04)
5. v1.0 vs v2.0 speedup comparison (Plan 05)
  </what-built>
  <how-to-verify>
1. Run the quick profiling test (single GPU, ~5 min):
   ```
   pytest tests/benchmarks/test_production_validation.py::TestProductionValidation::test_throughput_subset_profiling -v -s
   ```

2. If 2 GPUs available, run scaling test:
   ```
   pytest tests/benchmarks/test_scaling_v2.py::TestV2Scaling::test_2gpu_scaling_efficiency -v -s
   ```

3. Run parameter sweep (DataLoader only, ~15 min):
   ```
   pytest tests/benchmarks/test_parameter_tuning.py::TestParameterTuning::test_dataloader_parameter_sweep -v -s
   ```

4. Review telemetry JSON output in test temp directories

5. For full production validation (~1-2 hours):
   ```
   pytest tests/benchmarks/test_production_validation.py::TestProductionValidation::test_production_throughput_validation -v -s
   ```

Verify:
- Tests run without errors
- Results tables print clearly
- Projected 6M sequence time is <10 hours
- 2-GPU scaling shows >= 1.9x speedup
- Telemetry JSON files are written correctly

**If any requirement failed -- decision tree:**

- **Projected time >10h:**
  1. Review test_parameter_tuning.py results (Plan 04)
  2. Apply recommended DataLoader/packing parameters
  3. Re-run production validation (Plan 02)

- **GPU utilization <70%:**
  1. Check p95_wait_time_ms from telemetry
  2. If >100ms: increase num_workers or prefetch_factor
  3. Re-run with adjusted parameters

- **Packing efficiency <90%:**
  1. Increase buffer_size (try 3000 or 5000)
  2. Verify token_budget matches GPU memory capacity
  3. Re-run production validation

- **Scaling <1.9x (2 GPUs):**
  1. Check per-GPU timing imbalance from Plan 03
  2. Verify stride distribution via token counts
  3. Check for thermal throttling or I/O contention

- **v1.0 speedup <4.5x:**
  1. If v1.0 unavailable: document as unable to validate, not a blocking failure
  2. If workload too small: re-run with 20K sequences
  3. If genuine underperformance: profile bottlenecks with Plan 04 parameter sweep
  </how-to-verify>
  <resume-signal>Type "approved" if results meet targets, or describe issues and parameter adjustments needed. If v1.0 comparison was skipped (tag unavailable), note whether this is acceptable.</resume-signal>
</task>

</tasks>

<verification>
- `python -c "from tests.benchmarks.test_v1_comparison import TestV1Comparison"`
- v2.0 measurement: runs full pipeline with world_size=1, saves results JSON, cleans up GPU + 30s cooldown
- v1.0 measurement: checks v1.0 tag, creates git worktree, runs CLI predict --gpus "0", saves results JSON, cleans up worktree. Skips gracefully if v1.0 tag unavailable.
- Comparison: calculates speedup, prints table, asserts >= 4.5x. Skips if v1.0 results missing.
- Human verification: review all Phase 10 results with decision tree for failures
</verification>

<success_criteria>
v1.0 vs v2.0 comparison validates actual speedup (target: >= 4.5x) using 10K sequences on single GPU (world_size=1) for fair comparison. v2.0 runs first with thermal cooldown. v1.0 comparison is conditional -- skips gracefully if v1.0 tag unavailable. Comprehensive breakdown table documents contribution of each optimization (async DataLoader, packing, FP16). Human verification confirms all Phase 10 results meet requirements: <10h projected time, >= 1.9x 2-GPU scaling, >= 90% packing efficiency, >= 70% GPU utilization. Decision tree guides remediation for any failed requirements.
</success_criteria>

<output>
After completion, create `.planning/phases/10-performance-validation-&-tuning**---end-to-end-benchmarking/10-05-SUMMARY.md`
</output>
