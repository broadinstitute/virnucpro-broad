---
phase: 09-checkpointing-integration
plan: 03
type: execute
wave: 2
depends_on: ["09-01", "09-02"]
files_modified:
  - virnucpro/pipeline/async_inference.py
autonomous: true

must_haves:
  truths:
    - "AsyncInferenceRunner checkpoints at batch boundaries without breaking packed attention"
    - "Checkpoint writes happen asynchronously (GPU continues inference while I/O runs)"
    - "Runner can resume from existing checkpoints and skip already-processed batches"
    - "Progress bar initializes at resume position for continuity"
    - "Checkpoint metadata includes GPU memory usage snapshot for crash debugging"
    - "Checkpoint metadata includes input fingerprint and model config hash for cross-run validation"
    - "Checkpoint metadata includes packing stats (efficiency, token count, buffer size) when packing enabled"
    - "Corrupted sequences from failed checkpoints are identified and logged for reprocessing"
    - "Manifest integration enables multi-GPU coordination when manifest provided"
  artifacts:
    - path: "virnucpro/pipeline/async_inference.py"
      provides: "AsyncInferenceRunner with checkpoint hooks in run() method"
      contains: "CheckpointTrigger"
  key_links:
    - from: "virnucpro/pipeline/async_inference.py"
      to: "virnucpro/pipeline/checkpoint_writer.py"
      via: "import CheckpointTrigger, AsyncCheckpointWriter, validate_checkpoint_pt, resume_from_checkpoints"
      pattern: "from virnucpro\\.pipeline\\.checkpoint_writer import"
    - from: "virnucpro/pipeline/async_inference.py"
      to: "virnucpro/pipeline/checkpoint_manifest.py"
      via: "optional CheckpointManifest parameter for multi-GPU coordination"
      pattern: "CheckpointManifest"
    - from: "virnucpro/pipeline/async_inference.py"
      to: "checkpoint files"
      via: "torch.save .pt format (consistent with Phase 3 and 09-01)"
      pattern: "batch_\\d+\\.pt"
---

<objective>
Wire checkpointing into AsyncInferenceRunner so inference produces incremental checkpoints.

Purpose: AsyncInferenceRunner is the core inference loop for both single-GPU and multi-GPU modes. Adding checkpoint hooks here means ALL inference paths automatically get checkpointing. The runner must checkpoint at batch boundaries (respecting packed attention atomicity), support resuming from prior checkpoints (including corrupted sequence identification), and optionally coordinate with CheckpointManifest for multi-GPU tracking.

Output: Modified `virnucpro/pipeline/async_inference.py` with checkpoint integration using .pt format consistent with 09-01 and Phase 3.
</objective>

<execution_context>
@/home/unix/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/unix/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-checkpointing-integration/09-CONTEXT.md
@.planning/phases/09-checkpointing-integration/09-01-SUMMARY.md
@.planning/phases/09-checkpointing-integration/09-02-SUMMARY.md
@virnucpro/pipeline/async_inference.py
@virnucpro/pipeline/checkpoint_writer.py
@virnucpro/pipeline/checkpoint_manifest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add checkpoint parameters and manifest integration to AsyncInferenceRunner.__init__</name>
  <files>virnucpro/pipeline/async_inference.py</files>
  <action>
Modify `AsyncInferenceRunner.__init__` to accept optional checkpoint parameters:

Add new parameters (all optional, defaults to disabled):
- `checkpoint_dir: Optional[Path] = None` - directory for checkpoint files (None = checkpointing disabled)
- `rank: int = 0` - shard rank for per-GPU isolation
- `checkpoint_seq_threshold: int = 10000` - sequence count trigger
- `checkpoint_time_threshold: float = 300.0` - time trigger in seconds
- `manifest: Optional['CheckpointManifest'] = None` - optional manifest for multi-GPU coordination (from 09-02)
- `input_fingerprint: str = ""` - SHA256 of input data for cross-run validation
- `model_config_hash: str = ""` - hash of model architecture/weights for compatibility checks

When checkpoint_dir is not None:
- Create `self.shard_checkpoint_dir = checkpoint_dir / f"shard_{rank}"`
- `self.shard_checkpoint_dir.mkdir(parents=True, exist_ok=True)`
- Initialize `self.trigger = CheckpointTrigger(seq_threshold=checkpoint_seq_threshold, time_threshold_sec=checkpoint_time_threshold)`
- Initialize `self.writer = AsyncCheckpointWriter(max_workers=1, manifest=manifest, rank=rank)` (pass manifest and rank for automatic coordination per 09-01 revised API)
- Initialize accumulator state: `self._ckpt_embeddings: List[np.ndarray] = []`, `self._ckpt_ids: List[str] = []`, `self._ckpt_batch_idx: int = 0`
- Store `self.checkpoint_dir = checkpoint_dir` and `self.rank = rank`
- Store `self.manifest = manifest`
- Store `self._input_fingerprint = input_fingerprint`
- Compute model config hash if not provided: `self._model_config_hash = model_config_hash or self._compute_model_config_hash()`
  - Add `_compute_model_config_hash(self) -> str` helper: uses `hashlib.sha256` on `str(next(self.model.parameters()).dtype) + str(sum(p.numel() for p in self.model.parameters()))` — a lightweight fingerprint of model dtype + parameter count. Returns hex digest truncated to 16 chars.

When checkpoint_dir is None:
- Set `self.trigger = None`, `self.writer = None`, `self.manifest = None`
- No checkpoint state initialized

Add `self._checkpointing_enabled` property: `return self.checkpoint_dir is not None`

Add imports at top of file:
- `from virnucpro.pipeline.checkpoint_writer import CheckpointTrigger, AsyncCheckpointWriter, validate_checkpoint_pt, resume_from_checkpoints`
- `import numpy as np`
- `import os`
- `import hashlib`

NOTE on TYPE_CHECKING import: Use `from __future__ import annotations` at file top (if not already present) so that `'CheckpointManifest'` can be used as a string annotation without importing the class at runtime. This avoids circular import risk. If the file already uses runtime type checking, use `TYPE_CHECKING` guard instead:
```python
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from virnucpro.pipeline.checkpoint_manifest import CheckpointManifest
```

IMPORTANT: Do NOT change existing __init__ parameter signatures or behavior. Only ADD new optional parameters. Existing callers must work unchanged.
  </action>
  <verify>
    python -c "from virnucpro.pipeline.async_inference import AsyncInferenceRunner; print('Import successful')"
  </verify>
  <done>
    AsyncInferenceRunner accepts optional checkpoint_dir, manifest, input_fingerprint, and model_config_hash parameters. When checkpoint_dir provided, initializes trigger, writer (with manifest and rank for automatic coordination), and accumulator state. Model config hash computed automatically if not provided. When checkpoint_dir not provided, behaves identically to before.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add checkpoint hooks to run() method and _write_checkpoint helper</name>
  <files>virnucpro/pipeline/async_inference.py</files>
  <action>
Modify `AsyncInferenceRunner.run()` method to integrate checkpointing:

1. **Add resume parameters**: Change `run()` signature to add `force_restart: bool = False` parameter (default False, backward compatible).

2. **Resume logic at start of run()**: Before the inference loop, if checkpointing enabled and not force_restart:
   - Call `resume_from_checkpoints(self.checkpoint_dir, self.rank, force_restart)` which returns a 4-TUPLE (per revised 09-01 API):
     `(resumed_ids, resumed_embs, resume_batch_idx, corrupted_sequence_ids)`
   - Handle corrupted_sequence_ids: if non-empty, log WARNING:
     `f"Checkpoint corruption detected: {len(corrupted_sequence_ids)} sequences need reprocessing (from batches after corruption point)"`
     Log the first 10 corrupted IDs at DEBUG level for troubleshooting.
   - If resumed data exists (ids not empty):
     - Store in `self._ckpt_embeddings` (wrap resumed_embs in list) and `self._ckpt_ids`
     - Set `self._ckpt_batch_idx` to resume_batch_idx
     - Log: `f"Resuming shard {self.rank}: {len(resumed_ids)} sequences from {resume_batch_idx} checkpoints"`
     - Yield an `InferenceResult` with the resumed data (batch_idx=-1 as marker for "resumed data")
       - Convert resumed embeddings np.ndarray to torch.Tensor for InferenceResult compatibility

3. **Checkpoint trigger after each batch**: In the main inference loop, after `yield result` and before `batch_idx += 1`:
   - If checkpointing enabled:
     - Accumulate: `self._ckpt_embeddings.append(result.embeddings.cpu().numpy())` and `self._ckpt_ids.extend(result.sequence_ids)`
       - NOTE: Use `.cpu().numpy()` to ensure GPU tensors are transferred to CPU before accumulation (prevents CUDA memory growth from accumulating GPU tensors)
     - Call `self.trigger.should_checkpoint(len(result.sequence_ids))`
     - If should checkpoint: call `self._write_checkpoint(reason)` then `self.trigger.reset()`

4. **Final checkpoint after loop**: After the flush logic (after `if hasattr(dataloader.collate_fn, 'flush')` block), if checkpointing enabled and `self._ckpt_embeddings` is not empty:
   - Call `self._write_checkpoint("final")`

5. **Wait for writes in finally block**: In the existing finally block, if checkpointing enabled:
   - Call `self.writer.wait_all(timeout=300)` to ensure all async writes complete before returning
   - Call `self.writer.shutdown()`
   - Log: "All checkpoint writes completed"

6. **Add `_write_checkpoint(self, reason: str)` method**:
   - If no accumulated data (`self._ckpt_embeddings` is empty): return early
   - Concatenate: `embeddings = np.concatenate(self._ckpt_embeddings, axis=0)`
   - Build checkpoint path: `self.shard_checkpoint_dir / f"batch_{self._ckpt_batch_idx:05d}.pt"` (NOTE: .pt extension, NOT .h5 — consistent with Phase 3 and 09-01)
   - Determine GPU device from self.model (e.g., `device = next(self.model.parameters()).device`)
   - Build metadata dict:
     - `batch_idx`: self._ckpt_batch_idx
     - `num_sequences`: len(self._ckpt_ids)
     - `timestamp`: datetime.utcnow().isoformat()
     - `trigger_reason`: reason
     - `model_dtype`: str(next(self.model.parameters()).dtype)
     - `packing_enabled`: not bool(os.environ.get("VIRNUCPRO_DISABLE_PACKING", ""))
     - `gpu_memory_allocated_bytes`: `torch.cuda.memory_allocated(device)` if device.type == 'cuda' else 0
     - `gpu_memory_peak_bytes`: `torch.cuda.max_memory_allocated(device)` if device.type == 'cuda' else 0
     - `input_fingerprint`: self._input_fingerprint
     - `model_config_hash`: self._model_config_hash
     - `packing_stats`: If packing is enabled and the collator has packing stats, include them:
       ```python
       packing_stats = {}
       if hasattr(self, '_last_packing_stats'):
           packing_stats = self._last_packing_stats
       metadata['packing_stats'] = packing_stats
       ```
   - Call `self.writer.write_checkpoint_async(checkpoint_path, embeddings, self._ckpt_ids, metadata)`
   - Log: `f"Checkpoint {self._ckpt_batch_idx} queued: {len(self._ckpt_ids)} sequences, reason={reason}"`
   - Increment `self._ckpt_batch_idx`
   - Reset accumulators: `self._ckpt_embeddings = []`, `self._ckpt_ids = []`

7. **Capture packing stats during inference**: In the main inference loop (step 3), after accumulating embeddings, capture packing stats from the batch result if available:
   ```python
   if hasattr(result, 'packing_stats') and result.packing_stats:
       self._last_packing_stats = result.packing_stats
   elif hasattr(result, 'metadata') and isinstance(result.metadata, dict):
       # Extract from metadata if result carries it there
       packing_info = {}
       for key in ('packing_efficiency', 'token_count', 'buffer_size', 'token_budget'):
           if key in result.metadata:
               packing_info[key] = result.metadata[key]
       if packing_info:
           self._last_packing_stats = packing_info
   ```
   Initialize `self._last_packing_stats = {}` in __init__ when checkpointing is enabled.

Add `from datetime import datetime` import. Import `torch` is already available (existing dependency).

CRITICAL: The checkpoint trigger fires AFTER yielding the batch result, at batch boundaries only. This respects packed attention atomicity - never mid-batch. The accumulate-then-check pattern ensures batch completeness.

IMPORTANT: Do NOT modify process_batch(), _run_inference(), _extract_embeddings(), or any other existing methods. Only modify run() and add _write_checkpoint() and _compute_model_config_hash().
  </action>
  <verify>
    python -c "
from virnucpro.pipeline.async_inference import AsyncInferenceRunner
import inspect
sig = inspect.signature(AsyncInferenceRunner.run)
assert 'force_restart' in sig.parameters, 'Missing force_restart param'
assert hasattr(AsyncInferenceRunner, '_write_checkpoint'), 'Missing _write_checkpoint method'
assert hasattr(AsyncInferenceRunner, '_compute_model_config_hash'), 'Missing _compute_model_config_hash method'
# Verify _write_checkpoint includes all required metadata
src = inspect.getsource(AsyncInferenceRunner._write_checkpoint)
assert 'gpu_memory_allocated_bytes' in src, 'Missing gpu_memory_allocated_bytes in metadata'
assert 'gpu_memory_peak_bytes' in src, 'Missing gpu_memory_peak_bytes in metadata'
assert 'input_fingerprint' in src, 'Missing input_fingerprint in metadata'
assert 'model_config_hash' in src, 'Missing model_config_hash in metadata'
assert 'packing_stats' in src, 'Missing packing_stats in metadata'
assert '.pt' in src, 'Missing .pt extension in checkpoint path'
# Verify resume handles 4-tuple
run_src = inspect.getsource(AsyncInferenceRunner.run)
assert 'corrupted_sequence_ids' in run_src, 'Missing corrupted_sequence_ids handling in resume'
print('Checkpoint integration with full metadata and corruption handling verified')
"
  </verify>
  <done>
    AsyncInferenceRunner.run() resumes from prior checkpoints using 4-tuple return (handling corrupted_sequence_ids with warning logging), accumulates embeddings, triggers checkpoint writes at batch boundaries, writes final checkpoint, and waits for all async writes to complete. Checkpoint trigger respects packed attention atomicity by only firing between batches. Checkpoints use .pt format consistent with Phase 3 and 09-01. Checkpoint metadata includes GPU memory snapshot, input fingerprint, model config hash, and packing stats for cross-run validation and crash debugging. Manifest integration via AsyncCheckpointWriter enables automatic multi-GPU coordination.
  </done>
</task>

</tasks>

<verification>
- `python -c "from virnucpro.pipeline.async_inference import AsyncInferenceRunner"` - import succeeds
- `AsyncInferenceRunner()` without checkpoint_dir works identically to before (backward compatible)
- `AsyncInferenceRunner(checkpoint_dir=...)` enables checkpointing with trigger + writer
- `AsyncInferenceRunner(checkpoint_dir=..., manifest=...)` passes manifest to AsyncCheckpointWriter for coordination
- `run()` accepts force_restart parameter
- Resume logic unpacks 4-tuple from resume_from_checkpoints and logs corrupted_sequence_ids
- `_write_checkpoint()` method exists and uses async writer
- `_write_checkpoint()` produces .pt files (not .h5)
- `_write_checkpoint()` metadata includes: gpu_memory_allocated_bytes, gpu_memory_peak_bytes, input_fingerprint, model_config_hash, packing_stats
- `_compute_model_config_hash()` generates reproducible hash from model dtype + parameter count
- Import uses validate_checkpoint_pt (not validate_checkpoint_hdf5)
- Existing tests still pass: `pytest tests/unit/test_async_inference.py -v`
</verification>

<success_criteria>
AsyncInferenceRunner integrates checkpointing at batch boundaries using .pt format (consistent with Phase 3 and 09-01). Resume logic handles the 4-tuple return from resume_from_checkpoints, including corrupted_sequence_ids which are logged for reprocessing. AsyncCheckpointWriter initialized with manifest and rank for automatic multi-GPU coordination when manifest provided. Checkpoint metadata includes GPU memory snapshot (allocated + peak bytes), input fingerprint, model config hash, and packing stats for cross-run validation and crash debugging. Backward compatible - existing callers work without checkpoint_dir. All existing tests pass.
</success_criteria>

<output>
After completion, create `.planning/phases/09-checkpointing-integration/09-03-SUMMARY.md`
</output>
