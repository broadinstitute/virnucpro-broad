---
phase: 09-checkpointing-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - virnucpro/pipeline/checkpoint_manifest.py
autonomous: true

must_haves:
  truths:
    - "Coordinator manifest tracks checkpoint progress per shard"
    - "Manifest uses atomic writes (temp + rename) to prevent corruption"
    - "Manifest can identify which shards completed vs failed"
    - "Manifest supports partial failure recovery (only restart failed shards)"
  artifacts:
    - path: "virnucpro/pipeline/checkpoint_manifest.py"
      provides: "CheckpointManifest class for multi-GPU checkpoint coordination"
      min_lines: 120
  key_links:
    - from: "virnucpro/pipeline/checkpoint_manifest.py"
      to: "json"
      via: "JSON manifest file for human-readable tracking"
      pattern: "json\\.(load|dump)"
---

<objective>
Create the CheckpointManifest for multi-GPU checkpoint coordination.

Purpose: In multi-GPU mode, each shard writes checkpoints independently. The manifest provides a global view of progress, enabling partial failure recovery (restart only failed GPUs) and completion validation. This is the coordination layer that connects independent per-shard checkpoints.

Output: `virnucpro/pipeline/checkpoint_manifest.py` with CheckpointManifest class.
</objective>

<execution_context>
@/home/unix/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/unix/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-checkpointing-integration/09-CONTEXT.md
@.planning/phases/09-checkpointing-integration/09-RESEARCH.md
@virnucpro/pipeline/gpu_coordinator.py
@virnucpro/pipeline/multi_gpu_inference.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: CheckpointManifest class</name>
  <files>virnucpro/pipeline/checkpoint_manifest.py</files>
  <action>
Create `virnucpro/pipeline/checkpoint_manifest.py` with:

**CheckpointManifest** class:

`__init__(self, manifest_path: Path)`:
- Store manifest_path
- Create `threading.Lock` for thread-safe access (workers may update from different processes via shared filesystem)

`initialize(self, world_size: int) -> Dict`:
- Create initial manifest JSON structure:
  ```
  {
    "version": "1.0",
    "world_size": N,
    "created_at": ISO timestamp,
    "shards": {
      "0": {"status": "in_progress", "last_checkpoint_batch": -1, "total_sequences": 0, "last_checkpoint_time": null, "checkpoints": []},
      "1": { ... },
      ...
    }
  }
  ```
- Write to disk via `_save_manifest`
- Return the manifest dict

`update_shard_checkpoint(self, rank: int, batch_idx: int, num_sequences: int, checkpoint_file: str)`:
- Thread-safe (acquire lock)
- Load current manifest
- Update shard entry: last_checkpoint_batch, total_sequences (+=), last_checkpoint_time, append to checkpoints list with {batch_idx, num_sequences, file, timestamp}
- Save manifest

`mark_shard_complete(self, rank: int)`:
- Thread-safe
- Set shard status to "complete", add completed_at timestamp
- Save manifest

`mark_shard_failed(self, rank: int, error: str)`:
- Thread-safe
- Set shard status to "failed", add failed_at timestamp, store error message
- Save manifest

`get_shard_status(self, rank: int) -> Dict`:
- Load manifest and return the shard dict for given rank
- Returns None if rank not found

`get_resumable_shards(self) -> List[int]`:
- Load manifest
- Return list of ranks where status is "in_progress" or "failed" (these need reprocessing)

`get_completed_shards(self) -> List[int]`:
- Load manifest
- Return list of ranks where status is "complete"

`get_global_progress(self) -> Dict`:
- Load manifest
- Return summary: total_shards, completed, in_progress, failed, total_sequences_checkpointed

`_load_manifest(self) -> Dict`:
- Read JSON from manifest_path
- Return dict

`_save_manifest(self, manifest: Dict)`:
- Atomic write: write to manifest_path.with_suffix('.tmp'), then temp_path.replace(manifest_path)
- Uses json.dump with indent=2 for human readability

`exists(self) -> bool`:
- Return whether manifest_path exists

Module-level logger: `logger = logging.getLogger('virnucpro.pipeline.checkpoint_manifest')`

Module docstring: "Coordinator manifest for multi-GPU checkpoint tracking. Tracks per-shard checkpoint progress to enable partial failure recovery and global completeness validation. Uses JSON format consistent with Phase 7 sequence_index.json."

Imports: json, logging, threading from stdlib; Path from pathlib; datetime from datetime; Dict, List, Optional from typing.
  </action>
  <verify>
    python -c "from virnucpro.pipeline.checkpoint_manifest import CheckpointManifest; print('Import successful')"
  </verify>
  <done>
    CheckpointManifest initializes, tracks per-shard checkpoints, supports marking complete/failed, provides resumable/completed shard lists, and uses atomic JSON writes. All methods are thread-safe via lock.
  </done>
</task>

</tasks>

<verification>
- `python -c "from virnucpro.pipeline.checkpoint_manifest import CheckpointManifest"`
- CheckpointManifest: verify initialize creates correct JSON structure
- Verify atomic write pattern (temp + rename)
- Verify get_resumable_shards / get_completed_shards return correct rank lists
</verification>

<success_criteria>
CheckpointManifest importable, initializes JSON manifest, supports per-shard checkpoint tracking with thread-safe updates, atomic writes, and shard status queries for resumable/completed/failed classification.
</success_criteria>

<output>
After completion, create `.planning/phases/09-checkpointing-integration/09-02-SUMMARY.md`
</output>
