---
phase: 09-checkpointing-integration
plan: 06
type: execute
wave: 2
depends_on: ["09-01", "09-02"]
files_modified:
  - tests/unit/test_checkpoint_writer.py
  - tests/unit/test_checkpoint_manifest.py
autonomous: true

must_haves:
  truths:
    - "CheckpointTrigger fires correctly on sequence, time, and emergency thresholds"
    - "AsyncCheckpointWriter writes valid HDF5 checkpoints with .done markers"
    - "validate_checkpoint_hdf5 detects all corruption types"
    - "resume_from_checkpoints loads valid checkpoints and stops at corruption"
    - "CheckpointManifest tracks shard progress and supports atomic updates"
  artifacts:
    - path: "tests/unit/test_checkpoint_writer.py"
      provides: "Unit tests for CheckpointTrigger, AsyncCheckpointWriter, validate/resume"
      min_lines: 150
    - path: "tests/unit/test_checkpoint_manifest.py"
      provides: "Unit tests for CheckpointManifest"
      min_lines: 80
  key_links:
    - from: "tests/unit/test_checkpoint_writer.py"
      to: "virnucpro/pipeline/checkpoint_writer.py"
      via: "imports and tests all public functions"
      pattern: "from virnucpro\\.pipeline\\.checkpoint_writer import"
    - from: "tests/unit/test_checkpoint_manifest.py"
      to: "virnucpro/pipeline/checkpoint_manifest.py"
      via: "imports and tests CheckpointManifest"
      pattern: "from virnucpro\\.pipeline\\.checkpoint_manifest import"
---

<objective>
Write unit tests for checkpoint foundation components (writer, trigger, manifest).

Purpose: These tests validate the checkpoint building blocks before they're wired into the inference pipeline. Tests cover trigger logic, async writes, HDF5 validation, resume from checkpoints, and manifest tracking. Testing these components in isolation catches bugs before integration.

Output: `tests/unit/test_checkpoint_writer.py` and `tests/unit/test_checkpoint_manifest.py`.
</objective>

<execution_context>
@/home/unix/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/unix/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-checkpointing-integration/09-01-SUMMARY.md
@.planning/phases/09-checkpointing-integration/09-02-SUMMARY.md
@virnucpro/pipeline/checkpoint_writer.py
@virnucpro/pipeline/checkpoint_manifest.py
@tests/unit/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Unit tests for checkpoint_writer.py</name>
  <files>tests/unit/test_checkpoint_writer.py</files>
  <action>
Create `tests/unit/test_checkpoint_writer.py` with these test cases:

**CheckpointTrigger tests:**

1. `test_trigger_sequence_threshold_fires` - Create trigger with seq_threshold=100. Call should_checkpoint with batch_size=50 twice. First call: (False, None). Second call: (True, "sequence_threshold").

2. `test_trigger_time_threshold_fires` - Create trigger with time_threshold_sec=0.1. Sleep 0.15s. Call should_checkpoint with batch_size=1. Assert (True, "time_threshold").

3. `test_trigger_emergency_override` - Create trigger with emergency_override_sec=0.1. Sleep 0.15s. Call should_checkpoint. Assert (True, "emergency_time_override").

4. `test_trigger_reset_clears_counters` - Trigger fires on sequence threshold, call reset(), then verify trigger doesn't fire on next small batch.

5. `test_trigger_viral_mode_thresholds` - Set VIRNUCPRO_VIRAL_CHECKPOINT_MODE=true env var (use monkeypatch), create trigger with defaults. Verify internal thresholds are 5000 seq / 180s. Clean up env var after test.

**AsyncCheckpointWriter tests (use tmp_path fixture):**

6. `test_writer_creates_hdf5_with_done_marker` - Create writer, call write_checkpoint_async with dummy embeddings (np.random.randn(10, 128)), sequence_ids (list of 10 strings), metadata dict. Call wait_all(). Assert checkpoint .h5 file exists, .h5.done marker exists.

7. `test_writer_hdf5_contains_correct_data` - Write checkpoint, read back with h5py. Assert embeddings shape matches, sequence_ids match, metadata attrs present.

8. `test_writer_atomic_write_no_temp_file_remains` - After write_checkpoint_async + wait_all, assert no .tmp files in directory.

9. `test_writer_copies_data_before_async` - Write checkpoint, immediately modify original numpy array. Wait for write. Read back and verify checkpoint contains ORIGINAL data (not modified data). This tests the .copy() safety.

10. `test_writer_shutdown_waits_for_pending` - Queue 3 writes, call shutdown(). Assert all 3 files exist.

**validate_checkpoint_hdf5 tests (use tmp_path fixture):**

11. `test_validate_empty_file_fails` - Create 0-byte .h5 file. Assert returns (False, "file is 0 bytes").

12. `test_validate_no_done_marker_fails` - Create valid HDF5 without .done marker. Assert returns (False, "missing .done marker...").

13. `test_validate_missing_datasets_fails` - Create HDF5 with only 'embeddings' dataset (no sequence_ids). Add .done marker. Assert returns (False, "missing required datasets").

14. `test_validate_shape_mismatch_fails` - Create HDF5 where embeddings has 10 rows but sequence_ids has 5 entries. Add .done marker. Assert returns (False, "shape mismatch...").

15. `test_validate_valid_checkpoint_passes` - Create complete valid checkpoint via AsyncCheckpointWriter. Assert returns (True, "").

**resume_from_checkpoints tests (use tmp_path fixture):**

16. `test_resume_no_checkpoints_returns_empty` - Empty checkpoint dir. Assert returns ([], None, 0).

17. `test_resume_force_restart_ignores_checkpoints` - Write checkpoints, call with force_restart=True. Assert returns ([], None, 0).

18. `test_resume_loads_valid_checkpoints_in_order` - Write batch_00000.h5 and batch_00001.h5 via AsyncCheckpointWriter. Call resume_from_checkpoints. Assert returns concatenated IDs, concatenated embeddings, resume_batch_idx=2.

19. `test_resume_stops_at_corrupted_checkpoint` - Write 3 checkpoints. Corrupt middle one (remove its .done marker). Call resume. Assert only first checkpoint loaded, resume_batch_idx=1.

Use `import pytest`, `import numpy as np`, `import h5py`, `from unittest.mock import patch`. Follow project test naming convention: `test_{what}_{condition}_{expected_outcome}`.

Use `tmp_path` fixture for all file operations (pytest built-in, auto-cleaned).
  </action>
  <verify>
    pytest tests/unit/test_checkpoint_writer.py -v
  </verify>
  <done>
    All unit tests for CheckpointTrigger, AsyncCheckpointWriter, validate_checkpoint_hdf5, and resume_from_checkpoints pass. Tests cover normal operation, edge cases, corruption detection, and data safety (copy before async).
  </done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for checkpoint_manifest.py</name>
  <files>tests/unit/test_checkpoint_manifest.py</files>
  <action>
Create `tests/unit/test_checkpoint_manifest.py` with these test cases:

1. `test_manifest_initialize_creates_json` - Initialize manifest with world_size=4. Assert JSON file exists, contains version "1.0", has 4 shard entries all "in_progress".

2. `test_manifest_update_shard_checkpoint` - Initialize, call update_shard_checkpoint(rank=0, batch_idx=5, num_sequences=100, checkpoint_file="batch_00005.h5"). Load JSON, verify shard 0 has last_checkpoint_batch=5, total_sequences=100, checkpoint in list.

3. `test_manifest_mark_shard_complete` - Initialize, mark shard 0 complete. Verify status="complete" and completed_at timestamp set.

4. `test_manifest_mark_shard_failed` - Initialize, mark shard 1 failed with error message. Verify status="failed", error stored.

5. `test_manifest_get_resumable_shards` - Initialize with 4 shards. Mark 0 complete, leave 1 in_progress, mark 2 failed, leave 3 in_progress. Assert get_resumable_shards returns [1, 2, 3] (in_progress and failed).

6. `test_manifest_get_completed_shards` - Same setup as above. Assert get_completed_shards returns [0].

7. `test_manifest_get_global_progress` - Setup with mixed states. Assert progress dict has correct counts.

8. `test_manifest_atomic_write_no_temp_remains` - Initialize and update. Assert no .tmp files in directory.

9. `test_manifest_exists_false_before_init` - Create manifest object without initializing. Assert exists() returns False.

10. `test_manifest_cumulative_sequence_count` - Call update_shard_checkpoint for same shard twice. Assert total_sequences is cumulative (sum of both updates).

Use `tmp_path` fixture for all file operations.
  </action>
  <verify>
    pytest tests/unit/test_checkpoint_manifest.py -v
  </verify>
  <done>
    All unit tests for CheckpointManifest pass. Tests cover initialization, shard tracking, completion/failure marking, resumable/completed queries, atomic writes, and cumulative sequence counting.
  </done>
</task>

</tasks>

<verification>
- `pytest tests/unit/test_checkpoint_writer.py tests/unit/test_checkpoint_manifest.py -v` - all tests pass
- No test pollution (torch mock isolation verified by conftest autouse fixture)
- All checkpoint files created in tmp_path (no filesystem side effects)
</verification>

<success_criteria>
All 29 unit tests pass. Tests cover: trigger thresholds (sequence, time, emergency, viral mode), async writer (HDF5 creation, data correctness, atomic writes, copy safety, shutdown), validation (4 corruption types + valid), resume (empty, force restart, ordered loading, corruption stop), and manifest (init, update, complete, fail, queries, atomic writes).
</success_criteria>

<output>
After completion, create `.planning/phases/09-checkpointing-integration/09-06-SUMMARY.md`
</output>
