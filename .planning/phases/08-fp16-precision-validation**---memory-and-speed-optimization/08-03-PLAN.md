---
phase: 08-fp16-precision-validation
plan: 03
type: execute
wave: 2
depends_on: ["08-01", "08-02"]
files_modified:
  - tests/integration/test_fp16_validation.py
autonomous: true

must_haves:
  truths:
    - "FP16 ESM-2 embeddings have cosine similarity >0.99 vs FP32 baseline"
    - "FP16 forward_packed() embeddings match FP32 forward_packed() (production code path)"
    - "Short, medium, and long sequences all pass similarity threshold"
    - "No NaN/Inf detected in FP16 embeddings"
    - "Embedding distribution statistics (mean, std, norms) similar between FP16 and FP32"
    - "Sequential model loading with cleanup fits A100-40GB memory constraints"
  artifacts:
    - path: "tests/integration/test_fp16_validation.py"
      provides: "FP16 vs FP32 equivalence validation with stratified testing and packed inference"
      min_lines: 200
      exports: ["TestFP16Equivalence", "TestFP16PackedEquivalence", "TestFP16NumericalStability", "TestFP16StatisticalValidation"]
  key_links:
    - from: "tests/integration/test_fp16_validation.py"
      to: "virnucpro/models/esm2_flash.py"
      via: "load_esm2_model with enable_fp16=True and enable_fp16=False"
      pattern: "load_esm2_model.*enable_fp16"
---

<objective>
Validate FP16 embeddings match FP32 baseline via GPU integration tests with stratified sequence testing, production code path validation, and memory-efficient sequential loading.

Purpose: This is the core validation proving FP16 works for the VirNucPro workload. Tests compare FP16 vs FP32 embeddings across short/medium/long sequences in BOTH standard forward() and forward_packed() code paths (production uses packed inference). Detects NaN/Inf, validates statistical properties with realistic thresholds, and uses function-scoped fixtures with explicit cleanup to fit A100-40GB memory constraints. This is the one-time thorough validation described in CONTEXT.md.

Output: GPU integration test file that validates FP16 correctness with >0.99 cosine similarity threshold, tests production forward_packed() code path, and runs reliably on A100-40GB hardware.
</objective>

<execution_context>
@/home/unix/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/unix/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/08-fp16-precision-validation**---memory-and-speed-optimization/08-CONTEXT.md
@.planning/phases/08-fp16-precision-validation**---memory-and-speed-optimization/08-RESEARCH.md
@tests/integration/test_packed_equivalence.py
@virnucpro/models/esm2_flash.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create FP16 vs FP32 equivalence integration tests</name>
  <files>tests/integration/test_fp16_validation.py</files>
  <action>
  Create `tests/integration/test_fp16_validation.py` following the pattern from `test_packed_equivalence.py`.

  **Module header:**
  ```python
  """Integration tests for FP16 vs FP32 embedding equivalence.

  These tests require GPU and ESM-2 model. They validate that FP16 precision
  produces embeddings matching FP32 baseline (cosine similarity >0.99).

  This is the one-time thorough validation proving FP16 works for VirNucPro.
  """
  ```

  Skip entire module if CUDA unavailable:
  ```python
  pytestmark = pytest.mark.skipif(
      not torch.cuda.is_available(),
      reason="CUDA required for FP16 validation tests"
  )
  ```

  **Fixtures (function scope for sequential loading - fits A100-40GB):**

  ```python
  import gc

  @pytest.fixture(scope="function")
  def esm_model_fp32():
      """Load ESM-2 in FP32 (baseline). Function-scoped for memory cleanup."""
      from virnucpro.models.esm2_flash import load_esm2_model

      model, batch_converter = load_esm2_model(
          model_name="esm2_t36_3B_UR50D",
          device="cuda:0",
          enable_fp16=False
      )

      yield model, batch_converter

      # Explicit cleanup to free ~22GB before next model loads
      del model
      del batch_converter
      torch.cuda.empty_cache()
      gc.collect()

  @pytest.fixture(scope="function")
  def esm_model_fp16():
      """Load ESM-2 in FP16. Function-scoped for memory cleanup."""
      from virnucpro.models.esm2_flash import load_esm2_model

      # Ensure previous model fully cleaned up
      torch.cuda.empty_cache()

      model, batch_converter = load_esm2_model(
          model_name="esm2_t36_3B_UR50D",
          device="cuda:0",
          enable_fp16=True
      )

      yield model, batch_converter

      # Cleanup
      del model
      del batch_converter
      torch.cuda.empty_cache()
      gc.collect()
  ```

  **Memory management:** Function-scoped fixtures with explicit cleanup ensure sequential loading (FP32 → cleanup → FP16) instead of concurrent (FP32 + FP16). This reduces peak memory from ~40GB to ~22GB, fitting A100-40GB. Tests run slower but are reliable on standard hardware.

  **Helper function:**
  ```python
  def compare_embeddings(model_fp16, model_fp32, batch_converter, sequences, device, threshold=0.99):
      """Compare FP16 vs FP32 embeddings for a list of sequences."""
      labels, strs, tokens = batch_converter(sequences)
      tokens = tokens.to(device)

      with torch.no_grad():
          # FP32 baseline
          out_fp32 = model_fp32(tokens, repr_layers=[36])
          emb_fp32 = out_fp32["representations"][36]

          # FP16
          out_fp16 = model_fp16(tokens, repr_layers=[36])
          emb_fp16 = out_fp16["representations"][36]

      similarities = {}
      for i, (seq_id, seq_str) in enumerate(sequences):
          seq_len = min(len(seq_str), 1024)
          # Mean pool (skip BOS token at position 0)
          e32 = emb_fp32[i, 1:seq_len+1].mean(dim=0).float()
          e16 = emb_fp16[i, 1:seq_len+1].mean(dim=0).float()
          sim = torch.nn.functional.cosine_similarity(e32, e16, dim=0).item()
          similarities[seq_id] = sim

      min_sim = min(similarities.values())
      mean_sim = sum(similarities.values()) / len(similarities)
      failed = [sid for sid, s in similarities.items() if s < threshold]

      return {
          "passed": len(failed) == 0,
          "min_similarity": min_sim,
          "mean_similarity": mean_sim,
          "per_sequence": similarities,
          "failed_sequences": failed,
      }
  ```

  **class TestFP16Equivalence:**
  - `test_short_sequences_fp16_match` - 5 sequences <50 aa, threshold 0.99
  - `test_medium_sequences_fp16_match` - 3 sequences 50-200 aa, threshold 0.99
  - `test_long_sequences_fp16_match` - 2 sequences 200-500 aa, threshold 0.99
  - `test_mixed_lengths_fp16_match` - Mix of short/medium/long (7+ sequences), threshold 0.99

  Use biologically realistic amino acid sequences (varied compositions like the packed equivalence tests). Example short: "MKTAYIAK", "VLSPADKTNV", "MVHLTPEEK". For medium: "MKTAYIAK" * 10, etc. For long: "VLSPADKTNVKAAWGKVG" * 20, etc.

  **class TestFP16PackedEquivalence:**
  **Purpose:** Test the production code path (forward_packed) which differs from standard forward due to RoPE timing, FlashAttention kernels, and packing boundaries.

  - `test_packed_inference_fp16_vs_fp32` - Compare FP16 vs FP32 specifically in forward_packed() code path:
    ```python
    def test_packed_inference_fp16_vs_fp32(self, esm_model_fp16, esm_model_fp32):
        """Verify FP16 forward_packed matches FP32 forward_packed."""
        from virnucpro.data.collators import VarlenCollator
        from virnucpro.data.packing import GreedyPacker

        # Create packed batch
        sequences = [
            ("seq1", "MKTAYIAKQRQISFV"),
            ("seq2", "VLSPADKTNVKAAWGKVG"),
            ("seq3", "MVHLTPEEKSAVTALWG")
        ]

        # Tokenize and pack (use small token budget for test)
        packer = GreedyPacker(token_budget=128)
        packed = packer.pack(sequences)  # Returns packed batch dict

        # Compare forward_packed() outputs
        with torch.no_grad():
            out_fp32 = esm_model_fp32.forward_packed(
                input_ids=packed["input_ids"].to("cuda:0"),
                cu_seqlens=packed["cu_seqlens"].to("cuda:0"),
                max_seqlen=packed["max_seqlen"]
            )
            out_fp16 = esm_model_fp16.forward_packed(
                input_ids=packed["input_ids"].to("cuda:0"),
                cu_seqlens=packed["cu_seqlens"].to("cuda:0"),
                max_seqlen=packed["max_seqlen"]
            )

        # Compare embeddings (both should be [total_tokens, hidden_dim])
        similarity = F.cosine_similarity(
            out_fp32.float(),
            out_fp16.float(),
            dim=-1
        )
        assert similarity.mean() > 0.99, f"Packed FP16 similarity {similarity.mean():.4f} < 0.99"
    ```

  - `test_packed_long_sequences_fp16` - Test forward_packed with sequences >400aa (stresses RoPE and FlashAttention with FP16)
  - `test_packed_boundary_effects_fp16` - Test cu_seqlens boundaries don't cause FP16 precision issues at sequence transitions

  **class TestFP16NumericalStability:**
  - `test_no_nan_in_fp16_embeddings` - Run 10 sequences through FP16 model, verify no NaN in output
  - `test_no_inf_in_fp16_embeddings` - Run 10 sequences through FP16 model, verify no Inf in output
  - `test_fp16_embedding_magnitude_reasonable` - Verify embedding L2 norms are finite and within reasonable range (e.g., 1-1000)

  **class TestFP16StatisticalValidation:**
  **Purpose:** Validate embedding distributions match statistically (beyond cosine similarity).

  - `test_mean_std_similar` - Compare mean and std of FP16 vs FP32 embeddings with realistic thresholds:
    ```python
    def test_mean_std_similar(self, esm_model_fp16, esm_model_fp32):
        """Compare embedding statistics with realistic thresholds for ESM-2."""
        # Run inference on 10 sequences
        sequences = [...]  # Mix of short/medium/long
        # ... get embeddings ...

        # ESM-2 embeddings: mean ≈ 0.0, std ≈ 0.5-1.5
        fp32_mean = emb_fp32.mean().item()
        fp16_mean = emb_fp16.float().mean().item()
        mean_abs_diff = abs(fp32_mean - fp16_mean)

        # Realistic threshold: absolute difference <0.01 (not 0.1)
        # FP16 mantissa is 10 bits, expect ~1e-3 precision
        assert mean_abs_diff < 0.01, f"Mean diff {mean_abs_diff:.4f} exceeds 0.01"

        fp32_std = emb_fp32.std().item()
        fp16_std = emb_fp16.float().std().item()
        std_rel_diff = abs(fp32_std - fp16_std) / fp32_std

        # Relative threshold: <5% difference (not absolute 0.1)
        assert std_rel_diff < 0.05, f"Std relative diff {std_rel_diff:.4f} exceeds 5%"

        print(f"Mean: FP32={fp32_mean:.6f}, FP16={fp16_mean:.6f}, diff={mean_abs_diff:.6f}")
        print(f"Std: FP32={fp32_std:.6f}, FP16={fp16_std:.6f}, rel_diff={std_rel_diff:.4f}")
    ```

  - `test_l2_norm_distribution_similar` - Compare L2 norm distributions. Mean norm relative difference should be <5%.
  - `test_outlier_count_similar` - Count Z-score >3 outliers in both. Outlier count difference should be <10% of total elements.

  All test methods should print summary statistics for visibility during test runs.
  </action>
  <verify>
  Run: `pytest tests/integration/test_fp16_validation.py -v --tb=short` (on GPU server) -- all tests pass
  Run: `pytest tests/integration/test_fp16_validation.py -v -k "short"` -- quick validation
  Run: `pytest tests/integration/test_fp16_validation.py -v -k "packed"` -- validate forward_packed() code path
  Run: `nvidia-smi` during test run -- verify peak memory <40GB (fits A100-40GB with sequential loading)
  Verify: `wc -l tests/integration/test_fp16_validation.py` -- at least 200 lines (added TestFP16PackedEquivalence)
  Verify: `grep -n "scope=\"function\"" tests/integration/test_fp16_validation.py` -- fixtures are function-scoped for cleanup
  Verify: `grep -n "torch.cuda.empty_cache" tests/integration/test_fp16_validation.py` -- explicit cleanup present
  </verify>
  <done>
  FP16 vs FP32 equivalence validated with >0.99 cosine similarity across short/medium/long sequences in BOTH standard forward and forward_packed() code paths. No NaN/Inf detected. Statistical properties (mean <0.01 diff, std <5% rel diff, L2 norms, outliers) match between FP16 and FP32 with realistic thresholds. Sequential model loading with explicit cleanup fits A100-40GB memory constraints. This proves FP16 is safe for VirNucPro production workloads.
  </done>
</task>

</tasks>

<verification>
- `pytest tests/integration/test_fp16_validation.py -v` -- all tests pass on GPU
- Cosine similarity >0.99 for all tested sequences (standard forward AND forward_packed)
- No NaN/Inf in any FP16 outputs
- Statistical validation confirms distributions match with realistic thresholds
- Peak GPU memory <40GB during test run (verified with nvidia-smi)
- Function-scoped fixtures with explicit cleanup prevent CUDA OOM
</verification>

<success_criteria>
- All FP16 vs FP32 tests pass with >0.99 cosine similarity
- FP16 forward_packed() matches FP32 forward_packed() (production code path validated)
- Stratified validation covers short (<50 aa), medium (50-200 aa), and long (200-500 aa) sequences
- No NaN/Inf detected in any FP16 embeddings
- Statistical analysis confirms distributions match with realistic thresholds (mean <0.01 abs diff, std <5% rel diff)
- Sequential model loading with function-scoped fixtures fits A100-40GB memory constraints
- Explicit cleanup (torch.cuda.empty_cache, gc.collect) prevents CUDA OOM from leaked memory
- Test file follows existing test_packed_equivalence.py patterns
</success_criteria>

<notes>
**Deferred enhancements (optional - can add during execution or Phase 10):**

1. **Gradient checkpointing interaction test:** Test FP16 stability with gradient checkpointing enabled (if model supports it). Checkpointing affects memory pressure and can alter numerical precision due to recomputation. While valuable, checkpointing is primarily a training concern - inference mode doesn't use it. If added:
   ```python
   @pytest.mark.gpu
   def test_fp16_with_gradient_checkpointing(self, esm_model_fp16):
       if hasattr(esm_model_fp16.model, 'gradient_checkpointing_enable'):
           esm_model_fp16.model.gradient_checkpointing_enable()
       # Run inference on long sequences (stresses checkpointing)
       # Verify no NaN/Inf (checkpointing can cause precision issues)
   ```

2. **Smaller model fallback:** For development on GPUs with <40GB memory, add pytest parametrize to test on esm2_t33_650M (1.3GB FP32) as alternative. Note in README that 3B validation should be done on GPU server before production deployment.
</notes>

<output>
After completion, create `.planning/phases/08-fp16-precision-validation**---memory-and-speed-optimization/08-03-SUMMARY.md`
</output>
