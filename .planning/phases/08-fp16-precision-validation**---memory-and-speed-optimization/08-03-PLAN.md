---
phase: 08-fp16-precision-validation
plan: 03
type: execute
wave: 2
depends_on: ["08-01", "08-02"]
files_modified:
  - tests/integration/test_fp16_validation.py
autonomous: true

must_haves:
  truths:
    - "FP16 ESM-2 embeddings have cosine similarity >0.99 vs FP32 baseline"
    - "Short, medium, and long sequences all pass similarity threshold"
    - "No NaN/Inf detected in FP16 embeddings"
    - "Embedding distribution statistics (mean, std, norms) similar between FP16 and FP32"
  artifacts:
    - path: "tests/integration/test_fp16_validation.py"
      provides: "FP16 vs FP32 equivalence validation with stratified testing"
      min_lines: 150
      exports: ["TestFP16Equivalence", "TestFP16NumericalStability", "TestFP16StatisticalValidation"]
  key_links:
    - from: "tests/integration/test_fp16_validation.py"
      to: "virnucpro/models/esm2_flash.py"
      via: "load_esm2_model with enable_fp16=True and enable_fp16=False"
      pattern: "load_esm2_model.*enable_fp16"
---

<objective>
Validate FP16 embeddings match FP32 baseline via GPU integration tests with stratified sequence testing.

Purpose: This is the core validation proving FP16 works for the VirNucPro workload. Tests compare FP16 vs FP32 embeddings across short/medium/long sequences, detect NaN/Inf, and validate statistical properties. This is the one-time thorough validation described in CONTEXT.md.

Output: GPU integration test file that validates FP16 correctness with >0.99 cosine similarity threshold.
</objective>

<execution_context>
@/home/unix/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/unix/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/08-fp16-precision-validation**---memory-and-speed-optimization/08-CONTEXT.md
@.planning/phases/08-fp16-precision-validation**---memory-and-speed-optimization/08-RESEARCH.md
@tests/integration/test_packed_equivalence.py
@virnucpro/models/esm2_flash.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create FP16 vs FP32 equivalence integration tests</name>
  <files>tests/integration/test_fp16_validation.py</files>
  <action>
  Create `tests/integration/test_fp16_validation.py` following the pattern from `test_packed_equivalence.py`.

  **Module header:**
  ```python
  """Integration tests for FP16 vs FP32 embedding equivalence.

  These tests require GPU and ESM-2 model. They validate that FP16 precision
  produces embeddings matching FP32 baseline (cosine similarity >0.99).

  This is the one-time thorough validation proving FP16 works for VirNucPro.
  """
  ```

  Skip entire module if CUDA unavailable:
  ```python
  pytestmark = pytest.mark.skipif(
      not torch.cuda.is_available(),
      reason="CUDA required for FP16 validation tests"
  )
  ```

  **Fixtures (module scope for model reuse):**

  ```python
  @pytest.fixture(scope="module")
  def esm_model_fp16():
      """Load ESM-2 in FP16."""
      from virnucpro.models.esm2_flash import load_esm2_model
      model, batch_converter = load_esm2_model(
          model_name="esm2_t36_3B_UR50D",
          device="cuda:0",
          enable_fp16=True
      )
      return model, batch_converter

  @pytest.fixture(scope="module")
  def esm_model_fp32():
      """Load ESM-2 in FP32 (baseline)."""
      from virnucpro.models.esm2_flash import load_esm2_model
      model, batch_converter = load_esm2_model(
          model_name="esm2_t36_3B_UR50D",
          device="cuda:0",
          enable_fp16=False
      )
      return model, batch_converter
  ```

  Note: Loading two 3B models requires ~22GB GPU memory. If this is a problem, use a smaller model variant. But try 3B first since it's the production model.

  **Helper function:**
  ```python
  def compare_embeddings(model_fp16, model_fp32, batch_converter, sequences, device, threshold=0.99):
      """Compare FP16 vs FP32 embeddings for a list of sequences."""
      labels, strs, tokens = batch_converter(sequences)
      tokens = tokens.to(device)

      with torch.no_grad():
          # FP32 baseline
          out_fp32 = model_fp32(tokens, repr_layers=[36])
          emb_fp32 = out_fp32["representations"][36]

          # FP16
          out_fp16 = model_fp16(tokens, repr_layers=[36])
          emb_fp16 = out_fp16["representations"][36]

      similarities = {}
      for i, (seq_id, seq_str) in enumerate(sequences):
          seq_len = min(len(seq_str), 1024)
          # Mean pool (skip BOS token at position 0)
          e32 = emb_fp32[i, 1:seq_len+1].mean(dim=0).float()
          e16 = emb_fp16[i, 1:seq_len+1].mean(dim=0).float()
          sim = torch.nn.functional.cosine_similarity(e32, e16, dim=0).item()
          similarities[seq_id] = sim

      min_sim = min(similarities.values())
      mean_sim = sum(similarities.values()) / len(similarities)
      failed = [sid for sid, s in similarities.items() if s < threshold]

      return {
          "passed": len(failed) == 0,
          "min_similarity": min_sim,
          "mean_similarity": mean_sim,
          "per_sequence": similarities,
          "failed_sequences": failed,
      }
  ```

  **class TestFP16Equivalence:**
  - `test_short_sequences_fp16_match` - 5 sequences <50 aa, threshold 0.99
  - `test_medium_sequences_fp16_match` - 3 sequences 50-200 aa, threshold 0.99
  - `test_long_sequences_fp16_match` - 2 sequences 200-500 aa, threshold 0.99
  - `test_mixed_lengths_fp16_match` - Mix of short/medium/long (7+ sequences), threshold 0.99

  Use biologically realistic amino acid sequences (varied compositions like the packed equivalence tests). Example short: "MKTAYIAK", "VLSPADKTNV", "MVHLTPEEK". For medium: "MKTAYIAK" * 10, etc. For long: "VLSPADKTNVKAAWGKVG" * 20, etc.

  **class TestFP16NumericalStability:**
  - `test_no_nan_in_fp16_embeddings` - Run 10 sequences through FP16 model, verify no NaN in output
  - `test_no_inf_in_fp16_embeddings` - Run 10 sequences through FP16 model, verify no Inf in output
  - `test_fp16_embedding_magnitude_reasonable` - Verify embedding L2 norms are finite and within reasonable range (e.g., 1-1000)

  **class TestFP16StatisticalValidation:**
  - `test_mean_std_similar` - Compare mean and std of FP16 vs FP32 embeddings. Mean difference should be <0.1, std difference <0.1.
  - `test_l2_norm_distribution_similar` - Compare L2 norm distributions. Mean norm difference should be <5%.
  - `test_outlier_count_similar` - Count Z-score >3 outliers in both. Outlier count difference should be <10% of total elements.

  All test methods should print summary statistics for visibility during test runs.
  </action>
  <verify>
  Run: `pytest tests/integration/test_fp16_validation.py -v --tb=short` (on GPU server) -- all tests pass
  Run: `pytest tests/integration/test_fp16_validation.py -v -k "short"` -- quick validation
  Verify: `wc -l tests/integration/test_fp16_validation.py` -- at least 150 lines
  </verify>
  <done>
  FP16 vs FP32 equivalence validated with >0.99 cosine similarity across short/medium/long sequences. No NaN/Inf detected. Statistical properties (mean, std, L2 norms, outliers) match between FP16 and FP32. This proves FP16 is safe for VirNucPro production workloads.
  </done>
</task>

</tasks>

<verification>
- `pytest tests/integration/test_fp16_validation.py -v` -- all tests pass on GPU
- Cosine similarity >0.99 for all tested sequences
- No NaN/Inf in any FP16 outputs
- Statistical validation confirms embedding distributions match
</verification>

<success_criteria>
- All FP16 vs FP32 tests pass with >0.99 cosine similarity
- Stratified validation covers short (<50 aa), medium (50-200 aa), and long (200-500 aa) sequences
- No NaN/Inf detected in any FP16 embeddings
- Statistical analysis confirms mean, std, and L2 norm distributions match
- Test file follows existing test_packed_equivalence.py patterns
</success_criteria>

<output>
After completion, create `.planning/phases/08-fp16-precision-validation**---memory-and-speed-optimization/08-03-SUMMARY.md`
</output>
