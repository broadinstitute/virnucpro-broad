---
phase: 11-code-quality-foundations
plan: 03
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - virnucpro/pipeline/async_inference.py
  - tests/unit/test_async_inference.py
autonomous: true

must_haves:
  truths:
    - "AsyncInferenceRunner.run() delegates to focused private methods instead of inlining all logic"
    - "Each extracted method has a clear single responsibility"
    - "No method exceeds ~100 lines (with flexibility for natural boundaries)"
    - "All existing async_inference tests pass unchanged"
  artifacts:
    - path: "virnucpro/pipeline/async_inference.py"
      provides: "Refactored AsyncInferenceRunner with focused methods"
      contains: "_resume_from_checkpoints"
    - path: "tests/unit/test_async_inference.py"
      provides: "Unchanged existing tests (behavior equivalence)"
  key_links:
    - from: "virnucpro/pipeline/async_inference.py"
      to: "virnucpro/core/env_config.py"
      via: "get_env_config() for VIRNUCPRO_DISABLE_PACKING"
      pattern: "get_env_config"
---

<objective>
Refactor `AsyncInferenceRunner.run()` (currently ~440 lines, line 533-976) into focused helper methods.

Purpose: Addresses QUAL-03. The run() method contains checkpoint resumption, DataLoader iteration, collation, progress logging, packing efficiency computation, checkpoint accumulation, buffer flushing, and cleanup all inlined. Extract these into named methods that each do one thing.

Output: run() as a clean orchestrator calling focused helpers, all existing tests passing.
</objective>

<execution_context>
@/home/unix/carze/.claude/get-shit-done/workflows/execute-plan.md
@/home/unix/carze/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@virnucpro/pipeline/async_inference.py (run() method lines 533-976)
@.planning/phases/11-code-quality-foundations/11-01-SUMMARY.md (EnvConfig for env var access)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extract checkpoint resume, batch processing loop, and flush into methods</name>
  <files>virnucpro/pipeline/async_inference.py</files>
  <action>
    Refactor AsyncInferenceRunner.run() by extracting these focused methods. The run() method should become a clean orchestrator that reads top-to-bottom.

    **Methods to extract:**

    1. `_resume_checkpoints(self, force_restart: bool) -> Optional[InferenceResult]`
       Extract lines 578-613 (checkpoint resume logic). Returns an InferenceResult if resumed data exists, None otherwise. Updates self._ckpt_embeddings, self._ckpt_ids, self._ckpt_batch_idx.

    2. `_process_raw_item(self, raw_item, collator, main_process_collation: bool) -> Optional[Dict]`
       Extract lines 657-668 (collation dispatch). Takes raw item from DataLoader, returns collated batch or None if empty/not ready.

    3. `_record_batch_metrics(self, batch: Dict, result: InferenceResult, batch_idx: int, fetch_time_ms: float)`
       Extract lines 687-714 (packing efficiency computation and monitor recording). Handles DataLoader metric recording.

    4. `_log_progress(self, batch_idx: int, total_sequences_processed: int, dataloader: DataLoader, processing_start_time: float)`
       Extract lines 723-770 (adaptive progress logging with ETA calculation). Contains the should_log_progress heuristic and the formatted log message.

    5. `_accumulate_and_checkpoint(self, result: InferenceResult)`
       Extract lines 779-804 (checkpoint accumulation, trigger check, write). Handles all checkpoint bookkeeping after yielding a result.

    6. `_flush_collator(self, collator) -> Iterator[InferenceResult]`
       Extract lines 808-823 (collator buffer flush). Yields remaining results from flush.

    7. `_finalize(self, processing_start_time: float)`
       Extract lines 825-860 (final checkpoint, writer shutdown, stream sync, final logging). Called in the finally block.

    **Update _run_inference to use EnvConfig:**
    In `_run_inference()` (line 301-302), replace the inline `os.getenv('VIRNUCPRO_DISABLE_PACKING')` with:
    ```python
    from virnucpro.core.env_config import get_env_config
    env = get_env_config()
    DISABLE_PACKING = env.disable_packing
    ```
    Remove the `import os` that's inside the method (line 301).

    **Also update _write_checkpoint:**
    In `_write_checkpoint()` (line 892), replace `os.environ.get("VIRNUCPRO_DISABLE_PACKING", "")` with:
    ```python
    from virnucpro.core.env_config import get_env_config
    env = get_env_config()
    'packing_enabled': not env.disable_packing,
    ```

    **The refactored run() should look roughly like:**
    ```python
    def run(self, dataloader, progress_callback=None, force_restart=False):
        self.model.eval()
        self.monitor.start_monitoring()
        self.monitor.start_inference_timer()
        self.monitor.set_stage('inference')
        logger.info("Starting async inference loop")

        main_process_collation = self._is_main_process_collation(dataloader)
        collator = self._get_collator(dataloader)
        # ... log main_process_collation mode ...

        # Resume from checkpoints
        resumed_result = self._resume_checkpoints(force_restart)
        if resumed_result:
            yield resumed_result

        # Main batch loop
        processing_start_time = time.perf_counter()
        total_sequences_processed = 0
        # ... dataset info logging ...

        try:
            dataloader_iter = iter(dataloader)
            batch_idx = 0
            while True:
                # fetch raw_item with timing and error handling
                batch = self._process_raw_item(raw_item, collator, main_process_collation)
                if batch is None:
                    continue
                # ... first-batch validation ...
                result = self.process_batch(batch)
                self._record_batch_metrics(batch, result, batch_idx, fetch_time_ms)
                total_sequences_processed += len(result.sequence_ids)
                self._log_progress(batch_idx, total_sequences_processed, dataloader, processing_start_time)
                if progress_callback:
                    progress_callback(batch_idx, len(result.sequence_ids))
                yield result
                self._accumulate_and_checkpoint(result)
                batch_idx += 1

            # Flush remaining
            yield from self._flush_collator(collator)
        finally:
            self._finalize(processing_start_time)
    ```

    Important constraints:
    - The `yield` statements must stay in run() (generators can't delegate yields to non-generator helpers except via `yield from`)
    - The try/except for DataLoader errors stays in run() (it needs to break/continue the while loop)
    - Keep the first-batch validation (pinned memory check + buffering time log) inline in run() since it's a one-time check guarded by batch_idx == 0
    - Use `yield from` for _flush_collator since it's a generator
  </action>
  <verify>
    pytest tests/unit/test_async_inference.py -v -x
    # Verify method extraction
    grep -c "def _" virnucpro/pipeline/async_inference.py
    # Should show more private methods than before
  </verify>
  <done>
    run() is a clean orchestrator under ~80 lines. Helper methods each handle one concern. All existing tests pass. Environment variable access uses EnvConfig.
  </done>
</task>

</tasks>

<verification>
pytest tests/unit/test_async_inference.py -v
pytest tests/unit/test_gpu_worker.py -v  # gpu_worker uses AsyncInferenceRunner
# All tests pass with refactored code
</verification>

<success_criteria>
- run() method is a clean orchestrator, no longer 440+ lines
- Each extracted method has a single clear responsibility
- os.getenv/os.environ.get for VIRNUCPRO_DISABLE_PACKING replaced with EnvConfig
- All existing tests pass (1:1 behavior equivalence)
</success_criteria>

<output>
After completion, create `.planning/phases/11-code-quality-foundations/11-03-SUMMARY.md`
</output>
