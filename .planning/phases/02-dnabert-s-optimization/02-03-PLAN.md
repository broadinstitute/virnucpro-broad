---
phase: 02-dnabert-s-optimization
plan: 03
type: execute
wave: 3
depends_on: [02-01, 02-02]
files_modified: [virnucpro/pipeline/prediction.py, virnucpro/cli/predict.py, virnucpro/pipeline/profiler.py]
autonomous: true

must_haves:
  truths:
    - "Pipeline automatically uses parallel DNABERT-S when multiple GPUs available"
    - "CLI accepts --dnabert-batch-size flag for tuning"
    - "Profiler can determine optimal batch sizes"
    - "Sequential execution order maintained (DNABERT-S then ESM-2)"
  artifacts:
    - path: "virnucpro/pipeline/prediction.py"
      provides: "Updated pipeline with parallel DNABERT-S integration"
      contains: "from virnucpro.pipeline.parallel_dnabert import"
    - path: "virnucpro/cli/predict.py"
      provides: "CLI with --dnabert-batch-size flag"
      contains: "--dnabert-batch-size"
    - path: "virnucpro/pipeline/profiler.py"
      provides: "Batch size profiling utilities"
      min_lines: 100
      exports: ["profile_dnabert_batch_size", "profile_esm_batch_size"]
  key_links:
    - from: "virnucpro/pipeline/prediction.py"
      to: "virnucpro/pipeline/parallel_dnabert.py"
      via: "import and usage"
      pattern: "process_dnabert_files_worker"
    - from: "virnucpro/cli/predict.py"
      to: "--dnabert-batch-size"
      via: "argparse"
      pattern: "add_argument.*dnabert-batch-size"
---

<objective>
Integrate parallel DNABERT-S into the prediction pipeline with CLI support and create batch size profiling utilities.

Purpose: Enable users to leverage multi-GPU DNABERT-S processing with tunable batch sizes and provide tools to find optimal settings.
Output: Updated pipeline using parallel DNABERT-S, CLI flag for batch size tuning, and profiling utilities.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Previous plans' outputs
@.planning/phases/02-dnabert-s-optimization/02-01-SUMMARY.md
@.planning/phases/02-dnabert-s-optimization/02-02-SUMMARY.md

# Files to integrate with
@virnucpro/pipeline/prediction.py
@virnucpro/cli/predict.py
@virnucpro/pipeline/work_queue.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate parallel DNABERT-S into prediction pipeline</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Update the prediction pipeline to use parallel DNABERT-S processing when multiple GPUs are available.

    Integration points:
    1. Import parallel DNABERT-S functions:
       - from virnucpro.pipeline.parallel_dnabert import process_dnabert_files_worker, assign_files_by_sequences
       - from virnucpro.pipeline.work_queue import BatchQueueManager

    2. Modify DNABERT-S extraction logic:
       - Check if parallel processing enabled (multiple GPUs or --parallel flag)
       - If parallel: use BatchQueueManager with process_dnabert_files_worker
       - If not: fall back to existing sequential extraction
       - Match the pattern used for ESM-2 parallel processing

    3. Maintain sequential execution order:
       - Translation completes first (if using parallel translation)
       - Then DNABERT-S extraction (parallel if available)
       - Then ESM-2 extraction (parallel if available)
       - Finally prediction on merged features

    4. Handle batch size parameter:
       - Accept dnabert_batch_size parameter (default: 2048)
       - Pass to worker function for token-based batching

    5. GPU assignment:
       - Use same GPU list for both DNABERT-S and ESM-2
       - Auto-detect if not specified (matching Phase 1 pattern)

    Preserve all existing functionality - this should be additive, not breaking.
  </action>
  <verify>grep -n "from virnucpro.pipeline.parallel_dnabert" virnucpro/pipeline/prediction.py && grep -n "process_dnabert_files_worker" virnucpro/pipeline/prediction.py</verify>
  <done>prediction.py updated to use parallel DNABERT-S with automatic GPU detection and fallback</done>
</task>

<task type="auto">
  <name>Task 2: Add CLI support for DNABERT-S batch size</name>
  <files>virnucpro/cli/predict.py</files>
  <action>
    Add command-line flag for DNABERT-S batch size tuning, matching ESM-2 pattern.

    CLI additions:
    1. Add --dnabert-batch-size argument:
       - Type: int
       - Default: 2048
       - Help: "Token batch size for DNABERT-S processing (default: 2048, with BF16: 3072)"
       - Place near --esm-batch-size for consistency

    2. Pass parameter to pipeline:
       - Add dnabert_batch_size to the predict pipeline call
       - Ensure it reaches the DNABERT-S worker function

    3. Update help text:
       - Document that both --dnabert-batch-size and --esm-batch-size can be tuned
       - Note that BF16 automatically increases defaults when available

    Follow the exact pattern used for --esm-batch-size implementation.
  </action>
  <verify>grep -n "dnabert-batch-size" virnucpro/cli/predict.py && python -m virnucpro predict --help | grep "dnabert-batch-size"</verify>
  <done>CLI updated with --dnabert-batch-size flag matching ESM-2 pattern</done>
</task>

<task type="auto">
  <name>Task 3: Create batch size profiling utilities</name>
  <files>virnucpro/pipeline/profiler.py</files>
  <action>
    Create profiling utilities to help users find optimal batch sizes for their GPU hardware.

    Profiler implementation:
    1. profile_dnabert_batch_size() function:
       - Takes: device, test_sequence_file (optional), min_batch, max_batch, step
       - Tests batch sizes from min to max in increments
       - Measures: throughput (sequences/second), memory usage, success/OOM
       - Returns: dict with optimal_batch_size, throughput_curve, memory_curve

    2. profile_esm_batch_size() function:
       - Similar to DNABERT but for ESM-2 model
       - Uses toks_per_batch instead of sequence count

    3. Shared utilities:
       - measure_gpu_memory(): Get current GPU memory usage
       - create_test_sequences(): Generate synthetic test data if not provided
       - binary_search_max_batch(): Find maximum batch size before OOM

    4. Safety features:
       - Catch CUDA OOM errors and reduce batch size
       - Clear CUDA cache between tests
       - Use torch.no_grad() for all profiling

    5. Reporting:
       - Log results in structured format
       - Suggest optimal batch size (80% of max to leave headroom)
       - Show throughput vs batch size curve

    This helps users optimize for their specific hardware without manual trial and error.
  </action>
  <verify>grep -n "profile_dnabert_batch_size" virnucpro/pipeline/profiler.py && grep -n "profile_esm_batch_size" virnucpro/pipeline/profiler.py</verify>
  <done>profiler.py created with batch size profiling utilities for both models</done>
</task>

</tasks>

<verification>
1. Test parallel DNABERT-S integration in pipeline
2. Verify CLI flag is recognized and passed through
3. Check profiler can find optimal batch sizes
4. Confirm backward compatibility maintained
</verification>

<success_criteria>
- Pipeline uses parallel DNABERT-S when multiple GPUs available
- --dnabert-batch-size CLI flag works correctly
- Profiler successfully determines optimal batch sizes
- Sequential execution order maintained (DNABERT-S before ESM-2)
- No breaking changes to existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/02-dnabert-s-optimization/02-03-SUMMARY.md`
</output>