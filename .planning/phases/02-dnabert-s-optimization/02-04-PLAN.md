---
phase: 02-dnabert-s-optimization
plan: 04
type: execute
wave: 4
depends_on: [02-03]
files_modified: [virnucpro/pipeline/profiler.py, virnucpro/cli/profile.py]
autonomous: true

must_haves:
  truths:
    - "Profiler can determine optimal batch sizes for user's GPU"
    - "Profiler accessible via CLI command"
    - "Users get concrete recommendations for their hardware"
  artifacts:
    - path: "virnucpro/pipeline/profiler.py"
      provides: "Batch size profiling utilities"
      min_lines: 100
      exports: ["profile_dnabert_batch_size", "profile_esm_batch_size"]
    - path: "virnucpro/cli/profile.py"
      provides: "CLI command for profiling"
      contains: "profile_batch_sizes"
  key_links:
    - from: "virnucpro/cli/profile.py"
      to: "virnucpro/pipeline/profiler.py"
      via: "import and usage"
      pattern: "profile_dnabert_batch_size"
---

<objective>
Create batch size profiling utilities with CLI integration for finding optimal GPU settings.

Purpose: Provide tools to help users find optimal batch sizes for their specific GPU hardware.
Output: Profiling utilities and CLI command for batch size optimization.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Previous implementation
@.planning/phases/02-dnabert-s-optimization/02-01-SUMMARY.md
@.planning/phases/02-dnabert-s-optimization/02-02-SUMMARY.md
@.planning/phases/02-dnabert-s-optimization/02-03-SUMMARY.md

# CLI patterns to follow
@virnucpro/cli/predict.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create batch size profiling utilities</name>
  <files>virnucpro/pipeline/profiler.py</files>
  <action>
    Create profiling utilities to help users find optimal batch sizes for their GPU hardware.

    Profiler implementation:
    1. profile_dnabert_batch_size() function:
       - Takes: device, test_sequence_file (optional), min_batch, max_batch, step
       - Tests batch sizes from min to max in increments
       - Measures: throughput (sequences/second), memory usage, success/OOM
       - Returns: dict with optimal_batch_size, throughput_curve, memory_curve

    2. profile_esm_batch_size() function:
       - Similar to DNABERT but for ESM-2 model
       - Uses toks_per_batch instead of sequence count

    3. Shared utilities:
       - measure_gpu_memory(): Get current GPU memory usage
       - create_test_sequences(): Generate synthetic test data if not provided
       - binary_search_max_batch(): Find maximum batch size before OOM

    4. Safety features:
       - Catch CUDA OOM errors and reduce batch size
       - Clear CUDA cache between tests
       - Use torch.no_grad() for all profiling

    5. Reporting:
       - Log results in structured format
       - Suggest optimal batch size (80% of max to leave headroom)
       - Show throughput vs batch size curve

    This helps users optimize for their specific hardware without manual trial and error.
  </action>
  <verify>grep -n "profile_dnabert_batch_size" virnucpro/pipeline/profiler.py && grep -n "profile_esm_batch_size" virnucpro/pipeline/profiler.py</verify>
  <done>profiler.py created with batch size profiling utilities for both models</done>
</task>

<task type="auto">
  <name>Task 2: Add CLI command for profiling</name>
  <files>virnucpro/cli/profile.py</files>
  <action>
    Create CLI command for accessing the profiling utilities.

    CLI implementation:
    1. Create profile subcommand:
       - virnucpro profile --model dnabert-s --device cuda:0
       - virnucpro profile --model esm2 --device cuda:0
       - Options for min/max/step batch sizes

    2. Integration with profiler:
       - Import profiling functions from virnucpro.pipeline.profiler
       - Call appropriate profile function based on --model flag
       - Display results in user-friendly format

    3. Output format:
       - Show recommended batch size prominently
       - Display throughput curve as ASCII chart or table
       - Save detailed results to JSON file if --output specified

    4. Help text:
       - Clear explanation of what profiling does
       - Examples of common usage
       - Note about memory requirements

    This makes profiling accessible without writing Python code.
  </action>
  <verify>grep -n "profile" virnucpro/cli/profile.py && python -m virnucpro profile --help</verify>
  <done>CLI profile command created for easy access to profiling utilities</done>
</task>

</tasks>

<verification>
1. Test profiler can find optimal batch sizes
2. Verify CLI command works correctly
3. Check output provides actionable recommendations
</verification>

<success_criteria>
- Profiler successfully determines optimal batch sizes
- CLI provides easy access to profiling functionality
- Users get concrete batch size recommendations for their hardware
- Profiler integrates smoothly with existing pipeline
</success_criteria>

<output>
After completion, create `.planning/phases/02-dnabert-s-optimization/02-04-SUMMARY.md`
</output>