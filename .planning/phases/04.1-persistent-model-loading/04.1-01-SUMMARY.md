---
phase: 04.1-persistent-model-loading
plan: 01
subsystem: pipeline
tags: [multiprocessing, pytorch, gpu, memory-management, persistent-workers]

# Dependency graph
requires:
  - phase: 04-memory-optimization
    provides: FlashAttention-2 integration and BF16 dtype fixes
provides:
  - PersistentWorkerPool class for long-lived workers with model caching
  - BatchQueueManager persistent pool support (opt-in)
  - Memory management infrastructure for fragmentation prevention
affects: [04.1-02, future-pipeline-optimization]

# Tech tracking
tech-stack:
  added: []
  patterns:
    - "Pool initializer with lazy model loading"
    - "Module-level globals for model persistence"
    - "Periodic CUDA cache clearing (every 10 files)"
    - "Expandable segments memory configuration"

key-files:
  created:
    - virnucpro/pipeline/persistent_pool.py
  modified:
    - virnucpro/pipeline/work_queue.py

key-decisions:
  - "Lazy model loading on first task instead of during Pool init to allow device_id assignment per-worker"
  - "Opt-in persistent pool via use_persistent_pool parameter for backward compatibility"
  - "Periodic cache clearing every 10 files to prevent fragmentation"

patterns-established:
  - "Pattern: Lazy model loading in workers allows device_id to come from task arguments"
  - "Pattern: Opt-in feature flags maintain backward compatibility while enabling new capabilities"

# Metrics
duration: 4min
completed: 2026-01-24
---

# Phase 04.1 Plan 01: Persistent Model Loading Summary

**PersistentWorkerPool infrastructure with lazy model loading, CUDA memory management for fragmentation prevention, and opt-in BatchQueueManager integration**

## Performance

- **Duration:** 4 min
- **Started:** 2026-01-24T06:23:51Z
- **Completed:** 2026-01-24T06:28:09Z
- **Tasks:** 2
- **Files modified:** 2 (1 created, 1 updated)

## Accomplishments

- Created PersistentWorkerPool class with lazy model loading for ESM-2 and DNABERT-S
- Integrated persistent pool support into BatchQueueManager as opt-in feature
- Implemented memory fragmentation prevention with expandable segments and periodic cache clearing
- Maintained complete backward compatibility with existing pipeline code

## Task Commits

Each task was committed atomically:

1. **Task 1: Create PersistentWorkerPool class** - `9c22c09` (feat)
2. **Task 2: Update BatchQueueManager with persistent pool support** - `d7aee39` (feat)

## Files Created/Modified

- `virnucpro/pipeline/persistent_pool.py` - PersistentWorkerPool class for long-lived workers with model persistence (458 lines)
- `virnucpro/pipeline/work_queue.py` - Added persistent pool support via use_persistent_pool parameter and lifecycle methods

## Decisions Made

**1. Lazy model loading on first task**
- **Context:** Pool initializer runs before device_id is known (assigned per-task)
- **Decision:** Defer model loading to first task execution using _load_model_lazy()
- **Rationale:** Allows device_id to be determined from task arguments rather than hardcoded during pool initialization
- **Impact:** Workers initialize quickly, models load on first process_files_persistent() call

**2. Opt-in persistent pool via flag**
- **Context:** Existing pipeline code uses traditional per-job Pool creation
- **Decision:** Add use_persistent_pool=False default parameter to BatchQueueManager.__init__()
- **Rationale:** Maintains backward compatibility, allows gradual adoption
- **Impact:** Existing code unchanged, new code can opt-in with use_persistent_pool=True

**3. Periodic cache clearing every 10 files**
- **Context:** Long-running workers accumulate fragmented CUDA memory
- **Decision:** Call torch.cuda.empty_cache() every 10 files processed
- **Rationale:** Balance between clearing overhead and fragmentation prevention (research suggests 10-100 interval)
- **Impact:** Prevents OOM errors in long-running workers without excessive clearing overhead

## Deviations from Plan

None - plan executed exactly as written.

## Issues Encountered

**Note on feature extraction functions**
- Current `extract_esm_features()` and `extract_dnabert_features()` load models internally
- Persistent pool's `process_files_persistent()` currently calls these functions, which reload models
- This will be addressed in future plan (refactoring extraction functions to accept pre-loaded models)
- For now, persistent pool infrastructure is in place and ready for integration

## User Setup Required

None - no external service configuration required.

## Next Phase Readiness

**Ready for next plan:**
- Persistent pool infrastructure complete
- Memory management configured (expandable_segments, 0.9 memory fraction)
- Lifecycle management methods (create_persistent_pool, close_persistent_pool) available
- Integration pattern established (opt-in via use_persistent_pool parameter)

**Next steps:**
- Refactor extract_esm_features() and extract_dnabert_features() to accept pre-loaded models
- Update worker functions (process_esm_files_worker, process_dnabert_files_worker) to use persistent pool
- Benchmark model loading overhead savings

**No blockers or concerns** - infrastructure ready for integration testing and refinement.

---
*Phase: 04.1-persistent-model-loading*
*Completed: 2026-01-24*
