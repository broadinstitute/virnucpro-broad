---
phase: 04.1-persistent-model-loading
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [virnucpro/pipeline/persistent_pool.py, virnucpro/pipeline/work_queue.py]
autonomous: true

must_haves:
  truths:
    - "Workers load models once during pool initialization"
    - "Models persist in GPU memory across multiple jobs"
    - "Memory management prevents fragmentation in long-running workers"
  artifacts:
    - path: "virnucpro/pipeline/persistent_pool.py"
      provides: "PersistentWorkerPool class for long-lived workers"
      min_lines: 150
    - path: "virnucpro/pipeline/work_queue.py"
      provides: "Updated BatchQueueManager with persistent pool option"
      exports: ["BatchQueueManager"]
  key_links:
    - from: "persistent_pool.py"
      to: "work_queue.py"
      via: "PersistentWorkerPool imported and used"
      pattern: "from.*persistent_pool import PersistentWorkerPool"
---

<objective>
Create persistent worker pool infrastructure for keeping models loaded in GPU memory between jobs.

Purpose: Eliminate model loading overhead by loading models once in worker processes and reusing them across multiple file processing jobs.
Output: PersistentWorkerPool class and updated BatchQueueManager with persistent pool option.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04.1-persistent-model-loading/04.1-RESEARCH.md

# Key implementation patterns from research
@virnucpro/pipeline/work_queue.py
@virnucpro/pipeline/parallel_esm.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PersistentWorkerPool class</name>
  <files>virnucpro/pipeline/persistent_pool.py</files>
  <action>
    Create a new PersistentWorkerPool class that manages long-lived worker processes with model persistence.

    Key features:
    - Initialize Pool with maxtasksperchild=None for persistent workers
    - Worker initializer function that loads models once and stores in module globals
    - Configure PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' before model loading
    - Implement periodic cache clearing mechanism (every 10 files)
    - Support for both ESM-2 and DNABERT-S model types
    - Fixed GPU assignment per worker (one worker per GPU)
    - Progress queue inheritance via Pool initializer (not pickled)

    Include:
    - init_persistent_worker() function for Pool initializer
    - process_files_persistent() wrapper for processing with pre-loaded models
    - Memory configuration using torch.cuda.set_per_process_memory_fraction(0.9)
    - Graceful shutdown with pool.close() and pool.join()

    Reference patterns from research:
    - Pattern 1: Pool initializer with model caching (lines 58-115)
    - Pattern 3: Memory management for long-running workers (lines 156-188)
  </action>
  <verify>Check that persistent_pool.py exists with PersistentWorkerPool class containing init methods and worker functions</verify>
  <done>PersistentWorkerPool class created with model initialization and memory management</done>
</task>

<task type="auto">
  <name>Task 2: Update BatchQueueManager with persistent pool support</name>
  <files>virnucpro/pipeline/work_queue.py</files>
  <action>
    Modify BatchQueueManager to support persistent worker pools as an option.

    Changes:
    - Add use_persistent_pool parameter to __init__ (default: False for backward compatibility)
    - Add persistent_pool attribute to store PersistentWorkerPool instance
    - Update process_files() to check if persistent_pool exists:
      * If yes: use persistent_pool.process_job() instead of creating new Pool
      * If no: use existing Pool creation logic (current behavior)
    - Add lifecycle management:
      * create_persistent_pool() method to initialize persistent workers
      * close_persistent_pool() method for cleanup
    - Import PersistentWorkerPool from persistent_pool module

    Ensure backward compatibility:
    - Default behavior remains unchanged (create new Pool per process_files call)
    - Persistent pool is opt-in via use_persistent_pool parameter
    - Existing tests continue to pass without modification
  </action>
  <verify>Run grep -n "use_persistent_pool\|PersistentWorkerPool" virnucpro/pipeline/work_queue.py to confirm integration</verify>
  <done>BatchQueueManager updated with persistent pool support while maintaining backward compatibility</done>
</task>

</tasks>

<verification>
- PersistentWorkerPool class implements worker persistence pattern with model caching
- BatchQueueManager supports both persistent and non-persistent modes
- Memory management configured for long-running workers
- Module-level globals used for model storage in workers
</verification>

<success_criteria>
- Persistent worker pool infrastructure created and integrated
- Workers can load models once and reuse across jobs
- Memory fragmentation prevention implemented
- Backward compatibility maintained in BatchQueueManager
</success_criteria>

<output>
After completion, create `.planning/phases/04.1-persistent-model-loading/04.1-01-SUMMARY.md`
</output>