---
phase: 04.1-persistent-model-loading
plan: 05
type: execute
wave: 2
depends_on: [04.1-04]
files_modified: [virnucpro/pipeline/prediction.py, virnucpro/pipeline/work_queue.py]
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Pipeline creates persistent pool when --persistent-models flag is used"
    - "Same queue manager is reused between DNABERT and ESM stages"
    - "Persistent pool is properly closed on completion or error"
  artifacts:
    - path: "virnucpro/pipeline/prediction.py"
      provides: "Proper persistent pool lifecycle management"
      contains: "create_persistent_pool"
    - path: "virnucpro/pipeline/work_queue.py"
      provides: "Logging to confirm persistent pool usage"
      contains: "persistent_pool"
  key_links:
    - from: "prediction.py"
      to: "BatchQueueManager"
      via: "calls create_persistent_pool after initialization"
      pattern: "queue_manager\\.create_persistent_pool\\("
---

<objective>
Wire pipeline to actually create and use persistent worker pools when enabled.

Purpose: Close the critical gap where pipeline passes use_persistent_pool=True but never calls create_persistent_pool(), causing fallback to standard workers.
Output: Modified pipeline that properly creates, uses, and closes persistent worker pools.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04.1-persistent-model-loading/04.1-VERIFICATION.md

# Key files to modify
@virnucpro/pipeline/prediction.py
@virnucpro/pipeline/work_queue.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add logging to BatchQueueManager for persistent pool usage</name>
  <files>virnucpro/pipeline/work_queue.py</files>
  <action>
    Add logging to BatchQueueManager to confirm when persistent pool is used vs standard pool.

    In process_files() method (around line 164):
    - Add logging when checking for persistent pool
    - Add logging when falling back to standard pool

    ```python
    def process_files(self, file_assignments, **kwargs):
        """Process files with either persistent or standard pool"""
        if self.use_persistent_pool and self.persistent_pool is not None:
            logger.info("Using persistent worker pool for processing")
            # Use persistent pool
            results = []
            for gpu_id, files in file_assignments.items():
                for file_batch in self._batch_files(files):
                    result = self.persistent_pool.process_job(
                        gpu_id, file_batch, **kwargs
                    )
                    results.extend(result)
            return results, []
        else:
            if self.use_persistent_pool:
                logger.warning("Persistent pool requested but not created, falling back to standard pool")
            else:
                logger.info("Using standard worker pool for processing")
            # Standard pool processing
            # ... existing code ...
    ```

    Also add logging in create_persistent_pool() and close_persistent_pool() methods to track lifecycle.
  </action>
  <verify>grep -n "Using persistent worker pool\|Persistent pool requested" virnucpro/pipeline/work_queue.py</verify>
  <done>BatchQueueManager logs persistent pool usage and fallback behavior</done>
</task>

<task type="auto">
  <name>Task 2: Refactor pipeline to create and reuse persistent pool</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Refactor run_prediction() to properly create, use, and close persistent worker pools.

    Major changes needed:
    1. Create queue_manager ONCE at the beginning if persistent_models=True
    2. Create persistent pool after manager initialization
    3. Reuse same manager for both DNABERT and ESM stages
    4. Close persistent pool in finally block

    Structure around lines 450-480 (DNABERT) and 635-674 (ESM):

    ```python
    # Create queue manager once if using persistent models
    queue_manager = None
    if persistent_models:
        # Single queue manager for both stages
        queue_manager = BatchQueueManager(
            num_gpus,
            None,  # Will set worker function per stage
            progress_queue=progress_queue,
            use_persistent_pool=True
        )
        # Create persistent pool immediately
        logger.info("Creating persistent worker pool...")
        queue_manager.create_persistent_pool()

    try:
        # DNABERT-S processing
        if nucleotide_files_to_process:
            # ... existing setup ...

            if persistent_models:
                # Reuse existing queue_manager, just update worker function
                queue_manager.worker_func = process_dnabert_files_worker
            else:
                # Create standard queue manager
                queue_manager = BatchQueueManager(
                    num_gpus,
                    process_dnabert_files_worker,
                    progress_queue=progress_queue,
                    use_persistent_pool=False
                )

            processed, failed = queue_manager.process_files(...)
            # ... rest unchanged ...

        # ESM-2 processing (similar pattern)
        if protein_files_to_process:
            # ... existing setup ...

            if persistent_models:
                # Reuse existing queue_manager, just update worker function
                queue_manager.worker_func = process_esm_files_worker
            else:
                # Create standard queue manager
                queue_manager = BatchQueueManager(
                    num_gpus,
                    process_esm_files_worker,
                    progress_queue=progress_queue,
                    use_persistent_pool=False
                )

            processed, failed = queue_manager.process_files(...)
            # ... rest unchanged ...

    finally:
        # Clean up persistent pool if created
        if persistent_models and queue_manager:
            logger.info("Closing persistent worker pool...")
            queue_manager.close_persistent_pool()
    ```

    This ensures:
    - Persistent pool is created once and reused
    - Same manager handles both DNABERT and ESM stages
    - Pool is properly closed even on error
    - Standard behavior unchanged when persistent_models=False
  </action>
  <verify>grep -n "create_persistent_pool\|close_persistent_pool" virnucpro/pipeline/prediction.py</verify>
  <done>Pipeline creates persistent pool, reuses queue_manager, and ensures proper cleanup</done>
</task>

<task type="auto">
  <name>Task 3: Update memory management for persistent pool mode</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Enhance memory management when using persistent pools.

    Add periodic cache clearing between stages and better memory reporting:

    1. After DNABERT stage completes (around line 470):
    ```python
    # Clear cache after DNABERT-S stage if memory manager active
    if memory_manager:
        memory_manager.clear_cache()
        if persistent_models:
            # Extra aggressive clearing for persistent models
            torch.cuda.synchronize()
            torch.cuda.empty_cache()
        if not quiet:
            stats = memory_manager.get_memory_stats()
            mode = "persistent" if persistent_models else "standard"
            logger.info(f"  Post-DNABERT memory ({mode}): {stats['allocated']:.2f}GB allocated, "
                       f"{stats['free']:.2f}GB free")
    ```

    2. After ESM stage completes (around line 656):
    ```python
    # Clear cache after ESM-2 stage if memory manager active
    if memory_manager:
        memory_manager.clear_cache()
        if persistent_models:
            # Extra aggressive clearing for persistent models
            torch.cuda.synchronize()
            torch.cuda.empty_cache()
        if not quiet:
            stats = memory_manager.get_memory_stats()
            mode = "persistent" if persistent_models else "standard"
            logger.info(f"  Post-ESM-2 memory ({mode}): {stats['allocated']:.2f}GB allocated, "
                       f"{stats['free']:.2f}GB free")
    ```

    This helps prevent memory fragmentation in long-running persistent workers.
  </action>
  <verify>grep -n "persistent.*memory\|mode = \"persistent\"" virnucpro/pipeline/prediction.py</verify>
  <done>Enhanced memory management for persistent pool mode with aggressive cache clearing</done>
</task>

</tasks>

<verification>
- Pipeline creates persistent pool when --persistent-models is used
- Same queue_manager instance handles both DNABERT and ESM stages
- Persistent pool is properly closed in finally block
- Logging confirms persistent pool usage vs fallback
- Memory is aggressively cleared between stages
</verification>

<success_criteria>
- create_persistent_pool() is called when persistent_models=True
- Single queue_manager instance reused for both model types
- close_persistent_pool() called in finally block
- No "falling back to standard pool" warnings when using --persistent-models
- Memory stats show "persistent" mode when enabled
</success_criteria>

<output>
After completion, create `.planning/phases/04.1-persistent-model-loading/04.1-05-SUMMARY.md`
</output>