---
phase: 04.1-persistent-model-loading
plan: 03
subsystem: pipeline
tags: [cli, integration-tests, persistent-workers, memory-management]

# Dependency graph
requires:
  - phase: 04.1-01
    provides: PersistentWorkerPool infrastructure
  - phase: 04.1-02
    provides: Persistent worker functions for ESM-2 and DNABERT-S
provides:
  - Pipeline integration with persistent workers (opt-in via parameter)
  - CLI --persistent-models flag for user control
  - Comprehensive integration tests for persistent worker functionality
affects: [future-pipeline-optimization, production-deployment]

# Tech tracking
tech-stack:
  added: []
  patterns:
    - "Pipeline parameter plumbing for persistent workers"
    - "CLI boolean flag for feature enablement"
    - "Integration test fixtures for GPU testing"

key-files:
  created:
    - tests/integration/test_persistent_workers.py
  modified:
    - virnucpro/pipeline/prediction.py
    - virnucpro/cli/predict.py

key-decisions:
  - "Opt-in via CLI flag maintains backward compatibility while enabling new capability"
  - "Parameter defaults to False for conservative memory usage"
  - "Logging indicates when persistent models are enabled for user transparency"

patterns-established:
  - "Pattern: CLI flag → pipeline parameter → BatchQueueManager opt-in feature"
  - "Pattern: Integration tests with GPU markers skip gracefully in CI without GPU"

# Metrics
duration: 4min
completed: 2026-01-24
---

# Phase 04.1 Plan 03: Pipeline & CLI Integration Summary

**CLI and pipeline integration for persistent model loading with comprehensive testing**

## Performance

- **Duration:** 4 min
- **Started:** 2026-01-24T06:35:41Z
- **Completed:** 2026-01-24T06:39:21Z
- **Tasks:** 3
- **Files modified:** 3 (1 created, 2 updated)

## Accomplishments

- Integrated persistent worker pools into prediction pipeline via persistent_models parameter
- Added --persistent-models CLI flag for user control
- Created 17 integration tests covering initialization, lifecycle, output equivalence, and CLI integration
- Maintained complete backward compatibility (default: False)
- All tests use pytest markers (@pytest.mark.gpu) to skip gracefully without GPU

## Task Commits

Each task was committed atomically:

1. **Task 1: Integrate persistent workers into pipeline** - `f4ff7a7` (feat)
2. **Task 2: Add CLI flag for persistent models** - `cd1f67e` (feat)
3. **Task 3: Create integration tests for persistent workers** - `4bd103f` (test)

## Files Created/Modified

- `virnucpro/pipeline/prediction.py` - Added persistent_models parameter and passed use_persistent_pool to BatchQueueManager (2 call sites)
- `virnucpro/cli/predict.py` - Added --persistent-models/--no-persistent-models flag and parameter passing
- `tests/integration/test_persistent_workers.py` - 17 test cases covering persistent worker functionality (399 lines)

## Decisions Made

**1. Opt-in via parameter default False**
- **Context:** Users may not want models persistent due to memory concerns
- **Decision:** Default persistent_models=False in both CLI and pipeline
- **Rationale:** Conservative default, users explicitly opt-in with --persistent-models
- **Impact:** No change in behavior for existing users, new feature available on demand

**2. Logging when persistent models enabled**
- **Context:** Users need to know when persistent mode is active
- **Decision:** Add logging at CLI and pipeline level indicating persistent models enabled
- **Rationale:** Transparency helps users understand memory usage patterns
- **Impact:** Clear feedback that feature is active and models remain in GPU memory

**3. Integration tests use GPU markers**
- **Context:** CI environments may not have GPU, but feature requires GPU to test fully
- **Decision:** Use @pytest.mark.gpu decorator, pytest automatically skips if no GPU
- **Rationale:** Tests run in local GPU environments, skip gracefully in CI
- **Impact:** Full test coverage locally, no CI failures from missing GPU

**4. Pass use_persistent_pool to BatchQueueManager**
- **Context:** BatchQueueManager already has opt-in support from Phase 04.1-01
- **Decision:** Pass persistent_models parameter directly to use_persistent_pool
- **Rationale:** Clean parameter plumbing, BatchQueueManager handles pool type internally
- **Impact:** Minimal changes to pipeline code, encapsulation maintained

## Deviations from Plan

None - plan executed exactly as written.

## Issues Encountered

None - implementation proceeded smoothly building on infrastructure from 04.1-01 and 04.1-02.

## User Setup Required

None - feature is opt-in via CLI flag.

## Usage Examples

**Enable persistent models:**
```bash
python -m virnucpro predict input.fasta --persistent-models
```

**Disable persistent models (default):**
```bash
python -m virnucpro predict input.fasta --no-persistent-models
# or just omit the flag (defaults to False)
python -m virnucpro predict input.fasta
```

**Recommended use case:**
- Processing multiple samples in sequence where model loading overhead is significant
- Systems with sufficient GPU memory to keep models resident
- Not recommended for single-sample jobs or memory-constrained systems

## Test Coverage

**17 integration tests covering:**
- Persistent pool initialization and lifecycle
- BatchQueueManager with use_persistent_pool flag
- Backward compatibility (existing code works without parameter)
- Memory management (periodic cache clearing, expandable segments)
- Output structure equivalence between persistent and standard workers
- CLI flag parsing and parameter passing
- Error handling and cleanup
- End-to-end pipeline integration (GPU tests)

**Test organization:**
- `TestPersistentPoolInitialization` - 3 tests for pool creation and lifecycle
- `TestBatchQueueManagerPersistentPool` - 2 tests for BatchQueueManager integration
- `TestMemoryManagement` - 2 tests for memory optimization
- `TestOutputEquivalence` - 2 tests for output correctness
- `TestCLIIntegration` - 4 tests for CLI flag handling
- `TestPersistentWorkersEndToEnd` - 2 tests for end-to-end scenarios
- `TestErrorHandling` - 2 tests for error cases

## Next Phase Readiness

**Ready for production use:**
- Pipeline integrated with persistent workers (opt-in)
- CLI flag exposed for user control
- Integration tests verify correctness
- Backward compatibility maintained
- Memory management configured (from Phase 04.1-01, 04.1-02)

**Next steps:**
- Benchmark persistent vs standard workers for model loading overhead savings
- Document persistent model loading in user guide
- Monitor memory usage patterns in production
- Consider auto-detection based on available GPU memory

**No blockers or concerns** - feature complete and ready for testing with real workloads.

---
*Phase: 04.1-persistent-model-loading*
*Completed: 2026-01-24*
