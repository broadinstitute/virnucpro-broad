---
phase: 05-advanced-load-balancing
plan: 03
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - virnucpro/pipeline/load_dashboard.py
  - virnucpro/pipeline/load_balancer.py
  - virnucpro/pipeline/gpu_utilization.py
autonomous: true

must_haves:
  truths:
    - "Dashboard shows real-time per-GPU metrics"
    - "Work stealing events are visible in dashboard"
    - "Dashboard updates every 2-3 seconds without flicker"
    - "GPU utilization tracked via nvidia-smi/nvitop"
    - "Throughput metrics logged persistently"
  artifacts:
    - path: "virnucpro/pipeline/load_dashboard.py"
      provides: "LoadBalancingDashboard class"
      min_lines: 150
      exports: ["LoadBalancingDashboard"]
    - path: "virnucpro/pipeline/gpu_utilization.py"
      provides: "GPU utilization monitoring"
      min_lines: 100
      exports: ["GPUMonitor", "get_gpu_utilization"]
  key_links:
    - from: "load_dashboard.py"
      to: "rich.live"
      via: "Live context for updates"
      pattern: "from rich.live import Live"
    - from: "gpu_utilization.py"
      to: "nvidia-ml-py"
      via: "nvidia-smi Python bindings"
      pattern: "import nvidia_ml_py|pynvml"
    - from: "load_dashboard.py"
      to: "load_balancer.py"
      via: "gets metrics from coordinator"
      pattern: "WorkStealingCoordinator"
---

<objective>
Create real-time monitoring dashboard showing per-GPU utilization, throughput, queue depths, and work stealing events with persistent logging.

Purpose: Provide visibility into GPU load distribution and work stealing effectiveness.
Output: LoadBalancingDashboard class with Rich-based live terminal UI and GPU utilization monitoring.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-advanced-load-balancing/05-CONTEXT.md
@.planning/phases/05-advanced-load-balancing/05-RESEARCH.md

@virnucpro/pipeline/dashboard.py
@virnucpro/pipeline/gpu_monitor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GPU utilization monitoring</name>
  <files>virnucpro/pipeline/gpu_utilization.py</files>
  <action>
    Create gpu_utilization.py with GPUMonitor class for real GPU compute and memory utilization tracking.

    Implementation using nvidia-ml-py (pynvml):
    - Install nvidia-ml-py if not present (pip install nvidia-ml-py)
    - Initialize NVML in __init__, handle gracefully if not available (CPU-only systems)
    - get_gpu_utilization(device_id) method returns:
      * compute_percent: GPU compute utilization % (0-100)
      * memory_percent: GPU memory usage % (0-100)
      * temperature: GPU temperature in Celsius
      * power_watts: Current power draw
    - Fallback to nvidia-smi subprocess if pynvml unavailable
    - Cache results for 1-2 seconds to avoid excessive NVML calls
    - Thread-safe for concurrent dashboard updates

    Key implementation:
    ```python
    import nvidia_ml_py as nvml
    # or fallback to:
    subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,utilization.memory',
                    '--format=csv,noheader,nounits'])
    ```

    MON-01 requirement: Track actual GPU compute % and memory usage, not estimated from queue depth.
  </action>
  <verify>grep -n "class GPUMonitor" virnucpro/pipeline/gpu_utilization.py && grep -n "get_gpu_utilization" virnucpro/pipeline/gpu_utilization.py</verify>
  <done>GPUMonitor class provides real GPU utilization metrics via NVML/nvidia-smi</done>
</task>

<task type="auto">
  <name>Task 2: Create LoadBalancingDashboard with persistent logging</name>
  <files>virnucpro/pipeline/load_dashboard.py</files>
  <action>
    Create load_dashboard.py with LoadBalancingDashboard class for real-time GPU metrics display.

    Implementation using Rich library (Pattern 3 from RESEARCH.md):
    - Use Rich Live context manager with Table regeneration
    - Update frequency: 2-3 seconds (configurable)
    - Regenerate entire table on update (simpler than mutating rows)

    Dashboard columns:
    - GPU ID
    - GPU Name (model)
    - Compute % (from GPUMonitor - actual utilization, not estimated)
    - Memory % (from GPUMonitor)
    - Throughput (sequences/sec, rolling average over 60s or last 10 files)
    - Queue Depth (files remaining)
    - Files Done (completed count)
    - Work Stolen (count of files stolen by/from this GPU)

    Key features:
    - Non-blocking dashboard update in background thread
    - TTY detection with fallback to logging if not interactive
    - Handle terminal resize gracefully (Rich does this automatically)
    - Show work stealing events in separate section below table
    - Recent events list (last 5-10 steal events with timestamp)
    - Persistent logging of throughput metrics to file (MON-02 requirement)

    Methods:
    - __init__(coordinator, gpu_monitor, update_interval=2.0, log_file="gpu_metrics.log")
    - start() - begins background update thread
    - stop() - cleanly shuts down dashboard
    - _generate_table(metrics) - creates Rich Table from current metrics
    - _collect_metrics() - gathers data from coordinator and GPUMonitor
    - _update_loop() - background thread that refreshes display
    - _log_metrics(metrics) - writes throughput/utilization to persistent log file

    MON-02 requirement: Log sequences/sec per GPU to file for analysis.
    Format: timestamp, gpu_id, sequences_per_sec, compute_percent, memory_percent
  </action>
  <verify>grep -n "class LoadBalancingDashboard" virnucpro/pipeline/load_dashboard.py && grep -n "from rich.live import Live" virnucpro/pipeline/load_dashboard.py</verify>
  <done>LoadBalancingDashboard class exists with Rich Live display for real-time metrics and persistent logging</done>
</task>

<task type="auto">
  <name>Task 3: Add metrics collection to WorkStealingCoordinator</name>
  <files>virnucpro/pipeline/load_balancer.py</files>
  <action>
    Update WorkStealingCoordinator to provide metrics for dashboard display and persistent logging.

    Add methods:
    - get_gpu_metrics() - returns dict of per-GPU statistics:
      * device_id, device_name
      * queue_depth (current files in queue)
      * files_completed (processed count)
      * work_stolen_from (files stolen from this GPU)
      * work_stolen_to (files stolen by this GPU)
      * throughput (sequences/sec based on recent completions)
      * last_update_time (for persistent logging)

    - get_recent_steal_events() - returns list of recent work stealing events:
      * timestamp, source_gpu, dest_gpu, file_name

    - record_file_completion(gpu_id, file_path, sequences, duration) - track throughput:
      * Store with timestamp for persistent logging
      * Calculate rolling average for dashboard display

    Add internal tracking:
    - Per-GPU completion history with timestamps (for throughput calculation and logging)
    - Work stealing event log (circular buffer, keep last 50 events)
    - Queue depth snapshots for monitoring

    Calculate throughput as rolling average over 60 seconds or last 10 files.
    Include timestamp in all metrics for persistent logging (MON-02).
  </action>
  <verify>grep -n "def get_gpu_metrics" virnucpro/pipeline/load_balancer.py && grep -n "def record_file_completion" virnucpro/pipeline/load_balancer.py</verify>
  <done>WorkStealingCoordinator provides metrics collection with timestamps for dashboard and logging</done>
</task>

</tasks>

<verification>
- GPUMonitor tracks real GPU compute % and memory % via NVML/nvidia-smi (MON-01)
- LoadBalancingDashboard displays real-time GPU metrics with actual utilization
- Dashboard persistently logs throughput metrics to file (MON-02)
- Rich Live updates table every 2-3 seconds
- Work stealing events logged and displayed
- WorkStealingCoordinator tracks metrics with timestamps
</verification>

<success_criteria>
- Dashboard shows actual GPU utilization % from nvidia-smi/NVML (not estimated)
- Throughput (sequences/sec per GPU) logged to persistent file
- Dashboard updates live without flicker (Rich handles this)
- Per-GPU metrics visible in tabular format
- Work stealing events shown with timestamps
- Color-coded utilization for quick status assessment
- TTY detection with logging fallback for non-interactive
</success_criteria>

<output>
After completion, create `.planning/phases/05-advanced-load-balancing/05-03-SUMMARY.md`
</output>