---
phase: 05-advanced-load-balancing
plan: 03
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - virnucpro/pipeline/load_dashboard.py
  - virnucpro/pipeline/load_balancer.py
autonomous: true

must_haves:
  truths:
    - "Dashboard shows real-time per-GPU metrics"
    - "Work stealing events are visible in dashboard"
    - "Dashboard updates every 2-3 seconds without flicker"
  artifacts:
    - path: "virnucpro/pipeline/load_dashboard.py"
      provides: "LoadBalancingDashboard class"
      min_lines: 150
      exports: ["LoadBalancingDashboard"]
  key_links:
    - from: "load_dashboard.py"
      to: "rich.live"
      via: "Live context for updates"
      pattern: "from rich.live import Live"
    - from: "load_dashboard.py"
      to: "load_balancer.py"
      via: "gets metrics from coordinator"
      pattern: "WorkStealingCoordinator"
---

<objective>
Create real-time monitoring dashboard showing per-GPU utilization, throughput, queue depths, and work stealing events.

Purpose: Provide visibility into GPU load distribution and work stealing effectiveness.
Output: LoadBalancingDashboard class with Rich-based live terminal UI.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-advanced-load-balancing/05-CONTEXT.md
@.planning/phases/05-advanced-load-balancing/05-RESEARCH.md

@virnucpro/pipeline/dashboard.py
@virnucpro/pipeline/gpu_monitor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LoadBalancingDashboard class</name>
  <files>virnucpro/pipeline/load_dashboard.py</files>
  <action>
    Create load_dashboard.py with LoadBalancingDashboard class for real-time GPU metrics display.

    Implementation using Rich library (Pattern 3 from RESEARCH.md):
    - Use Rich Live context manager with Table regeneration
    - Update frequency: 2-3 seconds (configurable)
    - Regenerate entire table on update (simpler than mutating rows)

    Dashboard columns:
    - GPU ID
    - GPU Name (model)
    - Utilization % (color-coded: green >80%, yellow 50-80%, red <50%)
    - Throughput (sequences/sec, rolling average over 60s or last 10 files)
    - Queue Depth (files remaining)
    - Files Done (completed count)
    - Work Stolen (count of files stolen by/from this GPU)

    Key features:
    - Non-blocking dashboard update in background thread
    - TTY detection with fallback to logging if not interactive
    - Handle terminal resize gracefully (Rich does this automatically)
    - Show work stealing events in separate section below table
    - Recent events list (last 5-10 steal events with timestamp)

    Methods:
    - __init__(coordinator, update_interval=2.0)
    - start() - begins background update thread
    - stop() - cleanly shuts down dashboard
    - _generate_table(metrics) - creates Rich Table from current metrics
    - _collect_metrics() - gathers data from coordinator
    - _update_loop() - background thread that refreshes display
  </action>
  <verify>grep -n "class LoadBalancingDashboard" virnucpro/pipeline/load_dashboard.py && grep -n "from rich.live import Live" virnucpro/pipeline/load_dashboard.py</verify>
  <done>LoadBalancingDashboard class exists with Rich Live display for real-time metrics</done>
</task>

<task type="auto">
  <name>Task 2: Add metrics collection to WorkStealingCoordinator</name>
  <files>virnucpro/pipeline/load_balancer.py</files>
  <action>
    Update WorkStealingCoordinator to provide metrics for dashboard display.

    Add methods:
    - get_gpu_metrics() - returns dict of per-GPU statistics:
      * device_id, device_name
      * queue_depth (current files in queue)
      * files_completed (processed count)
      * work_stolen_from (files stolen from this GPU)
      * work_stolen_to (files stolen by this GPU)
      * throughput (sequences/sec based on recent completions)
      * utilization_pct (estimated from queue depth and throughput)

    - get_recent_steal_events() - returns list of recent work stealing events:
      * timestamp, source_gpu, dest_gpu, file_name

    - record_file_completion(gpu_id, file_path, sequences, duration) - track throughput

    Add internal tracking:
    - Per-GPU completion history (for throughput calculation)
    - Work stealing event log (circular buffer, keep last 50 events)
    - Queue depth snapshots for utilization estimation

    Use torch.cuda for GPU device names and memory info (Pattern 4 from RESEARCH.md).
    Calculate throughput as rolling average over 60 seconds or last 10 files.
    Estimate utilization from queue depth and throughput (not GPU core % - PyTorch doesn't expose that).
  </action>
  <verify>grep -n "def get_gpu_metrics" virnucpro/pipeline/load_balancer.py && grep -n "def get_recent_steal_events" virnucpro/pipeline/load_balancer.py</verify>
  <done>WorkStealingCoordinator provides metrics collection methods for dashboard</done>
</task>

</tasks>

<verification>
- LoadBalancingDashboard class displays real-time GPU metrics
- Rich Live updates table every 2-3 seconds
- Dashboard shows utilization, throughput, queue depth, work stealing
- WorkStealingCoordinator tracks and provides metrics
- Work stealing events logged and displayed
</verification>

<success_criteria>
- Dashboard updates live without flicker (Rich handles this)
- Per-GPU metrics visible in tabular format
- Work stealing events shown with timestamps
- Color-coded utilization for quick status assessment
- TTY detection with logging fallback for non-interactive
</success_criteria>

<output>
After completion, create `.planning/phases/05-advanced-load-balancing/05-03-SUMMARY.md`
</output>