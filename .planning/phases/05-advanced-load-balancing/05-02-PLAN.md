---
phase: 05-advanced-load-balancing
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - virnucpro/pipeline/base_worker.py
  - virnucpro/pipeline/gpu_weights.py
autonomous: true

must_haves:
  truths:
    - "Heterogeneous GPUs receive work proportional to their capability"
    - "GPU capability weights are applied during file assignment"
    - "Unknown GPU models default to weight 1.0"
  artifacts:
    - path: "virnucpro/pipeline/gpu_weights.py"
      provides: "GPU weight lookup table and functions"
      min_lines: 50
      exports: ["GPU_WEIGHTS", "get_gpu_weight", "assign_files_weighted"]
  key_links:
    - from: "base_worker.py"
      to: "gpu_weights.py"
      via: "imports weighted assignment"
      pattern: "from.*gpu_weights import"
    - from: "gpu_weights.py"
      to: "torch.cuda"
      via: "gets device name"
      pattern: "torch.cuda.get_device_name"
---

<objective>
Add GPU capability weighting to file assignment for heterogeneous GPU support.

Purpose: Distribute work proportional to GPU compute capability so faster GPUs get more files.
Output: Weighted file assignment functions that account for GPU performance differences.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-advanced-load-balancing/05-CONTEXT.md
@.planning/phases/05-advanced-load-balancing/05-RESEARCH.md

@virnucpro/pipeline/base_worker.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GPU weights module</name>
  <files>virnucpro/pipeline/gpu_weights.py</files>
  <action>
    Create gpu_weights.py with GPU capability weight lookup table and helper functions.

    Include static weight table from RESEARCH.md:
    - Consumer GPUs: RTX 3080 (0.90), RTX 3090 (1.00 baseline), RTX 4080 (1.35), RTX 4090 (1.50)
    - Professional Ampere: RTX A6000 (1.10), A100 (1.20)
    - Professional Hopper: H100 (2.50)
    - Professional Volta: V100 16GB (0.75), V100 32GB (0.80)
    - Default weight: 1.0 for unknown models

    Implement:
    - GPU_WEIGHTS dictionary with GPU name -> weight mapping
    - get_gpu_weight(device_id) function that returns weight for a GPU (default 1.0 if unknown)
    - assign_files_weighted() function that extends existing bin-packing with weights
    - Weighted assignment: divide sequence count by GPU weight when determining minimum load

    Use torch.cuda.get_device_name() to identify GPU model.
    Log warning for unknown GPU models (but continue with default weight).

    Follow Pattern 5 from RESEARCH.md for weighted bin-packing algorithm.
  </action>
  <verify>grep -n "GPU_WEIGHTS = {" virnucpro/pipeline/gpu_weights.py && grep -n "def get_gpu_weight" virnucpro/pipeline/gpu_weights.py</verify>
  <done>gpu_weights.py exists with GPU weight table and weighted assignment functions</done>
</task>

<task type="auto">
  <name>Task 2: Update base_worker with weighted assignment</name>
  <files>virnucpro/pipeline/base_worker.py</files>
  <action>
    Update BaseEmbeddingWorker to support weighted file assignment for heterogeneous GPUs.

    Modifications:
    - Add use_weighted_assignment parameter to assign_files_by_sequences (default: False for backward compatibility)
    - When enabled, import and use assign_files_weighted from gpu_weights module
    - Pass GPU weights to weighted assignment function
    - Update logging to show GPU weights in file assignment summary
    - Maintain existing behavior when use_weighted_assignment=False

    The weighted assignment should:
    - Collect GPU weights for all workers
    - Use weights to normalize load (faster GPUs get proportionally more sequences)
    - Log the weight-adjusted assignments for transparency

    Example log output:
    "GPU 0 (RTX 3090, weight=1.00): 20 files, 50000 sequences"
    "GPU 1 (RTX 4090, weight=1.50): 30 files, 75000 sequences"
  </action>
  <verify>grep -n "use_weighted_assignment" virnucpro/pipeline/base_worker.py && grep -n "gpu_weights" virnucpro/pipeline/base_worker.py</verify>
  <done>BaseEmbeddingWorker supports weighted file assignment with GPU capability weights</done>
</task>

</tasks>

<verification>
- GPU_WEIGHTS dictionary contains performance weights for common GPU models
- get_gpu_weight() returns appropriate weight or 1.0 default
- assign_files_weighted() distributes files proportional to GPU capability
- BaseEmbeddingWorker can use weighted assignment when enabled
- Backward compatible (weighted assignment is opt-in)
</verification>

<success_criteria>
- GPU capability weights defined for consumer and datacenter GPUs
- Unknown GPUs handled gracefully with default weight
- Files assigned proportional to GPU compute capability
- Heterogeneous GPU setups (3090 + 4090) get balanced work
- Assignment logging shows GPU model and weight
</success_criteria>

<output>
After completion, create `.planning/phases/05-advanced-load-balancing/05-02-SUMMARY.md`
</output>