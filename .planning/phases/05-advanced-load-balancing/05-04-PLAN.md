---
phase: 05-advanced-load-balancing
plan: 04
type: execute
wave: 3
depends_on: ["05-01", "05-03"]
files_modified:
  - virnucpro/pipeline/prediction.py
  - virnucpro/cli.py
  - virnucpro/pipeline/parallel_dnabert.py
  - virnucpro/pipeline/parallel_esm.py
autonomous: true

must_haves:
  truths:
    - "Pipeline uses work stealing when enabled via CLI"
    - "GPU weights applied to initial file distribution"
    - "Dashboard displays during multi-GPU processing"
  artifacts:
    - path: "virnucpro/cli.py"
      provides: "CLI flags for load balancing"
      contains: "--work-stealing|--gpu-weighted"
    - path: "virnucpro/pipeline/prediction.py"
      provides: "Pipeline integration"
      contains: "WorkStealingCoordinator|LoadBalancingDashboard"
  key_links:
    - from: "prediction.py"
      to: "load_balancer.py"
      via: "creates coordinator"
      pattern: "WorkStealingCoordinator"
    - from: "cli.py"
      to: "prediction.py"
      via: "passes load balancing flags"
      pattern: "work_stealing|gpu_weighted"
---

<objective>
Integrate work stealing and weighted assignment into the pipeline with CLI control flags.

Purpose: Enable load balancing features in production pipeline with user control.
Output: Full pipeline integration with CLI flags for work stealing and GPU weighting.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-advanced-load-balancing/05-CONTEXT.md

@virnucpro/cli.py
@virnucpro/pipeline/prediction.py
@virnucpro/pipeline/parallel_dnabert.py
@virnucpro/pipeline/parallel_esm.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CLI flags for load balancing</name>
  <files>virnucpro/cli.py</files>
  <action>
    Add CLI flags to control work stealing and GPU weighting features.

    New flags:
    - --work-stealing: Enable work stealing for load balancing (default: False)
    - --gpu-weighted: Use GPU capability weights for file assignment (default: False)
    - --steal-interval: Work stealing check interval in seconds (default: 3.0)
    - --show-gpu-dashboard: Display real-time GPU utilization dashboard (default: True when parallel)

    Add to predict command's click options:
    ```python
    @click.option('--work-stealing', is_flag=True,
                  help='Enable work stealing for GPU load balancing')
    @click.option('--gpu-weighted', is_flag=True,
                  help='Weight file assignment by GPU capability')
    @click.option('--steal-interval', type=float, default=3.0,
                  help='Work stealing check interval in seconds')
    @click.option('--show-gpu-dashboard/--no-gpu-dashboard', default=None,
                  help='Show real-time GPU utilization dashboard (default: auto)')
    ```

    Pass these parameters to run_prediction() function.
    Auto-enable dashboard when parallel=True and show_gpu_dashboard not explicitly False.
  </action>
  <verify>grep -n "--work-stealing" virnucpro/cli.py && grep -n "--gpu-weighted" virnucpro/cli.py</verify>
  <done>CLI has flags for work stealing, GPU weighting, and dashboard control</done>
</task>

<task type="auto">
  <name>Task 2: Integrate load balancing into pipeline</name>
  <files>virnucpro/pipeline/prediction.py</files>
  <action>
    Update run_prediction() to use work stealing and weighted assignment when enabled.

    Pipeline integration:
    1. Accept new parameters: work_stealing, gpu_weighted, steal_interval, show_gpu_dashboard
    2. When parallel processing and work_stealing enabled:
       - Create WorkStealingCoordinator before worker pools
       - Pass coordinator to BatchQueueManager with work_stealing_enabled=True
       - Use shared work queues instead of static file lists
    3. When gpu_weighted enabled:
       - Import and use assign_files_weighted from gpu_weights module
       - Pass GPU weights to file assignment (works independently of work stealing)
       - Apply weighted assignment in DNABERT-S and ESM-2 stages
    4. When show_gpu_dashboard enabled (and parallel):
       - Create GPUMonitor for real GPU utilization tracking
       - Create LoadBalancingDashboard, explicitly passing coordinator instance:
         ```python
         # Step 2: Create coordinator (if work_stealing enabled)
         coordinator = WorkStealingCoordinator(...) if work_stealing else None

         # Step 3: Create GPU monitor
         gpu_monitor = GPUMonitor()

         # Step 4: Create and start dashboard, EXPLICITLY pass coordinator instance
         dashboard = LoadBalancingDashboard(
             coordinator=coordinator,  # EXPLICIT: Pass coordinator instance created in step 2
             gpu_monitor=gpu_monitor,
             update_interval=2.0,
             log_file="gpu_metrics.log"
         )
         dashboard.start()
         ```
       - Stop dashboard cleanly after processing completes

    Key integration points:
    - Before DNABERT-S parallel processing: setup coordinator if work_stealing
    - Before ESM-2 parallel processing: reuse or create new coordinator
    - In file assignment: apply GPU weights if gpu_weighted (independently)
    - During processing: dashboard shows live metrics if enabled
    - After processing: clean shutdown of coordinator and dashboard

    Note: GPU weighting works independently of work stealing - can use one, both, or neither.
    Ensure backward compatibility - all features disabled by default.
    Log when advanced load balancing features are active.
  </action>
  <verify>grep -n "WorkStealingCoordinator" virnucpro/pipeline/prediction.py && grep -n "LoadBalancingDashboard" virnucpro/pipeline/prediction.py</verify>
  <done>Pipeline integrates work stealing coordinator and explicitly wires it to dashboard</done>
</task>

<task type="auto">
  <name>Task 3: Update parallel workers for work stealing</name>
  <files>virnucpro/pipeline/parallel_dnabert.py, virnucpro/pipeline/parallel_esm.py</files>
  <action>
    Update DNABERT-S and ESM-2 parallel workers to support work stealing.

    In parallel_dnabert.py:
    - Modify process_dnabert_files() to accept optional work_queues parameter
    - When work_queues provided, workers pull from shared queues instead of static file list
    - Add work stealing check when own queue is empty
    - Report file completions to coordinator for metrics

    In parallel_esm.py:
    - Similar updates to process_esm_files()
    - Support for shared work queues
    - Work stealing when idle
    - Completion reporting for throughput tracking

    Worker modifications:
    - Check own queue first with get_nowait()
    - If empty, try stealing from other queues
    - Log stolen work for debugging
    - Continue until all queues empty

    Maintain backward compatibility - if no work_queues, use existing static file list.
  </action>
  <verify>grep -n "work_queues" virnucpro/pipeline/parallel_dnabert.py && grep -n "work_queues" virnucpro/pipeline/parallel_esm.py</verify>
  <done>Parallel workers support work stealing from shared queues</done>
</task>

</tasks>

<verification>
- CLI flags control work stealing and GPU weighting
- Pipeline creates coordinator when work stealing enabled
- Dashboard displays when requested with explicit coordinator wiring
- Workers can steal from shared queues
- GPU weights applied to file assignment (independently of work stealing)
</verification>

<success_criteria>
- Users can enable work stealing via --work-stealing flag
- GPU weighting activates with --gpu-weighted flag
- Dashboard appears during parallel processing (unless disabled)
- Dashboard receives coordinator instance explicitly in constructor
- Work stealing happens automatically when enabled
- GPU weighting works independently of work stealing
- All features backward compatible (off by default)
</success_criteria>

<output>
After completion, create `.planning/phases/05-advanced-load-balancing/05-04-SUMMARY.md`
</output>